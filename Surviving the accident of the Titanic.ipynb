{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier of likelihood of Surviving the Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0    male  22.0                        1                        0   7.2500  \n",
       "1  female  38.0                        1                        0  71.2833  \n",
       "2  female  26.0                        0                        0   7.9250  \n",
       "3  female  35.0                        1                        0  53.1000  \n",
       "4    male  35.0                        0                        0   8.0500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv(r'titanic.csv')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "0       3    male  22.0                        1                        0   \n",
       "1       1  female  38.0                        1                        0   \n",
       "2       3  female  26.0                        0                        0   \n",
       "3       1  female  35.0                        1                        0   \n",
       "4       3    male  35.0                        0                        0   \n",
       "\n",
       "      Fare  \n",
       "0   7.2500  \n",
       "1  71.2833  \n",
       "2   7.9250  \n",
       "3  53.1000  \n",
       "4   8.0500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only including the features/factors, excluding the \"Name\" column\n",
    "X=training_data.iloc[:,[1,3,4,5,6,7]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   female  male\n",
       "0       0     1\n",
       "1       1     0\n",
       "2       1     0\n",
       "3       1     0\n",
       "4       0     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorising and creating dummy variables\n",
    "indicator=pd.get_dummies(training_data[\"Sex\"])\n",
    "indicator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final dataset with unnormalised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \\\n",
       "0       3  22.0                        1                        0   7.2500   \n",
       "1       1  38.0                        1                        0  71.2833   \n",
       "2       3  26.0                        0                        0   7.9250   \n",
       "3       1  35.0                        1                        0  53.1000   \n",
       "4       3  35.0                        0                        0   8.0500   \n",
       "\n",
       "   Gender  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final dataset with unnormalised data\n",
    "X2=pd.concat([X,indicator],axis=1)\n",
    "X3=X2.iloc[:,[0,2,3,4,5,6]]\n",
    "Final=X3.rename(columns={'female':'Gender'})\n",
    "Final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The observed values for the \"Survived\" column\n",
    "Output=training_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \\\n",
       "0       3  22.0                        1                        0   7.2500   \n",
       "1       1  38.0                        1                        0  71.2833   \n",
       "2       3  26.0                        0                        0   7.9250   \n",
       "3       1  35.0                        1                        0  53.1000   \n",
       "4       3  35.0                        0                        0   8.0500   \n",
       "\n",
       "   Gender  Survived  \n",
       "0       0         0  \n",
       "1       1         1  \n",
       "2       1         1  \n",
       "3       1         1  \n",
       "4       0         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combine=pd.concat([Final,Output],axis=1)\n",
    "Combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Insights from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABR8AAATkCAYAAADl43eyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZmZmZmZmbWEv8PdjONIBi9pz0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b44a4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.pairplot(Combine, hue='Survived')\n",
    "for i, j in zip(*np.triu_indices_from(g.axes, 1)):\n",
    "    g.axes[i, j].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAFtCAYAAAC6F0vsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1e59c4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(Final.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>0.085026</td>\n",
       "      <td>0.020252</td>\n",
       "      <td>-0.548919</td>\n",
       "      <td>-0.129507</td>\n",
       "      <td>-0.336528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.391492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.297669</td>\n",
       "      <td>-0.193741</td>\n",
       "      <td>0.112329</td>\n",
       "      <td>-0.091875</td>\n",
       "      <td>-0.059665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <td>0.085026</td>\n",
       "      <td>-0.297669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414244</td>\n",
       "      <td>0.158839</td>\n",
       "      <td>0.113249</td>\n",
       "      <td>-0.037082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <td>0.020252</td>\n",
       "      <td>-0.193741</td>\n",
       "      <td>0.414244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215470</td>\n",
       "      <td>0.244337</td>\n",
       "      <td>0.080097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>-0.548919</td>\n",
       "      <td>0.112329</td>\n",
       "      <td>0.158839</td>\n",
       "      <td>0.215470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181137</td>\n",
       "      <td>0.256179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>-0.129507</td>\n",
       "      <td>-0.091875</td>\n",
       "      <td>0.113249</td>\n",
       "      <td>0.244337</td>\n",
       "      <td>0.181137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.542152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.336528</td>\n",
       "      <td>-0.059665</td>\n",
       "      <td>-0.037082</td>\n",
       "      <td>0.080097</td>\n",
       "      <td>0.256179</td>\n",
       "      <td>0.542152</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Pclass       Age  Siblings/Spouses Aboard  \\\n",
       "Pclass                   1.000000 -0.391492                 0.085026   \n",
       "Age                     -0.391492  1.000000                -0.297669   \n",
       "Siblings/Spouses Aboard  0.085026 -0.297669                 1.000000   \n",
       "Parents/Children Aboard  0.020252 -0.193741                 0.414244   \n",
       "Fare                    -0.548919  0.112329                 0.158839   \n",
       "Gender                  -0.129507 -0.091875                 0.113249   \n",
       "Survived                -0.336528 -0.059665                -0.037082   \n",
       "\n",
       "                         Parents/Children Aboard      Fare    Gender  Survived  \n",
       "Pclass                                  0.020252 -0.548919 -0.129507 -0.336528  \n",
       "Age                                    -0.193741  0.112329 -0.091875 -0.059665  \n",
       "Siblings/Spouses Aboard                 0.414244  0.158839  0.113249 -0.037082  \n",
       "Parents/Children Aboard                 1.000000  0.215470  0.244337  0.080097  \n",
       "Fare                                    0.215470  1.000000  0.181137  0.256179  \n",
       "Gender                                  0.244337  0.181137  1.000000  0.542152  \n",
       "Survived                                0.080097  0.256179  0.542152  1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combine.corr(method ='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top most correlated features with survived are Gender, Pclass and Fare. Also, the Pclass and Fare have a negative correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1fc5a940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIElq/h9DTCrpwJowwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c5898d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1dd4b9e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF3tJREFUeJzt3X2UHXWd5/H3hzAZBJlxlczgkmDYMbKiIkiMzuKID4hx\ndcFdUcEHxFVz3DWK60MW1jk4E4+7Z3HVcRQdo8Po6iDiw6xxJk50FHxgB02CCISIRkDTYIag4gOL\nQuC7f1R1cenppG+Hrtx08n6d06er6v5u1bcb0p9bv6r6/VJVSJIEsN+oC5Ak7TkMBUlSx1CQJHUM\nBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHX2H3UB03XIIYfUwoULR12GJM0qGzZsuLWq5k3VbtaF\nwsKFC1m/fv2oy5CkWSXJD4dpZ/eRJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOrPu\n4TXtvVasWMHWrVs59NBDOe+880ZdjrRPMhS0x9i6dSs33XTTqMuQ9ml2H0mSOoaCJKljKEiSOoaC\nJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOr2GQpKlSa5LsjnJ2Tto84Ik1ybZmOTCPuvZ261YsYIz\nzjiDFStWjLoUSbNUb8NcJJkDnA88AxgD1iVZXVXXDrRZBJwDHF9VP0vye33Vsy9wmAhJ91efZwpL\ngM1VdX1V3QlcBJwyoc2rgPOr6mcAVXVLj/VIkqbQZygcBmwZWB9rtw16BPCIJJcluTzJ0h7rkSRN\noc9RUjPJtprk+IuApwDzga8neXRV3XafHSXLgGUAhx9++MxXKkkC+j1TGAMWDKzPB26epM3nququ\nqroBuI4mJO6jqlZV1eKqWjxv3rzeCpakfV2fobAOWJTkiCRzgdOA1RPa/B/gqQBJDqHpTrq+x5ok\nSTvRWyhU1XZgObAW2ARcXFUbk6xMcnLbbC3wkyTXApcAb66qn/RVkyRp53qdea2q1gBrJmw7d2C5\ngDe0X5KkEfOJZklSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlS\nx1CQJHUMBUlSx1CQJHUMBUlSp9f5FDScH618zIzsZ/tPHwzsz/af/nBG9nn4uVff/6IkzSqeKUiS\nOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOr2GQpKlSa5LsjnJ2ZO8fmaSbUmubL9e2Wc9kqSd\n6+3htSRzgPOBZwBjwLokq6vq2glNP1lVy/uqQ5I0vD7PFJYAm6vq+qq6E7gIOKXH40mS7qc+Q+Ew\nYMvA+li7baLnJbkqyaeTLOixHknSFPoMhUyyrSasfx5YWFVHA/8AfHTSHSXLkqxPsn7btm0zXKYk\naVyfoTAGDH7ynw/cPNigqn5SVb9pVz8EHDfZjqpqVVUtrqrF8+bN66VYSVK/obAOWJTkiCRzgdOA\n1YMNkjx0YPVkYFOP9UiSptDb3UdVtT3JcmAtMAe4oKo2JlkJrK+q1cDrkpwMbAd+CpzZVz2SpKn1\nOp9CVa0B1kzYdu7A8jnAOX3WIEkank80S5I6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqdPrLanavQ45\n4B5ge/t99zn+vcfPyH7m3jaX/diPLbdtmZF9Xvbay2agKmnfYijsRd509G2jLkHSLGf3kSSpYyhI\nkjqGgiSpYyhIkjqGgiSpYyhIkjrekirNgBUrVrB161YOPfRQzjvvvFGXI+0yQ0GaAVu3buWmm24a\ndRnS/Wb3kSSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp02soJFma5Lokm5OcvZN2pyapJIv7\nrEeStHO9hUKSOcD5wLOAo4DTkxw1SbuDgdcB3+yrFknScPo8U1gCbK6q66vqTuAi4JRJ2r0NOA/4\ndY+1SJKG0GcoHAZsGVgfa7d1khwLLKiqv+2xDknSkPoMhUyyrboXk/2AdwNvnHJHybIk65Os37Zt\n2wyWKEkatNNQSPLLJL/Y0dcU+x4DFgyszwduHlg/GHg0cGmSG4EnAqsnu9hcVauqanFVLZ43b94w\nP5ckaRfsdJTUqjoYIMlKYCvwMZozgBfT/FHfmXXAoiRHADcBpwEvGtj3z4FDxteTXAq8qarWT/un\nkCTNiGGHzn5mVT1hYP0DSb5Jc4F4UlW1PclyYC0wB7igqja2AbO+qlbvctU9cUx8Sfu6YUPh7iQv\nprmDqIDTgbunelNVrQHWTNh27g7aPmXIWnrjmPiS9nXDXmh+EfAC4J/ar+cz0BUkSdo7DHWmUFU3\nMvkzBpKkvchQZwpJHpHky0muadePTvLH/ZYmSdrdhu0++hBwDnAXQFVdRXM3kSRpLzJsKBxYVd+a\nsG37TBcjSRqtYUPh1iR/QPtEcpJTgR/3VpUkaSSGvSX1NcAq4F8nuQm4geYBNknSXmTYUPhhVZ2Y\n5CBgv6r6ZZ9FSZJGY9juoxuSrKIZn+hXPdYjSRqhYUPhSOAfaLqRbkjyviRP6q8sSdIoDBUKVXVH\nVV1cVf8BOBb4HeCrvVYmSdrthp5PIckJSd4PXAEcQDPshSRpLzLUheYkNwBXAhcDb66q23utapqO\ne/P/npH9HHzrL5kD/OjWX87IPje844z7X5Qk7UbD3n302KqaalIdSdIst9NQSLKiqs4D3p6kJr5e\nVa/rrTJJ0m431ZnCpva7s6FJezEnmNK4qabj/Hy7eFVVfXs31CNpBJxgSuOGvfvoXUm+m+RtSR7V\na0WSpJEZ9jmFpwJPAbYBq5Jc7XwKkrT3Gfo5haraWlV/Drya5vbUSedaliTNXsPOvPbIJH/Szrz2\nPuD/AvN7rUyStNsN+5zCXwGfAE6qqpt7rEeSNEJThkKSOcAPquo9u6EeSdIITdl9VFV3Aw9JMne6\nO0+yNMl1STYnOXuS11/dXrS+Msk3khw13WNIkmbO0JPsAJclWQ104x5V1bt29Ib2DON84BnAGLAu\nyeqqunag2YVV9Rdt+5OBdwFLp/cjSJJmyrChcHP7tR9w8JDvWQJsrqrrAZJcBJwCdKEwYTylg2jn\ngB6Ve+YedJ/vkrSvGSoUqupPd2HfhwFbBtbHgCdMbJTkNcAbgLnA03bhODPm9kUnjfLwkjRyww6d\nfQmTfIqvqp39Ec8k2ybbx/nA+UleBPwx8LJJjr8MWAZw+OGHD1OyJGkXDNt99KaB5QOA5wHbp3jP\nGLBgYH0+TRfUjlwEfGCyF6pqFbAKYPHixSPtYpKkvdmw3UcbJmy6LMlU03GuAxYlOQK4CTgNeNFg\ngySLqur77eqzge8jSRqZYbuPHjywuh+wGDh0Z++pqu1JlgNrgTnABVW1MclKYH1VrQaWJzkRuAv4\nGZN0HUmSdp9hu482cO/1gO3AjcArpnpTVa0B1kzYdu7A8llDHl+StBtMNfPa44EtVXVEu/4ymusJ\nNzJwa6kkae8w1RPNHwTuBEjyZOB/AB8Ffk574VeaKXVgcc9B91AHei+BNCpTdR/NqaqftssvBFZV\n1WeAzyS5st/StK+56/i7Rl2CtM+b6kxhTpLx4Hg68JWB14a9HiFJmiWm+sP+CeCrSW4F7gC+DpDk\n4TRdSJKkvchOQ6Gq3p7ky8BDgS9W1Xhn737Aa/suTpK0e03ZBVRVl0+y7Xv9lCNJGqWh52iWJO39\nDAVJUsdQkCR1DAVJUsdnDbRP++qTT5iR/dyx/xxIuGNsbMb2ecLXphqIWJp5nilIkjqGgiSpYyhI\nkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp02soJFma5Lokm5OcPcnr\nb0hybZKrknw5ycP6rEeStHO9hUKSOcD5wLOAo4DTkxw1odm3gcVVdTTwaeC8vuqRJE2tzzOFJcDm\nqrq+qu4ELgJOGWxQVZdU1f9rVy8H5vdYjyRpCn2GwmHAloH1sXbbjrwC+MJkLyRZlmR9kvXbtm2b\nwRIlSYP6DIVMsq0mbZi8BFgMvGOy16tqVVUtrqrF8+bNm8ESJUmD+px5bQxYMLA+H7h5YqMkJwJv\nAU6oqt/0WI8kaQp9nimsAxYlOSLJXOA0YPVggyTHAh8ETq6qW3qsRZI0hN5Coaq2A8uBtcAm4OKq\n2phkZZKT22bvAB4IfCrJlUlW72B3kqTdoM/uI6pqDbBmwrZzB5ZP7PP4kqTp8YlmSVLHUJAkdQwF\nSVLHUJAkdQwFSVKn17uPJPXrfW/8/Izs57Zbb+++z8Q+l7/z393vfWg0PFOQJHUMBUlSx1CQJHUM\nBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlS\nx1CQJHV6DYUkS5Ncl2RzkrMnef3JSa5Isj3JqX3WIkmaWm+hkGQOcD7wLOAo4PQkR01o9iPgTODC\nvuqQJA2vzzmalwCbq+p6gCQXAacA1443qKob29fu6bEOSdKQ+uw+OgzYMrA+1m6TJO2h+gyFTLKt\ndmlHybIk65Os37Zt2/0sS5K0I32GwhiwYGB9PnDzruyoqlZV1eKqWjxv3rwZKU6S9M/1GQrrgEVJ\njkgyFzgNWN3j8SRJ91NvoVBV24HlwFpgE3BxVW1MsjLJyQBJHp9kDHg+8MEkG/uqR5I0tT7vPqKq\n1gBrJmw7d2B5HU23kiRpD+ATzZKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSer0+vCa\ntK94UNV9vkuzlaEgzYCX3O2UINo72H0kSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKk\njqEgSeoYCpKkjqEgSeoYCpKkjqEgSer0GgpJlia5LsnmJGdP8vpvJ/lk+/o3kyzssx5J0s71FgpJ\n5gDnA88CjgJOT3LUhGavAH5WVQ8H3g38z77qkSRNrc8zhSXA5qq6vqruBC4CTpnQ5hTgo+3yp4Gn\nJ0mPNUmSdqLPUDgM2DKwPtZum7RNVW0Hfg48pMeaJEk7kepp+sAkzweeWVWvbNdfCiypqtcOtNnY\nthlr13/QtvnJhH0tA5a1q0cC1/VSdOMQ4NYe99836x+d2Vw7WP+o9V3/w6pq3lSN+pyOcwxYMLA+\nH7h5B23GkuwP/C7w04k7qqpVwKqe6ryPJOuravHuOFYfrH90ZnPtYP2jtqfU32f30TpgUZIjkswF\nTgNWT2izGnhZu3wq8JXq69RFkjSl3s4Uqmp7kuXAWmAOcEFVbUyyElhfVauBvwQ+lmQzzRnCaX3V\nI0maWp/dR1TVGmDNhG3nDiz/Gnh+nzXsgt3STdUj6x+d2Vw7WP+o7RH193ahWZI0+zjMhSSpYyi0\nphqSY0+X5IIktyS5ZtS1TFeSBUkuSbIpycYkZ426pulIckCSbyX5Tlv/n466pl2RZE6Sbyf521HX\nMl1JbkxydZIrk6wfdT3TkeS/tP/fXJPkE0kOGGU9hgJDD8mxp/sIsHTUReyi7cAbq+qRwBOB18yy\n3/9vgKdV1WOBY4ClSZ444pp2xVnAplEXcT88taqO2RNu6xxWksOA1wGLq+rRNDfljPSGG0OhMcyQ\nHHu0qvoakzzjMRtU1Y+r6op2+Zc0f5gmPv2+x6rGr9rV32q/ZtXFuiTzgWcDHx51Lfug/YEHtM9q\nHcg/f55rtzIUGsMMyaHdoB0p91jgm6OtZHrarpcrgVuAL1XVrKof+DNgBXDPqAvZRQV8McmGdgSE\nWaGqbgL+F/Aj4MfAz6vqi6OsyVBoTDYI36z6pLc3SPJA4DPA66vqF6OuZzqq6u6qOobmyf0lSR49\n6pqGleQ5wC1VtWHUtdwPx1fV42i6gF+T5MmjLmgYSf4FTa/EEcC/BA5K8pJR1mQoNIYZkkM9SvJb\nNIHw11X12VHXs6uq6jbgUmbX9Z3jgZOT3EjTdfq0JB8fbUnTU1U3t99vAf6Gpkt4NjgRuKGqtlXV\nXcBngX8zyoIMhcYwQ3KoJ+1w6X8JbKqqd426nulKMi/Jg9rlB9D8Q//uaKsaXlWdU1Xzq2ohzf/7\nX6mqkX5anY4kByU5eHwZOAmYLXfh/Qh4YpID238HT2fEF/sNBbphu8eH5NgEXFxVG0db1fQk+QTw\nj8CRScaSvGLUNU3D8cBLaT6hXtl+/dtRFzUNDwUuSXIVzQeML1XVrLutcxb7feAbSb4DfAv4u6r6\n+xHXNJT22tOngSuAq2n+Jo/0yWafaJYkdTxTkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAX1Jslb2tEf\nr2pvM31Cu/3D4wPeJfnVDt77kSSnTmw/w/Wdk+TFSY5Mcmlb46Yke8RkJ1NJcmySSvLMgW0Ld9dI\nuTv6b6fZrdeZ17TvSvKHwHOAx1XVb5IcAswFqKpXTmdf020/DScBLwA+Dry7qj4HkOQxPR1vpp0O\nfKP9vrbPAyXZv32eR3s5zxTUl4cCt1bVbwCq6tbxoQjaT+Xd8MZJ3pnkiiRfTjJv4o4G2yf5VZK3\nt3MXXJ7k99vtf9Cur0uycvxTbJKHJvlaexZwTZI/arf/DjC3qra1tY6NH6+qrm7bnJnkc0n+vp1r\n460DNb2h3d81SV7fbrvPp/Qkb0ryJ+3y65Jc2541XdRuOyjNPBjr2nkMTmm3PyrN/AxXtu0XTfI7\nCXAqcCZw0oQx+PdP8tH2vZ9OcmD7nqe3x7m6Pe5vt9vPbWu4Jsmqdt/jv/f/nuSrwFntE///2LZ9\n2xT//TVLGQrqyxeBBUm+l+T9SU7YQbuDgCvawcy+Crx1B+0G21/ezl3wNeBV7fb3AO+pqsdz33Gr\nXgSsbQereyxwZbv9RODL7fK7ga8k+UKaCU8eNPD+JcCLaeZJeH6SxUmOA14OPIFm/odXJTl2irrP\nBo6tqqOBV7fb3kIzpMTjgacC72iHaXh1+7McAyxmILAGHE8zZs4PaMZaGnwC/EhgVXusXwD/uQ2N\njwAvrKrH0PQS/Ke2/fuq6vHteP4PoDnDG/egqjqhqt5J8zv+QFvv1il+Xs1ShoJ60c4vcBywDNgG\nfDLJmZM0vQf4ZLv8ceBJU+z6TmB8CIkNwMJ2+Q+BT7XLFw60Xwe8vP3E/ph2vgZoBqz7QlvrXwGP\nbN//FODy8U/RNENW/KSq7qAZrOxJ7dffVNXt7c/5WeCPpqj7KuCv04yAOd4NcxJwdpohty8FDgAO\npxmu5L8l+a/Aw9pjT3Q6zeB1tN9PH3htS1Vd1i6P/06PpAmR77XbPwqMjyT61CTfTHI18DTgUQP7\n+uTA8vHAJ9rlj03x82qWMhTUm3Y46Uur6q00Y0s9b5i3TfH6XXXv2Cx3M8V1sXbyoScDNwEfS3JG\n+9ISmnFyxtvdXFUXVNUpNH+0x4e+nlhPMflQ67TvG/w3Ndil82ya2f2OAzakmVAlwPPa2cKOqarD\nq2pTVV0InAzcAaxN8rTBg6SZKfB5wLlpRjZ9L/CstIPCTafm9gzi/cCp7RnEhybUffsk+9JezFBQ\nL9o7egb7wo8BfjhJ0/1o+sah6er5xi4e8nLuDZ1uOsMkD6OZK+BDNCOxPi7Jo4DvVtXdbZulaYbu\nJsmhwENoQgTgGUkenGb00+cCl9F0Wz03zciWBwH/Hvg68E/A7yV5SHum8Zx2n/sBC6rqEpqJbB4E\nPJDm4vBrB/rwj22//yvg+qr6c5rReo+e8LOeCHynqhZU1cKqehjNsOPPbV8/vL3QD/dejP4usDDJ\nw9vtL6XprhsPgFvTzGcx/t9iMpcN/G5fvJN2msW8+0h9eSDw3rZ/fjuwmaYraaLbgUcl2QD8HHjh\nLh7v9cDHk7wR+Lt2X9B0B705yV3Ar4AzaMJjcBTNk4D3JPl1u/7mqtra/q3+Bk1XycOBC6tqPTS3\nzHLvmcaHq+rb7faVNLPG3cC9w2fPaWv7XZpP7O+uqtvai7V/BlzVBsONNEHyQuAlbc1bgZUTftbT\naeYMGPQZmmsEX6cZ6fdlST4IfJ/mOsCvk7wc+FR7lrIO+Iv2zrAP0YzQeWO7fUfOAi5MclZ7PO2F\nHCVVe4X2Dps7qqqSnAac3nYFTdb2S8AZVfXjKfZ5Js2E6stnvGBpD+WZgvYWxwHvaz9x3wb8xx01\nrKpn7LaqpFnGMwVJUscLzZKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSer8f3h4zPPRcwZDAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1e737978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Siblings/Spouses Aboard', y='Survived', data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1fbc3a20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9f8BHHBJFjSn0hkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1e63fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Parents/Children Aboard', y='Survived', data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1fe38b70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKlhKEiSGoaCJKnx/wG5dmYpH9EB5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a13c38470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Sex', y='Survived', data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9MR1MA/oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1ff455f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = Final.iloc[:,:] \n",
    "y = training_data.iloc[:,0]\n",
    "survived = Final.loc[y == 1]\n",
    "not_survived = Final.loc[y == 0]\n",
    "plt.scatter(survived.iloc[:, 1], survived.iloc[:, 2], s=10, label='survived')\n",
    "plt.scatter(not_survived.iloc[:, 1], not_survived.iloc[:, 2], s=10, label='Not survived')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Siblings/Spouses Aboard')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VOX5//H3nUlCAkHZoiBBWUpBZA0BRMWiiCK12NYF\nsNVWLViVqv2qVb9uAVv7s9parUur31prXQCXKiqKuKO4kCCKRCggKpEtolCWQLb798dMDnMmIQnL\nkKif13XlmnnOs8x9zpyZO+ecmWfM3REREQFIaewARESk6VBSEBGRgJKCiIgElBRERCSgpCAiIgEl\nBRERCSgpiIhIQElBREQCSgoiIhJIbewAdlW7du28c+fOjR2GiMjXSmFh4Rfunl1fu69dUujcuTMF\nBQWNHYaIyNeKmX3akHY6fSQiIgElBRERCSgpiIhIQElBREQCSgoiIhJQUhARkUDSkoKZ3Wdm68zs\nw53Um5ndbmbLzOwDM8tNViwiItIwyTxSuB8YVUf9iUD32N9E4O4kxiIiIg2QtC+vufvrZta5jiYn\nAw949Eei3zazVmbWwd1XJysmgJtnLeGRdz8Dd8YPOYQfzT+bnO1LKG7Wg+9cNZePp15B809ms7Xz\nSLqOu4kRf3yVFSVb6JLdgpcuHc4pd89lYfEG+uS04vHzj2DB7IfZtuRFMnocBxDc7z/yDNbcO5aW\na+ayqf0RtJ8wDf4+Ela9Dwf1g3Nnw+KZsPxl6HYs9BxdZ/nmT7vxYtEajuvVnstP6MFzt11At69e\nZ1OLrgzs9V1+/5+D+McXPYO4Lv/t7zls23wWZeRy8zVXcc1NN9F9UwFLW+bx2yuuYNW1nWmf8hVr\nqlpzo51LXtUHFKT05Y4p19bYBhvyO7K/b2ajZdEq/3P+cvVZHBeZz4uVufzqdw+Exj7wv4tCdYU3\nj6HrlgI+bpHHwMtn8OgfzqPP5jdZmHUkp/3mbzXifP664xlsH/Ku92bUlBd48MZzGbjtHQozhrCp\ntJzhNp9PvAMnHt6PWfMWcnDV57yRkseE/Pt5695LOHD1yyzZ/yje6nwB0+Z9xvYKp0V6CoumnFjj\nuexxzUy2VzjNUo3MtAgbSitolZnKgutPqPFcJG6/xPV4cfIocqs+YH5KX8pbdaXbV6+zvPXRnHjx\nXTUeN36f6T/yDJ545F4iK16hsssx/Hj8hBrbbHbRWuYsLWFY92yyP38p1Ddx+908a0loP/n9rX8i\n58u3KG4zlKt+/T+hsUb2OjDUvn+nVqG6Cx6az9xlJRzxnWzu+klujb6J5cRtltg/Xo2+CRK3UeJ6\nSfJY9D05SYNHk8Iz7t67lrpngP/n7m/Eyi8BV7h7nV9XzsvL8939RvPNs5Zw5yvLgvKjadeTl7IU\nM3CHL1La0a7qi6B8f+QUJm89JWjfLNXYXrFje/209YdcvfUWMq2M7R7Nr82sglJPZ33LnnTc9EEw\nVln6/jQr37gjmHbdYWMxlJdCWiYcfgG8fVet5fKUDM7fdiEvVg0E4Lf7PcFPtj8WjG0GWz2di8p/\nxYtVAzkhUsitqX+huZWx1dO5r/JEzok8F5RLq9Jok7Il6F8FRGJjvFbVn1Ep7wZ12yyNDC8PyqVV\nqWSmVATlZysHc2xkAc2tjHKPkEplULesqgPfSVkdlD+2g+jqq4LyzKrBHJOyIIhrUdUhoecjsX90\nP9mxzvG386u6kxvX946Kk/lj5djd2k9OzljAbWl/CZ6LB+37/Hj7jCDOxG1UV5z3+A/5fdnpwdin\nZX3AlPI/kWlllHo6r7Y5je99+Wgw9vJIV3pXLg76v9lsGBNKJ1FaXsmo1PncGrk96PugfZ+f+LNB\n39/4RTxTlht6rMnlfwrqb2x+GY9v7kdpeSWZaRGO6XkAMxfu+B8sNcWoqHIy0yL0Omg/Cj/9Kqgb\neEhrilb9N+h7zlFduO+NFUH5kaO/pP+7/xNss7vbXc1NK7oG/Uf36RAkhtlFa7nokfeCvrePHxBK\nDAtmP0yPNy4O1vP+g64LjXXhMd9RYtgNZlbo7nn1tWvMC81Wy7JaM5SZTTSzAjMrKCkp2e0HfLFo\nTajcJ2UFZtWPAW1jCaG6fHjFu6H28QkBoPumAjKtDIgmg2ZWAUCmlZG9uSg0Vnp8QgD4Ynn0BQTR\n2yXP7bScVrWNo1IWBl0HbnsnNDZAcysL2gy1hTSPxdXcyhiRMj9Urk4I1f0jcWMMSVkUqqtOCNXl\n6oRQXT4isigYO80qQ3VdUtaEyof46lB5aMqiUFyJz0di/8R1jr89LKHvcZH57K4BFQtCz8XAbe+E\n4kzcRnXFeTSFobEP2zY/2GcyrYxuX70eGrt75bJQ/17b51NaXgnA4XwQ6ntUVUGob17VBzUeKzT2\npoJgrNLySuYuC7+WKqo8qFtYvCFUt7B4Q6jvi0VrQuVtS14MbbNWq+eE+sc/1pylJaG+c5aG49i2\n5MXQeiaOlfg6lr2rMZNCMdAprpwDrKqtobvf4+557p6XnV3vfE47dVyv9qHywqouwX927rA+pV2o\n/Hbq4FD7ZqnhPLa0ZR6lng7Adk8NjhZKPZ2SrF6hscrS9g8H065b9IgAorc9TtxpuTwlgzeq+gRd\nCzOGhMaG6H/51W3e8j5sjcW11dN5qSo3VP6yqkWof2XcGO9UHRaq22ZpoXJpVWqoPLfysGDsco+E\n6lZUtQ+VP7UOofJbVYeF4kp8PhL7J65z/O2ihL4vVu7+5xbeS+0fei4KM4aE4kzcRnXF+ToDQ2Mv\nysgN9plST2d566NDYy+NfCfUv6hZLplpEQDepm+o7xspeaG+BSl9azxWaOyWecFYmWkRjvhO+LWU\nmmJBXZ+cVqG6PjmtQn2P69U+VM7ocVxom23oMCzUP/6xhnXPDvUd1j0cR0aP40LrmThW4utY9q5I\nfn5+0gafPHlyK+CM/Pz8u2qpc2DC5MmTH548efLhwLHufmt9Y95zzz35EydO3K14jvxOO8orneUl\nm8lMS6HlEedwYMlcmld+xacZh9Lpmg9YsXYD2zd/RUn3sRx74R08/f4qNm4tp2t2C+ZdM5I5S79g\n/ebt9D+4NX+7ZDyLKnL4pDSDDbmT+OLg0XxSmsHG3Av57pm3snbZAmzrOr486BhaXTI3er51yxeQ\nMxB++QYc0Asy28CRl8DgX+y0HBn2a5a0GsZ/S8sYN/hgzj/7HJ7/YCW+bQOfZg3goP7Hc8uW0TxV\n2pf+B7fmX1f8lP99s5JVZc2Z3uzHXJP/Jya/66zclslTWady0rX/ZvXLf6OFbWNNVWuuZhLrKrP4\np43h4hv+L7QNDpg0m42v3UEzL2OjZdFyylruePEj9rOtTK08hjN/9+9g7CeyTqeotE1Qd+JvX2J+\nwVtkln9BUdYRHHb1mzw27xMi2zfyatZofnjt9FCcP8//F7NeeYU2bOB1z2XIDe/w0FvLSCvfxKyM\n45lb3p0stlLgPek+ZDQvrEqnvMp4MmUEJ02ZydvL1lK+5SveaX0SSw67hMVr/ktlFbRIT2Hp70aH\nnsv3rjueu19dRmVVNNm3bJbKtooqWmWm8lT+2aHnou+PLgttv/Ou/VtoPYZdO4uXXn+NVv4Vc1Py\n+E/r7+HbNjCvzQ8Yd9X/hR73wSvPDPaZjbkXMuyMK3l6TWv+symNpd1/wfBJd4e22eFXPk2P9i1p\n3TyNUcOPprR1j6Dv98+9NrT9/nz91ZRXerCf5J/zQ25ZkMonW5sxu/V4rr/s8mCsX36vGxeN6B5q\n/4thXYO6q0Yfyn/WbqZk0zaOPfRAHjhncKjvmUMPCZWPPHxoaJsNGvXTUP/4awrdsrNCfROvKbTv\n1ie0jX5w+i9CcerU0e6ZPHny6vz8/Hvqa5e0awpm9ggwHGgHrAWuB9IA3P2vZmbAHUQ/obQVOLu+\n6wmwZ9cURES+rRp6TSGZnz4aX0+9Axcm6/FFRGTX6RvNIiISUFIQEZGAkoKIiASUFEREJKCkICIi\nASUFEREJKCmIiEhASUFERAJKCiIiElBSEBGRgJKCiIgElBRERCSgpCAiIgElBRERCSgpiIhIQElB\nREQCSgoiIhJQUhARkYCSgoiIBJQUREQkoKQgIiIBJQUREQkoKYiISEBJQUREAkoKIiISUFIQEZGA\nkoKIiASUFEREJKCkICIiASUFEREJJDUpmNkoM1tiZsvM7Mpa6g82s1fM7D0z+8DMRiczHhERqVvS\nkoKZRYA7gROBXsB4M+uV0OwaYLq7DwDGAXclKx4REalfMo8UBgPL3P1jdy8DpgInJ7RxYL/Y/f2B\nVUmMR0RE6pGaxLE7AivjysXAkIQ2+cALZvYroAVwXBLjERGReiTzSMFqWeYJ5fHA/e6eA4wG/mVm\nNWIys4lmVmBmBSUlJUkIVUREILlJoRjoFFfOoebpoXOB6QDu/haQAbRLHMjd73H3PHfPy87OTlK4\nIiKSzKQwD+huZl3MLJ3oheQZCW0+A0YAmNmhRJOCDgVERBpJ0pKCu1cAk4BZwEdEP2W0yMymmNmY\nWLNLgQlm9j7wCPBzd088xSQiIvtIMi804+4zgZkJy66Lu18EHJnMGEREpOH0jWYREQkoKYiISEBJ\nQUREAkoKIiISUFIQEZGAkoKIiASUFEREJKCkICIiASUFEREJKCmIiEhASUFERAJKCiIiElBSEBGR\ngJKCiIgElBRERCSgpCAiIgElBRERCSgpiIhIQElBREQCSgoiIhJQUhARkYCSgoiIBJQUREQkoKQg\nIiIBJQUREQkoKYiISEBJQUREAkoKIiISUFIQEZGAkoKIiASSmhTMbJSZLTGzZWZ25U7anG5mRWa2\nyMweTmY8IiJSt9RkDWxmEeBOYCRQDMwzsxnuXhTXpjtwFXCku39lZgckKx4REalfMo8UBgPL3P1j\ndy8DpgInJ7SZANzp7l8BuPu6JMYjIiL1SGZS6AisjCsXx5bF+y7wXTN708zeNrNRSYxHRETqkbTT\nR4DVssxrefzuwHAgB5hjZr3dfUNoILOJwESAgw8+eO9HKiIiQHKPFIqBTnHlHGBVLW2ecvdyd18B\nLCGaJELc/R53z3P3vOzs7KQFLCLybZfMpDAP6G5mXcwsHRgHzEho8yRwDICZtSN6OunjJMYkIiJ1\nqPf0UexTRLPc/bhdGdjdK8xsEjALiAD3ufsiM5sCFLj7jFjd8WZWBFQCl7v7+l1eCxFpdOXl5RQX\nF7Nt27bGDuVbLSMjg5ycHNLS0narv7knnuavpZHZDOBMd9+4W4+yF+Xl5XlBQUFjhyEiCVasWEHL\nli1p27YtZrVdUpRkc3fWr1/Ppk2b6NKlS6jOzArdPa++MRp6oXkbsNDMZgNb4gK4aFcCFpFvrm3b\nttG5c2clhEZkZrRt25aSkpLdHqOhSeHZ2J+IyE4pITS+PX0OGpQU3P2fZpYJHOzuS/boEUVEviZm\nzJhBUVERV15Z6yw9uyQrK4vNmzfvhaiSq0GfPjKzHwALgOdj5f6x6wwiIl9rFRUVO60bM2bMXkkI\nXycN/UhqPtFpKzYAuPsCoEtdHURE9qUtW7bw/e9/n379+tG7d2+mTZtG586d+eKLLwAoKChg+PDh\nAOTn5zNx4kSOP/54zjrrLIYMGcKiRYuCsYYPH05hYSH3338/kyZNYuPGjXTu3JmqqioAtm7dSqdO\nnSgvL2f58uWMGjWKgQMHMmzYMBYvXgxEL7wPHTqUQYMGce211+7bjbEHGpoUKmr55FH9H1sSEanD\n7KK1XPfUh8wuWrvHYz3//PMcdNBBvP/++3z44YeMGlX3rDmFhYU89dRTPPzww4wbN47p06cDsHr1\nalatWsXAgQODtvvvvz/9+vXjtddeA+Dpp5/mhBNOIC0tjYkTJ/KXv/yFwsJCbrnlFi644AIALr74\nYs4//3zmzZtH+/bt93j99pWGJoUPzewMIGJm3c3sL8DcJMYlIt9ws4vWctEj7/HAW59y0SPv7XFi\n6NOnDy+++CJXXHEFc+bMYf/996+z/ZgxY8jMzATg9NNP59FHHwVg+vTpnHbaaTXajx07lmnTpgEw\ndepUxo4dy+bNm5k7dy6nnXYa/fv357zzzmP16tUAvPnmm4wfPx6AM888c4/WbV9qaFL4FXAYsB14\nBPgvcEmyghKRb745S0soLa8EoLS8kjlLd/9jlADf/e53KSwspE+fPlx11VVMmTKF1NTU4JRP4pfq\nWrRoEdzv2LEjbdu25YMPPmDatGmMGzeuxvhjxozhueee48svv6SwsJBjjz2WqqoqWrVqxYIFC4K/\njz76KOjzdfw0VoOSgrtvdfer3X1QbA6iq91dX1sUkd02rHs2mWkRADLTIgzrvmfzmq1atYrmzZvz\n05/+lMsuu4z58+fTuXNnCgsLAXj88cfr7D9u3Dj+8Ic/sHHjRvr06VOjPisri8GDB3PxxRdz0kkn\nEYlE2G+//ejSpUtwlOHuvP/++wAceeSRTJ06FYCHHnpoj9ZtX6rzI6lm9jR1XDtw9zF7PSIR+VYY\n2etAbh8/gDlLSxjWPZuRvQ7co/EWLlzI5ZdfTkpKCmlpadx9992UlpZy7rnncuONNzJkyJA6+596\n6qlcfPHFdV4UHjt2LKeddhqvvvpqsOyhhx7i/PPP57e//S3l5eWMGzeOfv36cdttt3HGGWdw2223\nccopp+zRuu1LdU5zYWbfi939MdAeeDBWHg984u7/m9zwatI0FyJN00cffcShhx7a2GEItT8Xe2Wa\nC3d/LTbYDe5+dFzV02b2+u4EKyIiTVdDLzRnm1nX6oKZdQH0wwYiIt8wDZ376NfAq2ZW/VsHnYHz\nkhKRiIg0mobOffS8mXUHesYWLXb37ckLS0REGsOu/EbzQKJHCKlAPzPD3R9ISlQiItIoGpQUzOxf\nQDeik+JVxhY7oKQgIvIN0tALzXnAke5+gbv/KvanH9gRkSbDzLj00kuD8i233EJ+fn6dfZ588kmK\nioqSHFnY6NGj2bBhwx6Pk5+fzy233LIXIgpr8NxHRL+nICLSJDVr1ownnngimBW1IZKVFCorK3da\nN3PmTFq1arXXH3NvaWhSaAcUmdksM5tR/ZfMwEREdkVqaioTJ07k1ltvrVH36aefMmLECPr27cuI\nESP47LPPmDt3LjNmzODyyy+nf//+LF++PNTn0UcfpXfv3vTr14+jj45+Tat6Ku1qJ510UvDt5qys\nLK677jqGDBnCjTfeyOmnnx60e/XVV/nBD34AEEznfcUVV3DXXXcFbfLz8/njH/8IwM0338ygQYPo\n27cv119/fdDmd7/7HT169OC4445jyZLk/N5ZQy805yfl0UXk223xTFj+MnQ7FnqO3uPhLrzwQvr2\n7ctvfvOb0PJJkyZx1lln8bOf/Yz77ruPiy66iCeffJIxY8Zw0kknceqpp9YYa8qUKcyaNYuOHTs2\n6HTPli1b6N27N1OmTKGiooKuXbuyZcsWWrRowbRp0xg7dmyo/bhx47jkkkuCqbanT5/O888/zwsv\nvMDSpUt59913cXfGjBnD66+/TosWLZg6dSrvvfceFRUV5Obmhqb33lsaOiHea8AnQFrs/jxg/l6P\nRkS+PRbPhMfPgXn3Rm8Xz9zjIffbbz/OOussbr/99tDyt956izPOOAOITmP9xhtv1DvWkUceyc9/\n/nPuvffeOk8HVYtEIsEcR6mpqYwaNYqnn36aiooKnn32WU4++eRQ+wEDBrBu3TpWrVrF+++/T+vW\nrTn44IN54YUXeOGFFxgwYAC5ubksXryYpUuXMmfOHH70ox/RvHlz9ttvP8aMSc7Ucw399NEEYCLQ\nhuinkDoCfwVGJCUqEfnmW/4ylJdG75eXRst74WjhkksuITc3l7PPPnunbRoypfVf//pX3nnnHZ59\n9ln69+/PggULQlNxQ3g67oyMDCKRSFAeO3Ysd955J23atGHQoEG0bNmyxmOceuqpPPbYY6xZsyaY\nrtvdueqqqzjvvPD3g//85z/vk6m4G3pN4ULgSKK/o4C7LwUOSFZQIvIt0O1YSIv+yA1pmdHyXtCm\nTRtOP/10/v73vwfLjjjiiNA01kcddRQALVu2ZNOmTbWOs3z5coYMGcKUKVNo164dK1eupHPnzixY\nsICqqipWrlzJu+++u9M4hg8fzvz587n33ntrnDqqNm7cOKZOncpjjz0WnMI64YQTuO+++9i8eTMA\nn3/+OevWrePoo4/m3//+N6WlpWzatImnn3561zdOAzT0msJ2dy+rzlJmlop+jlNE9kTP0XDKfXv1\nmkK1Sy+9lDvuuCMo33777ZxzzjncfPPNZGdn849//AOIvilPmDCB22+/nccee4xu3boFfS6//HKW\nLl2KuzNixAj69esHQJcuXejTpw+9e/cmNzd3pzFEIhFOOukk7r//fv75z3/W2uawww5j06ZNdOzY\nkQ4dOgBw/PHH89FHHzF06FAgegH7wQcfJDc3l7Fjx9K/f38OOeQQhg0btmcbaSfqnDo7aGT2B2AD\ncBbRX2G7AChy96uTElUdNHW2SNOkqbObjj2ZOruhp4+uBEqAhUSvLTzbGAlBRESSq86kYGYnm9mF\n7l7l7vcChxD9dvP/mlnNz3CJiMjXWn1HCr8B4r+klk50YrzhwPlJiklERBpJfRea0919ZVz5DXf/\nEvjSzFokMS4R+Rpy933ysUnZuYZcJ65LfUcKrRMebFJcsd5fXjOzUWa2xMyWmdmVdbQ71czczOq9\nCCIiTVNGRgbr16/f4zcl2X3uzvr168nIyNjtMeo7UnjHzCbEricEzOw8YOcf0I22iQB3AiOBYmCe\nmc1w96KEdi2Bi4B3djV4EWk6cnJyKC4upqSkpLFD+VbLyMggJydnt/vXlxR+DTxpZmewY1qLgUAz\n4If19B0MLHP3jwHMbCpwMpA4JeENwB+Ay3YhbhFpYtLS0ujSpUtjhyF7qM6k4O7rgCPM7FjgsNji\nZ9395QaM3RGIvx5RDAyJb2BmA4BO7v6MmSkpiIg0sob+RvPLQEMSQbzarjYFJxvNLAW4Ffh5vQOZ\nTST6/QgOPvjgXQxDREQaqqFfXtsdxUCnuHIOsCqu3BLoDbxqZp8AhwMzarvY7O73uHueu+dlZ9d7\nfVtERHZTMpPCPKC7mXUxs3RgHHHfeXD3je7ezt07u3tn4G1gjLtrDgsRkUaStKTg7hXAJGAW8BEw\n3d0XmdkUM0vOROAiIrJHGjpL6m5x95nAzIRl1+2k7fBkxiIiIvVL5ukjERH5mlFSEBGRgJKCiIgE\nlBRERCSgpCAiIgElBRERCSgpiIhIQElBREQCSgoiIhJQUhARkYCSgoiIBJQUREQkoKQgIiIBJQUR\nEQkoKYiISEBJQUREAkoKIiISUFIQEZGAkoKIiASUFEREJKCkICIiASUFEREJKCmIiEhASUFERAJK\nCiIiElBSEBGRgJKCiIgElBRERCSgpCAiIgElBRERCSQ1KZjZKDNbYmbLzOzKWur/x8yKzOwDM3vJ\nzA5JZjwiIlK3pCUFM4sAdwInAr2A8WbWK6HZe0Ceu/cFHgP+kKx4RESkfsk8UhgMLHP3j929DJgK\nnBzfwN1fcfetseLbQE4S4xERkXokMyl0BFbGlYtjy3bmXOC52irMbKKZFZhZQUlJyV4MUURE4iUz\nKVgty7zWhmY/BfKAm2urd/d73D3P3fOys7P3YogiIhIvNYljFwOd4so5wKrERmZ2HHA18D13357E\neEREpB7JPFKYB3Q3sy5mlg6MA2bENzCzAcDfgDHuvi6JsYiISAMkLSm4ewUwCZgFfARMd/dFZjbF\nzMbEmt0MZAGPmtkCM5uxk+FERGQfSObpI9x9JjAzYdl1cfePS+bji4jIrtE3mkVEJKCkICIiASUF\nEREJKCmIiEhASUFERAJKCiIiElBSEBGRgJKCiIgElBRERCSgpCAiIgElBRERCSgpiIhIQElBREQC\nSgoiIhJQUhARkYCSgoiIBJQUREQkoKQgIiIBJQUREQkoKYiISEBJQUREAkoKIiISUFIQEZGAkoKI\niASUFEREJKCkICIiASUFEREJKCmIiEhASUFERAJKCiIiEkhqUjCzUWa2xMyWmdmVtdQ3M7Npsfp3\nzKxzMuMREZG6pSZrYDOLAHcCI4FiYJ6ZzXD3orhm5wJfuft3zGwccBMwNhnxzC5ay8PvfMrCzzdy\n9rZ/MSJlPivaHs2A5utpuWYum9ofQfsJ0zjl7rksLN5An5xWPH7+ERTePIauWwr4uEUeAy+fAS9N\ngSXPQY8TYcR1zC5ay5ylJQzrnk23D/5E809ms7XzSLqOu4kFsx9m25IXyehxHP1HnsFb917Cgatf\nZm2HYxk64c+weCYsfxm6HQs9R/Px1CtC/ePHHtnrwPAKJcSROFZlfitScKowIvkbqJiSTaSqjMqU\ndFKvK6Eyf39SgKrYcNX3I/kbQ3WRQROonHfvzusTyqGxqvs6VFl124S48lsRcafSjNT8DeGxD+hF\n5boiUhwqzTA8NPbWeQ+SSSmbrCX7XV/M1uvakWnllHmEZkPOgcJ/QFUFpDaDa9ZRkd+WCBVUkUJk\n0LmUz/sHqVRQRjoRyom4R+McNIHt8/5JOmWUkknz/DVsvmUAmZtXUJrVhazL3qMyvzUpVEXHyv+K\n8hs6kFq5lSpLJRJJg4rt0CkPzp3N9vxs0imjjHSa5ZfAHXnwxXJo1w0mFdQYe9Vve3NARTFbLYv9\nsjtR+t/1pG77ks1t+tB803LSyzdSlrY/za7+jOduu4BuX73O8tZHc+LFd1F8yzCyNxdRktWLnMvm\n8NXtx5D15UI2t+lD64teqfFYa+4dG9r/Q/7YEzathpYd4NLFO/a5dt2hxQGsWbUS1i8N9tca+2R8\nGUJ1NR53+lnw8evQ9Wg4/YEar4WQhLY1yolx1Cf+tfN5QWgd2bIOvli6e2P1HF1/+11Q5/vBXmTu\nnpyBzYYC+e5+Qqx8FYC7/z6uzaxYm7fMLBVYA2R7HUHl5eV5QUHBLsUyu2gtFz40n7LKKi6NTGNS\n6lOYQfWjVN9/Le0Ifr55UtDvbxm3c7y/HdSvTuvEQRUrg/qPe/6S7y86htLySn6TNp3zU54M2i5p\nO4JD1s/Q+d+eAAAMU0lEQVQh08oo9XSKsoaSu/m1UH3PTXOhvBTSMllzwPc4sPj5oP7tnLM557NR\nlJZXkpkW4fbxA3bsCC9NgTl/3LGCvU6GpS8EY1WWl5LiO9aryqizHL8NEusSb+sbyyw6XoP6VkFK\nys7LibfxcdYYu5a+8Sqpe73qHLuedd7ZNqjtcasMIvFxWSopVRVBfbmlkuYVDYpzu6XTzMuC8jpr\nwwH+ZVAutUwyvTQoV6Skk1q1o31ZJJP0yh31a3NG7UgM1QmhWnoLKNsS2qbxcW1om0vrL+fvqOw0\nGFa+W/PFCGzO6kqLTR8HfbdlHkjmtrU7rV9x6C93JIbpZ0HRUzsGa9khHGe77tE38WrDLq37zXzx\nTHj8nOhrJyU1+k/EzuzKWGmZcMp9ey0xzC5ay0WPvFf7+0EDmVmhu+fV1y6Zp486AivjysWxZbW2\ncfcKYCPQNnEgM5toZgVmVlBSUrLLgcxZWkJZZfT/2OMi84MXrRmh+33L3w/1G+QLQ/UHVBSH6pt/\nMpvS8koAjrHCUNsOX75DppUBkGlldN1SUKOe8tLogvJSWq6ZG6o/cPXLwdil5ZXMWRq33kueC6/g\nx6+HxkohvF71lUN1Hi4n3tY3VrVa+yaMXf0mvrNy4m2dcdXSN15tcTZ47MS4G7gNanvcxBdcSiwB\nVNenJZTrirM6IVSXs2MJobqcSWmonJrQPr0qXN9yzdwdgcW/0UKNhJAYV9aXC8OVq96v0b5a5uYV\n4fWISwi11Tf/ZPaOyo9fDw+WGOcXy8PlxNdKouUv73jt1JUQdnWs8tJoeS+Zs7Rk5+8He1kyk0It\nL00SjwAa0gZ3v8fd89w9Lzs7e5cDGdY9m/RIdFVfrMwN/uNyJ3T/g7R+oX7zrE+ofl1qTqh+a+eR\nZKZF/+97xQeG2q5uM4RSTweg1NP5uEVejXrSMqML0jLZ1P6IUP3aDscGY2emRRjWPW69qw/Hq3U9\nOjRWFeH1qq8cqrNwOfG2vrGq1do3YeyqqrrLibd1xlVL33i1xdngsRPjbuA2qO1xq0iot9RQfXlC\nua44t1t6qFxibULlUjJD5YqE9mUp4fpN7Y/YEVjLDuFA01uQKL7v5jZ9wpUH9avRvlppVpfwemQc\nWGf91s4jd1R2PTo8WGKc7bqFy4mvlUTdjt3x2kmp52z6royVlhkt7yXDumfv/P1gL0tmUigGOsWV\nc4BVO2sTO320P/Dl3g5kZK8DufMnuRzTI5t/Zp7JXZUns7iqE8+3+Qlrc0axJbIfa3NGMfya5xh4\nSGvSI8bAQ1pzQv4s5md9j69owfys73HQNR9GDyEP6AXDLqXruJu4ffwAzhp6CN3H/4EVh/6SNRnd\nWHHoL+l50RMsOeo23m53CkuOuo2Bl8/g7Zyz+TjlEN7OOZueFz0RPbwcNAFOuY/2E6aF+g+d8Odg\n7BqHiiOuC8XB6Q+Exorkb6TKDAeqzKLn8iPpOFAZSY/VE6sndD+xjkET6qxPLFdSS1+PbxsX1w0b\nqTTDPXrNIHJDwmMf0CvoX2lWI65Sy8SBTSktidywkVJPi77ZeSS6Lapf5KnNotvAUmP9U2DQBCpi\n5TJLD+KoHrvMotur1DKJ5G9kS8uuVGJsadk1th4pwViR/I1UpDaPllNSITUTSIFOg4nkbwzGKrPo\ntqdd92h9u+5Erl8fGjs9fz2r0zpRgbEppSUc0IttmQdSThob2uZSlr5/dKz0/cnIL+H5Nj/hP0T3\n5QPzV/B5y75sJ5XPW/alef4aNrTNDfqmXV8Seqxm160J7f+hawqXLt7xhtuyA/zvqh37XK+TYdAE\n1uaMCvbX1he9Et4nz50dLsfdz7rsvdDjZl75n+iYGa2h18lkXfZe6LUQuqZw+gOhtly6OFyeVBB+\n3PquA/QcveO1c/q/aqwjvU7evbH24qkjiL6H7fT9YC9L5jWFVOA/wAjgc2AecIa7L4prcyHQx91/\nGbvQ/GN3P72ucXfnmoKIyLddQ68pJO3TR+5eYWaTgFlEr63d5+6LzGwKUODuM4C/A/8ys2VEjxDG\nJSseERGpX9KSAoC7zwRmJiy7Lu7+NuC0ZMYgIiINp280i4hIQElBREQCSgoiIhJQUhARkYCSgoiI\nBJQUREQkkLQvryWLmZUAn+5G13bAF3s5nL1Bce2aphoXNN3YFNeuaapxwZ7Fdoi71zs/xtcuKewu\nMytoyLf59jXFtWuaalzQdGNTXLumqcYF+yY2nT4SEZGAkoKIiAS+TUnhnsYOYCcU165pqnFB041N\nce2aphoX7IPYvjXXFEREpH7fpiMFERGpxzc+KZjZKDNbYmbLzOzKRo7lPjNbZ2Yfxi1rY2azzWxp\n7LZ1I8TVycxeMbOPzGyRmV3cFGIzswwze9fM3o/FNTm2vIuZvROLa5qZpe/LuOLii5jZe2b2TFOJ\ny8w+MbOFZrbAzApiyxp9H4vF0crMHjOzxbF9bWhjx2ZmPWLbqvrvv2Z2SWPHFYvt17H9/kMzeyT2\nekj6PvaNTgpmFgHuBE4EegHjzaxXI4Z0PzAqYdmVwEvu3h14KVbe1yqAS939UOBw4MLYdmrs2LYD\nx7p7P6A/MMrMDgduAm6NxfUVcO4+jqvaxcBHceWmEtcx7t4/7qOLjf08VrsNeN7dewL9iG67Ro3N\n3ZfEtlV/YCCwFfh3Y8dlZh2Bi4A8d+9N9DdpxrEv9jF3/8b+AUOBWXHlq4CrGjmmzsCHceUlQIfY\n/Q7Akiaw3Z4CRjal2IDmwHxgCNEv76TW9hzvw3hyiL5ZHAs8Q/T3xptCXJ8A7RKWNfrzCOwHrCB2\nHbMpxRYXy/HAm00hLqAjsBJoQ/R3b54BTtgX+9g3+kiBHRu2WnFsWVNyoLuvBojdHtCYwZhZZ2AA\n8A5NILbYKZoFwDpgNrAc2ODuFbEmjfWc/hn4DVAVK7dtInE58IKZFZrZxNiyRn8ega5ACfCP2Cm3\n/zOzFk0ktmrjgEdi9xs1Lnf/HLgF+AxYDWwECtkH+9g3PSlYLcv0caudMLMs4HHgEnf/b2PHA+Du\nlR49tM8BBgOH1tZsX8ZkZicB69y9MH5xLU0bY1870t1ziZ4yvdDMjm6EGGqTCuQCd7v7AGALjXca\nq4bYufkxwKONHQtA7BrGyUAX4CCgBdHnNNFe38e+6UmhGOgUV84BVjVSLDuz1sw6AMRu1zVGEGaW\nRjQhPOTuTzSl2ADcfQPwKtFrHq3MrPqnZBvjOT0SGGNmnwBTiZ5C+nMTiAt3XxW7XUf03Phgmsbz\nWAwUu/s7sfJjRJNEU4gNom+48919bazc2HEdB6xw9xJ3LweeAI5gH+xj3/SkMA/oHrtin0708HBG\nI8eUaAbws9j9nxE9n79PmZkBfwc+cvc/NZXYzCzbzFrF7mcSfaF8BLwCnNpYcbn7Ve6e4+6die5T\nL7v7Txo7LjNrYWYtq+8TPUf+IU1gH3P3NcBKM+sRWzQCKGoKscWMZ8epI2j8uD4DDjez5rHXZ/X2\nSv4+1lgXdfbhBZvRwH+Inou+upFjeYTo+cFyov85nUv0XPRLwNLYbZtGiOsoooehHwALYn+jGzs2\noC/wXiyuD4HrYsu7Au8Cy4ge7jdrxOd0OPBMU4gr9vjvx/4WVe/vjf08xsXXHyiIPZ9PAq2bQmxE\nP8SwHtg/bllTiGsysDi27/8LaLYv9jF9o1lERALf9NNHIiKyC5QUREQkoKQgIiIBJQUREQkoKYiI\nSEBJQWQXmNmPzMzNrGdjxyKSDEoKIrtmPPAG0S+tiXzjKCmINFBsbqgjiX7pcFxsWYqZ3RWb9/4Z\nM5tpZqfG6gaa2WuxyelmVU+bINKUKSmINNwPif4ewH+AL80sF/gx0enQ+wC/IDqdcfVcUn8BTnX3\ngcB9wO8aI2iRXZFafxMRiRlPdOI7iE6ENx5IAx519ypgjZm9EqvvAfQGZkenriFCdIoTkSZNSUGk\nAcysLdHZUHubmRN9k3eiM5HW2gVY5O5D91GIInuFTh+JNMypwAPufoi7d3b3TkR/SewL4JTYtYUD\niU6QB9Ff7so2s+B0kpkd1hiBi+wKJQWRhhlPzaOCx4n+AEox0Zks/0b0F+s2unsZ0URyk5m9T3Tm\n2SP2Xbgiu0ezpIrsITPLcvfNsVNM7xL99bM1jR2XyO7QNQWRPfdM7MeA0oEblBDk60xHCiIiEtA1\nBRERCSgpiIhIQElBREQCSgoiIhJQUhARkYCSgoiIBP4/xvXXVfGhUk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1ff7e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = Final.iloc[:,:]\n",
    "y = training_data.iloc[:,0]\n",
    "survived = Final.loc[y == 1]\n",
    "not_survived = Final.loc[y == 0]\n",
    "plt.scatter(survived.iloc[:, 1], survived.iloc[:, 5], s=10, label='survived')\n",
    "plt.scatter(not_survived.iloc[:, 1], not_survived.iloc[:, 5], s=10, label='Not survived')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Gender')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a200c6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = Final.iloc[:,:]\n",
    "y = training_data.iloc[:,0]\n",
    "survived = Final.loc[y == 1]\n",
    "not_survived = Final.loc[y == 0]\n",
    "plt.scatter(survived.iloc[:, 1], survived.iloc[:, 4], s=10, label='survived')\n",
    "plt.scatter(not_survived.iloc[:, 1], not_survived.iloc[:, 4], s=10, label='Not survived')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Fare')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8FdW5//HPQ0DuyC0V5NKgpVgEiRhARKxHqFCk0FYQ\nUAu1HvF4OeLvWCv21Sq1R3+t2J8t3qoerPSIXL1hoSpUUZQWJQiiXApolRQUlEu5Q8jz+2MmkITJ\nJiaZvTfZ3/frldeetWbtmSfjmIc1a2aNuTsiIiJl1Up1ACIikp6UIEREJJIShIiIRFKCEBGRSEoQ\nIiISSQlCREQiKUGIiEgkJQgREYmkBCEiIpFqpzqAqmjZsqXn5OSkOgwRkRNKfn7+5+6efbx2J3SC\nyMnJYenSpakOQ0TkhGJmH1eknS4xiYhIJCUIERGJpAQhIiKRTugxCBFJT4cOHaKgoID9+/enOpSM\nVq9ePdq2bUudOnUq9X0lCBGpdgUFBTRu3JicnBzMLNXhZCR354svvqCgoIAOHTpUahu6xCQi1W7/\n/v20aNFCySGFzIwWLVpUqReX0T2I66cuY/H6rZz3tWwevqJ7qsMRqVGUHFKvqv8NMrYHcf3UZcxb\nuZkd+wqZt3Iz109dluqQRETSSsYmiMXrtyYsi4iUNGfOHH71q19Vy7YaNWpULduJW6wJwsz+YWYr\nzWy5mS0N65qb2XwzWxd+Ngvrzcwmmdl6M3vPzGK95nPe17ITlkUk8xQWFpa7bsiQIYwfPz6J0aRe\nMnoQ/+buue6eF5bHA39x947AX8IywLeBjuHPWOCROIN6+IruDOramqb1azOoa2uNQYjUIHv27OGS\nSy6hW7dudOnShRkzZpCTk8Pnn38OwNKlS7nwwgsBmDBhAmPHjuXiiy9m9OjR9OrViw8++ODIti68\n8ELy8/N58sknufHGG9m5cyc5OTkUFRUBsHfvXtq1a8ehQ4fYsGEDAwcO5JxzzqFv376sWbMGgI8+\n+ojevXvTo0cPfv7znyf3YFRBKi4xDQWmhMtTgO+WqP+jB/4GNDWz1nEG8vAV3Vl+5wAlB5E0MH/V\nZ9zxwvvMX/VZlbf10ksvceqpp7JixQref/99Bg4cmLB9fn4+L7zwAk8//TQjR45k5syZAGzevJlN\nmzZxzjnnHGl78skn061bN15//XUAXnzxRQYMGECdOnUYO3YsDzzwAPn5+dx3331cf/31AIwbN47r\nrruOd955h1atWlX590uWuBOEA6+YWb6ZjQ3rTnH3zQDh51fC+jbAxhLfLQjrRKSGm7/qM26a9i5/\n/OvH3DTt3Sonia5du7JgwQJuu+02Fi1axMknn5yw/ZAhQ6hfvz4Al112GbNmzQJg5syZDB8+/Jj2\nI0aMYMaMGQBMnz6dESNGsHv3bhYvXszw4cPJzc3l2muvZfPmzQC89dZbjBo1CoAf/OAHVfrdkinu\n21z7uPsmM/sKMN/M1iRoG3U/lh/TKEg0YwHat29fPVGKSEotWreVfYcOA7Dv0GEWrdvKtzqfUunt\nff3rXyc/P5958+Zx++23c/HFF1O7du0jl4XKPhvQsGHDI8tt2rShRYsWvPfee8yYMYNHH330mO0P\nGTKE22+/nW3btpGfn89FF13Enj17aNq0KcuXL4+M6US87TfWHoS7bwo/twDPAT2Bz4ovHYWfW8Lm\nBUC7El9vC2yK2OZj7p7n7nnZ2RpYFqkJ+nbMpn6dLADq18mib8eq/b+9adMmGjRowJVXXsmPf/xj\nli1bRk5ODvn5+QA888wzCb8/cuRI7r33Xnbu3EnXrl2PWd+oUSN69uzJuHHjGDx4MFlZWTRp0oQO\nHToc6X24OytWrACgT58+TJ8+HYCpU6dW6XdLptgShJk1NLPGxcvAxcD7wBxgTNhsDPBCuDwHGB3e\nzXQusLP4UpSI1Gzf6nwKk0adzejeX2XSqLOr1HsAWLlyJT179iQ3N5e7776bn/3sZ9x5552MGzeO\nvn37kpWVlfD7w4YNY/r06Vx22WXlthkxYgRPPfUUI0aMOFI3depUJk+eTLdu3TjzzDN54YXgz9vv\nfvc7HnroIXr06MHOnTur9Lslk7kfcxWnejZsdhpBrwGCS1lPu/vdZtYCmAm0Bz4Bhrv7Ngv6Xw8C\nA4G9wFXunvBtQHl5ea4XBomkn9WrV/ONb3wj1WEI0f8tzCy/xJ2l5YptDMLdPwS6RdR/AfSLqHfg\nhrjiERGRLydjn6QWEZHElCBERCSSEoSIiERSghARkUhKECIiEkkJQkRqJDPjlltuOVK+7777mDBh\nQsLvPP/886xatSrmyEobNGgQO3bsqPJ2JkyYwH333VcNER2lBCEiNVLdunV59tlnj8zgWhFxJYjD\nhw+Xu27evHk0bdq02vdZHZQgRKRGql27NmPHjuX+++8/Zt3HH39Mv379OOuss+jXrx+ffPIJixcv\nZs6cOdx6663k5uayYcOGUt+ZNWsWXbp0oVu3blxwwQUAR6YALzZ48GAWLlwIBNNx3HHHHfTq1Yt7\n7rmn1FPZCxcu5Dvf+Q7AkWnIb7vtNh5++OEjbSZMmMBvfvMbACZOnEiPHj0466yzuPPOO4+0ufvu\nu+nUqRP9+/dn7dq1VTxix8rod1KLSBpZMw82vAqnXwRnDKqWTd5www2cddZZ/OQnPylVf+ONNzJ6\n9GjGjBnDE088wU033cTzzz/PkCFDGDx4MMOGDTtmW3fddRcvv/wybdq0qdAloT179tClSxfuuusu\nCgsLOe2009izZw8NGzZkxowZpabogGD+p5tvvvnIFOEzZ87kpZde4pVXXmHdunW8/fbbuDtDhgzh\njTfeoGHDhkyfPp13332XwsJCunfvXmpa8uqgHoSIpN6aefDMj+Cdx4PPNfOqZbNNmjRh9OjRTJo0\nqVT9X//6Vy6//HIgmH77zTffPO62+vTpww9/+EMef/zxhJeMimVlZXHppZcCQW9m4MCBvPjiixQW\nFjJ37lyGDh1aqv3ZZ5/Nli1b2LRpEytWrKBZs2a0b9+eV155hVdeeYWzzz6b7t27s2bNGtatW8ei\nRYv43ve+R4MGDWjSpAlDhgyp6GGpMPUgRCT1NrwKh/YFy4f2BeVq6kXcfPPNdO/enauuuqrcNhWZ\nivv3v/89S5YsYe7cueTm5rJ8+fJSU4hD6WnE69WrV2pSwBEjRvDQQw/RvHlzevToQePGjY/Zx7Bh\nw5g9ezaffvopI0eOBIJZYW+//XauvfbaUm1/+9vfxj6FuHoQIpJ6p18EdYIX9lCnflCuJs2bN+ey\nyy5j8uTJR+rOO++8UtNvn3/++QA0btyYXbt2RW5nw4YN9OrVi7vuuouWLVuyceNGcnJyWL58OUVF\nRWzcuJG333673DguvPBCli1bxuOPP37M5aViI0eOZPr06cyePfvIZa4BAwbwxBNPsHv3bgD++c9/\nsmXLFi644AKee+459u3bx65du3jxxRe//ME5DvUgRCT1zhgElz5R7WMQxW655RYefPDBI+VJkybx\nox/9iIkTJ5Kdnc0f/vAHIPgDfc011zBp0iRmz57N6aeffuQ7t956K+vWrcPd6devH926BXORdujQ\nga5du9KlSxe6dy//9cVZWVkMHjyYJ598kilTpkS2OfPMM9m1axdt2rShdevgjcsXX3wxq1evpnfv\n3kAw+P3UU0/RvXt3RowYQW5uLl/96lfp27dv1Q5ShNim+04GTfctkp403Xf6qMp037rEJCIikZQg\nREQkkhKEiMTiRL58XVNU9b+BEoSIVLt69erxxRdfKEmkkLvzxRdfUK9evUpvQ3cxiUi1a9u2LQUF\nBWzdujXVoWS0evXq0bZt20p/XwlCRKpdnTp16NChQ6rDkCrSJSYREYmkBCEiIpGUIEREJJIShIiI\nRFKCEBGRSEoQIiISSQlCREQiKUGIiEgkJQgREYmkBCEiIpFiTxBmlmVm75rZn8JyBzNbYmbrzGyG\nmZ0U1tcNy+vD9TlxxyYiIuVLRg9iHLC6RPnXwP3u3hHYDlwd1l8NbHf3rwH3h+1ERCRFYk0QZtYW\nuAT4n7BswEXA7LDJFOC74fLQsEy4vl/YXkREUiDuHsRvgZ8ARWG5BbDD3QvDcgHQJlxuA2wECNfv\nDNuXYmZjzWypmS3VVMIiIvGJLUGY2WBgi7vnl6yOaOoVWHe0wv0xd89z97zs7OxqiFRERKLE+T6I\nPsAQMxsE1AOaEPQomppZ7bCX0BbYFLYvANoBBWZWGzgZ2BZjfCIikkBsPQh3v93d27p7DjASeNXd\nrwBeA4aFzcYAL4TLc8Iy4fpXXe8rFBFJmVQ8B3Eb8F9mtp5gjGFyWD8ZaBHW/xcwPgWxiYhIKCmv\nHHX3hcDCcPlDoGdEm/3A8GTEIyIix6cnqUVEJJIShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEgk\nJQgREYmkBCEiIpGUIEREJJIShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEgkJQgREYmkBCEiIpGU\nIEREJJIShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEgkJQgREYmkBCEiIpGUIEREJJIShIiIRFKC\nEBGRSEoQIiISSQlCREQixZYgzKyemb1tZivM7AMz+0VY38HMlpjZOjObYWYnhfV1w/L6cH1OXLGJ\niMjxxdmDOABc5O7dgFxgoJmdC/wauN/dOwLbgavD9lcD2939a8D9YTsREUmR2BKEB3aHxTrhjwMX\nAbPD+inAd8PloWGZcH0/M7O44hMRkcRiHYMwsywzWw5sAeYDG4Ad7l4YNikA2oTLbYCNAOH6nUCL\nOOMTEZHyxZog3P2wu+cCbYGewDeimoWfUb0FL1thZmPNbKmZLd26dWv1BSsiIqUk5S4md98BLATO\nBZqaWe1wVVtgU7hcALQDCNefDGyL2NZj7p7n7nnZ2dlxhy4ikrHivIsp28yahsv1gf7AauA1YFjY\nbAzwQrg8JywTrn/V3Y/pQYiISHLUPn6TSmsNTDGzLIJENNPd/2Rmq4DpZvbfwLvA5LD9ZOB/zWw9\nQc9hZIyxiYjIccSWINz9PeDsiPoPCcYjytbvB4bHFY+IiHw5epJaREQiKUGIiEgkJQgREYlUoQRh\ngSvN7I6w3N7MjhlHEBGRmqOiPYiHgd7AqLC8C3golohERCQtVPQupl7u3t3M3gVw9+3Fs7CKiEjN\nVNEexKHweQaH4CE4oCi2qEREJOUqmiAmAc8BXzGzu4E3gXtiiypJZt17LWvu6MKse69NdSgiImmn\nQpeY3H2qmeUD/Qgm1fuuu6+ONbKYzbr3WobtmY7Vgk57pjPrXhj+k0dTHZaISNo4boIws1rAe+7e\nBVgTf0jJ0XX3W1jYfzILyiIictRxLzG5exGwwszaJyGepFnZqA/FUwG6B2URETmqoncxtQY+MLO3\ngT3Fle4+JJaokmD4Tx5l1r1Bz2Floz66vCQiUkZFE8QvYo0iRYqTwhkpjkNEJB1VdJD69bgDSYXl\n859m/9oF1OvUn9xvXZ7qcERE0kqFEoSZnQs8QPDK0JOALGCPuzeJMbZYLZ//NJ3eHEd9O8i+rS+y\nHJQkRERKqOhzEA8STLOxDqgP/HtYd8Lav3YB9e0gAPXtIPvXLkhxRCIi6aXCs7m6+3ogy90Pu/sf\ngAtjiyoJ6nXqzz4PZgvZ5ydRr1P/FEckIpJeKjpIvTece2m5md0LbAYaxhdW/HK/dTnLQWMQIiLl\nMC9+GCBRI7OvAp8RjD/8H+Bk4OGwV5EyeXl5vnTp0lSGICJywjGzfHfPO167hD0IM2vv7p+4+8dh\n1X5q6C2vIiJS2vHGIJ4vXjCzZ2KOJekeefQBpk24jEcefSDVoYiIpJ3jjUFYieXT4gwk2R559AHG\nbLqLBnaQvZte45FH4bpr/zPVYYmIpI3j9SC8nOUTXtPNi2gQ3ubawA7SdPOiFEckIpJejteD6GZm\n/yLoSdQPlwnLfiI/KNe0WUt8WzCTqzs0bd4y1SGJiKSVhAnC3bOSFUiyfftrDeCdYNksLIuIyBEV\nflCuxjn9IqhTP1iuUz8oi4jIEZmbIM4YxJ8bfZ+/044/N/o+nDEo1RGJiKSVjE0Qjzz6AN/cNouv\ns5FvbpulW11FRMrI2AShu5hERBKLLUGYWTsze83MVpvZB2Y2LqxvbmbzzWxd+NksrDczm2Rm683s\nPTPrHldsADta92VvOFnfXj+JHa37xrk7EZETTkUn66uMQuAWd19mZo2BfDObD/wQ+Iu7/8rMxgPj\ngduAbwMdw59ewCPhZyyuu/Y/eeTRoCex49S+ekhORKSM2BKEu28mmPUVd99lZquBNsBQjk4VPgVY\nSJAghgJ/9GD2wL+ZWVMzax1uJxZBUlBiEBGJkpQxCDPLAc4GlgCnFP/RDz+/EjZrA2ws8bWCsE5E\nRFIg9gRhZo2AZ4Cb3f1fiZpG1B0zvYeZjTWzpWa2dOvWrdUVpoiIlBFrgjCzOgTJYaq7PxtWf2Zm\nrcP1rYEtYX0B0K7E19sCm8pu090fc/c8d8/Lzs6OL3gRkQwX511MBkwGVrv7/yuxag4wJlweA7xQ\non50eDfTucDOOMcfREQksTjvYuoD/ABYaWbLw7qfAr8CZprZ1cAnwPBw3TxgELAe2AtcFWNsIiJy\nHHHexfQm0eMKAP0i2jtwQ1zxiIjIl5OxT1KLiEhiShAiIhJJCUJERCIpQYiISCQlCBERiaQEISIi\nkTI6QUx8eS0D7n+diS+vTXUoIiJpJ84H5dLaxJfX8tBr6wFY+1nweeuATqkMSUQkrWRsD2LBqk8T\nlkVEMl3GJoj+nVslLIuIZLqMvcRUfDlpwapP6d+5lS4viYiUkbE9CIDe+bcwbccoeuffkupQRETS\nTsYmiDfvGUyfA4tobnvoc2ARb94zONUhiYiklYxNEJ0PLMPCuWbNgrKIiByVsQliWa2z8PCFpu5B\nWUREjsrYBDGxye3MPdyTbd6QuYd7MrHJ7akOSUQkrWTsXUz9O7fixtduhsKgfINucxURKSVjE8St\nAzpRuGoubbf9lYLmvbl1wCWpDklEJK1kbIJ4dtrjjNvxf2mQdZC9Oxby7LTGfH/UNakOS0QkbWTs\nGMTe1fNpYAcBaGAH2bt6foojEhFJLxmbIF4/3IW9fhIAe/0kXj/cJcURiYikl4y9xLStbX9u2gjn\n11rJm0Vd2d6uf6pDEhFJKxnbg3jmuvPY3q4/9/hVbG/Xn2euOy/VIYmIpJWMTRAiIpJYxiaISx9Z\nTP7H2zl42Mn/eDuXPrI41SGJiKSVjE0QKwt2JCyLiGS6jB2k7tq2Kc02Ljg6SN1Wg9QiIiVlbIK4\noukHXPLp76hrhYzyV5nbtDWggWoRkWIZe4mp+Zqp1LVgIqa6VkjzNVNTHJGISHqJLUGY2RNmtsXM\n3i9R19zM5pvZuvCzWVhvZjbJzNab2Xtm1j2uuIo19x0JyyIimS7OHsSTwMAydeOBv7h7R+AvYRng\n20DH8Gcs8EiMcQGQVcsSlkVEMl1sCcLd3wC2lakeCkwJl6cA3y1R/0cP/A1oamat44oN4FC9lgnL\nIiKZLtljEKe4+2aA8PMrYX0bYGOJdgVhXXzOuYoDHozRH/DacM5Vse5OROREky53MUVd3/HIhmZj\nCS5D0b59+0rvMPdbl7Mc2L92AfU69Sf3W5dXelsiIjVRsnsQnxVfOgo/t4T1BUC7Eu3aApuiNuDu\nj7l7nrvnZWdnVymYX67PYfTmYfxyfU6VtiMiUhMlO0HMAcaEy2OAF0rUjw7vZjoX2Fl8KSoulz6y\nmGYbF/BT+wPNNi7QVBsiImXEdonJzKYBFwItzawAuBP4FTDTzK4GPgGGh83nAYOA9cBeIPYBgWYb\nFzCpzgM0sINc5gu5aSPoQTkRkaNiSxDuPqqcVf0i2jpwQ1yxRDm/1spSb5Q7v9bKZO5eRCTtZeyT\n1Lu8Ph4Og7sHZREROSpjE0SXWh9j4b1TZkFZRESOytgEcTZ/T1gWEcl06fIcRNI1qrU3YVmk0h7M\ng883QMvT4calqY5GpNIytgdxwE9KWBaplAfz4PN1QFHw+WBeqiMSqbSMTRCveW6pQerXPDe1AUnN\n8PmGxGWRqvh1Dkw4OfhMgoxNEDtrNSs1SL2zVrPUBiQ1Q8vTj8wR42FZpFr8Ogf2bQ+W921PSpLI\n2ASxmwalehC7aZDagKRGmNhxKusPt6bQjfWHWzOxo15EJdWkODmUV45Bxg5SZ9fejx0Ols0gO2t/\nagOSGmHBqk956NBvjpQ7rfqUWwd0SmFEUmPUb1Y6KdSP/6pHxvYgzsz6uFQP4swsPQchVde/c6uE\nZZFKu+0fR5NC/WZBOWYZ24NofXBjqTGI1gc3Jv6CSAUU9xYWrPqU/p1bqfcg1eqpw/04p2gJ+Yd7\ncWUS9pexCWLt4Vbk1dqFWdCDWFvUih6pDkpqhFsHdFJikGr31D1Xc8WB2VgtOOPARp66B6786eRY\n95mxl5i62Eelp9qwj1IbkIhIAufsX1Lqb9Y5+5fEvs+MTRD1rDBhWUQkneTX61Vq3DS/Xq/Y95mx\nCaLs+0wj328qIpImrqz71tGXM1tYjlnGjkFsrXMqpxRuKl1OYTxSczw77XGyPnqNwx3+je+PuibV\n4UhNsWtzyfwAu2J96SaQwT2IU3qPKvXE6ym9y3u/kUjFPTvtcS5ZM56hB+dyyZrxPDvt8VSHJDVF\n49aJyzHI2ASxadncUtl407K5qQxHaojma6ZSNxzPqmuFNF+jJ6nlxJWxCaL+nk0JyyKVkVP0z4Rl\nkUore0lJl5jiU5cDCcsilVG7VlHCskil1apdeiLIWvEPIWdugvADCcsilbG+ztdL3Yq4vs7XUxuQ\n1BhFRYWlLosXFcV/a37GJgg7TlmkMooO7C31MFPRAb2pUKpHKv5mKUGUUxapjG+yPGFZ5ESSsQlC\nJA61aiUui5xIMvb0dU9cFqmMIk9cFqm0FEz/kLEJotbl00oNJta6fFpqA5Ia4bBlJSyLnEgyNkFw\nxiBs1DTocU3wecagVEckNcCKotNK/cNjRdFpqQ1IpAoydi4mIEgKSgxSjbqzLmFZ5ESSuT0IkRjU\nqkWp21w1SC0nssw+fdfMg7k/Dj5FRKSUtEoQZjbQzNaa2XozGx/rztbMg2d+BO88HnwqSUg1KCqi\n1BhEkWbakBNY2iQIM8sCHgK+DXQGRplZ59h2uOFVOLQvWD60LyiLVFHWL3ceSRJFRUFZ5ESVNgkC\n6Amsd/cP3f0gMB0YGtve1vwpcVmkMn5zBllZwfhDVlZQFqkOqXh2K50SRBtgY4lyQVhXipmNNbOl\nZrZ069atld/brs8Sl0UqIwVTMktmOJhVP2E5DumUIKKmQzomR7r7Y+6e5+552dnZld9by9MTl0Uq\nIwVv/ZLMsOPUb5Ya39px6jdj32c6JYgCoF2Jclsgvrf43LgUWnYEagWfNy6NbVeSQW5ZczQpNG4d\nlEWqQatrZvBZ24HsyWrCZ20H0uqaGbHv0zxNJiEys9rA34F+wD+Bd4DL3f2D8r6Tl5fnS5fqD7uI\nyJdhZvnunne8dmnzJLW7F5rZjcDLQBbwRKLkICIi8UqbBAHg7vMAPZAgIpIG0mkMQkRE0ogShIiI\nRFKCEBGRSEoQIiISSQlCREQiKUGIiEiktHlQrjLMbCvwcRU30xL4vBrCqW7pGFc6xgTpGVc6xgSK\n68tIx5igeuL6qrsfd66iEzpBVAczW1qRJwqTLR3jSseYID3jSseYQHF9GekYEyQ3Ll1iEhGRSEoQ\nIiISSQkCHkt1AOVIx7jSMSZIz7jSMSZQXF9GOsYESYwr48cgREQkmnoQIiISqcYmCDN7wsy2mNn7\n5aw3M5tkZuvN7D0z615i3RgzWxf+jEliTFeEsbxnZovNrFuJdf8ws5VmttzMqvUlGBWI60Iz2xnu\ne7mZ3VFi3UAzWxsex/FJjuvWEjG9b2aHzax5uC6W42Vm7czsNTNbbWYfmNm4iDapOLcqEldSz68K\nxpT0c6uCcaXi3KpnZm+b2Yowrl9EtKlrZjPCY7LEzHJKrLs9rF9rZgOqJSh3r5E/wAVAd+D9ctYP\nAv5M8KrTc4ElYX1z4MPws1m43CxJMZ1XvC/g28UxheV/AC1TdKwuBP4UUZ8FbABOA04CVgCdkxVX\nmbbfAV6N+3gBrYHu4XJjgpdcdS7TJhXnVkXiSur5VcGYkn5uVSSuFJ1bBjQKl+sAS4Bzy7S5Hvh9\nuDwSmBEudw6PUV2gQ3jssqoaU43tQbj7G8C2BE2GAn/0wN+ApmbWGhgAzHf3be6+HZgPDExGTO6+\nONwnwN8IXrsauwocq/L0BNa7+4fufhCYTnBcUxHXKGBade27PO6+2d2Xhcu7gNVAmzLNUnFuHTeu\nZJ9fFTxW5Ynt3KpEXMk6t9zdd4fFOuFP2UHiocCUcHk20M/MLKyf7u4H3P0jYD3BMaySGpsgKqAN\nsLFEuSCsK68+2a4m+FdoMQdeMbN8Mxubgnh6h13fP5vZmWFdWhwrM2tA8If2mRLVsR+vsHt/NsG/\n9EpK6bmVIK6Sknp+HSemlJ1bxztWyT63zCzLzJYDWwj+MVHuueXuhcBOoAUxHa+0eqNckllEnSeo\nTxoz+zeC/4HPL1Hdx903mdlXgPlmtib8F3YyLCN4NH+3mQ0Cngc6kgbHKvQd4C13L9nbiPV4mVkj\ngj8aN7v7v8qujvhKUs6t48RV3Cap59dxYkrZuVWRY0WSzy13PwzkmllT4Dkz6+LuJcfgknpuZXIP\nogBoV6LcFtiUoD4pzOws4H+Aoe7+RXG9u28KP7cAz1EN3ceKcvd/FXd9PXgtbB0za0mKj1UJIylz\nCSDO42VmdQj+sEx192cjmqTk3KpAXEk/v44XU6rOrYocq1BSz60S+9gBLOTYS5BHjouZ1QZOJrgM\nG8/xqq4BlnT8AXIof+D1EkoPJL4d1jcHPiIYRGwWLjdPUkztCa4dnlemviHQuMTyYmBgEo9VK44+\nM9MT+CQ8brUJBlo7cHQg8cxkxRWuL/4fpGEyjlf4e/8R+G2CNkk/tyoYV1LPrwrGlPRzqyJxpejc\nygaahstv7ZznAAAC5UlEQVT1gUXA4DJtbqD0IPXMcPlMSg9Sf0g1DFLX2EtMZjaN4A6JlmZWANxJ\nMOiDu/8emEdwt8l6YC9wVbhum5n9Engn3NRdXrp7GWdMdxBcT3w4GHei0INJuU4h6G5C8D/O0+7+\nUnXEVMG4hgHXmVkhsA8Y6cFZWWhmNwIvE9x18oS7f5DEuAC+B7zi7ntKfDXO49UH+AGwMrxWDPBT\ngj++KTu3KhhXss+visSUinOrInFB8s+t1sAUM8siuLoz093/ZGZ3AUvdfQ4wGfhfM1tPkLxGhjF/\nYGYzgVVAIXCDB5erqkRPUouISKRMHoMQEZEElCBERCSSEoSIiERSghARkUhKECIiEkkJQiSBcBbP\n4hk9Z4VTL5TXdoKZ/TiZ8YnESQlCJLF97p7r7l2Ag8B/pDogkWRRghCpuEXA1wDMbLQF71VYYWb/\nW7ahmV1jZu+E658p7nmY2fCwN7LCzN4I684M3wOwPNxmx6T+ViLl0INyIgmY2W53bxTOe/MM8BLw\nBvAswaRtn5tZ8/Ap6QnAbne/z8xaeDjXkZn9N/CZuz9gZisJpmb4p5k1dfcdZvYA8Dd3n2pmJxFM\nkbAvJb+wSAnqQYgkVj+cjmEpwTxBk4GLgNnu/jkEU2hEfK+LmS0KE8IVBHPlALwFPGlm1xBMIQHw\nV+CnZnYbwcymSg6SFmrsXEwi1WSfu+eWrAhf0HK8rveTwHfdfYWZ/ZBgTinc/T/MrBfBhH7LzSzX\n3Z82syVh3ctm9u/u/mo1/x4iX5p6ECJf3l+Ay8ysBYCF7youozGwOZxW+oriSjM73d2XuPsdwOdA\nOzM7DfjQ3ScBc4CzYv8NRCpAPQiRLymcOfNu4HUzOwy8C/ywTLOfE7yl7GNgJUHCAJgYDkIbQaJZ\nAYwHrjSzQ8CnwF2x/xIiFaBBahERiaRLTCIiEkkJQkREIilBiIhIJCUIERGJpAQhIiKRlCBERCSS\nEoSIiERSghARkUj/H8mEu/8oG01XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1fff8a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = Final.iloc[:,:]\n",
    "y = training_data.iloc[:,0]\n",
    "survived = Final.loc[y == 1]\n",
    "not_survived = Final.loc[y == 0]\n",
    "plt.scatter(survived.iloc[:, 0], survived.iloc[:, 4], s=10, label='survived')\n",
    "plt.scatter(not_survived.iloc[:, 0], not_survived.iloc[:, 4], s=10, label='Not survived')\n",
    "plt.xlabel('Pclass')\n",
    "plt.ylabel('Fare')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>887.000000</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>887.00000</td>\n",
       "      <td>887.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.305524</td>\n",
       "      <td>29.471443</td>\n",
       "      <td>0.525366</td>\n",
       "      <td>0.383315</td>\n",
       "      <td>32.30542</td>\n",
       "      <td>0.354002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.836662</td>\n",
       "      <td>14.121908</td>\n",
       "      <td>1.104669</td>\n",
       "      <td>0.807466</td>\n",
       "      <td>49.78204</td>\n",
       "      <td>0.478480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.92500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.45420</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.13750</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.32920</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age  Siblings/Spouses Aboard  \\\n",
       "count  887.000000  887.000000               887.000000   \n",
       "mean     2.305524   29.471443                 0.525366   \n",
       "std      0.836662   14.121908                 1.104669   \n",
       "min      1.000000    0.420000                 0.000000   \n",
       "25%      2.000000   20.250000                 0.000000   \n",
       "50%      3.000000   28.000000                 0.000000   \n",
       "75%      3.000000   38.000000                 1.000000   \n",
       "max      3.000000   80.000000                 8.000000   \n",
       "\n",
       "       Parents/Children Aboard       Fare      Gender  \n",
       "count               887.000000  887.00000  887.000000  \n",
       "mean                  0.383315   32.30542    0.354002  \n",
       "std                   0.807466   49.78204    0.478480  \n",
       "min                   0.000000    0.00000    0.000000  \n",
       "25%                   0.000000    7.92500    0.000000  \n",
       "50%                   0.000000   14.45420    0.000000  \n",
       "75%                   0.000000   31.13750    1.000000  \n",
       "max                   6.000000  512.32920    1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of people in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    216\n",
       "2    184\n",
       "3    487\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Pclass'].value_counts(sort=False, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.00    39\n",
       "28.00    37\n",
       "18.00    36\n",
       "21.00    34\n",
       "24.00    34\n",
       "19.00    33\n",
       "30.00    33\n",
       "27.00    26\n",
       "29.00    25\n",
       "23.00    25\n",
       "25.00    24\n",
       "20.00    23\n",
       "36.00    23\n",
       "26.00    21\n",
       "35.00    21\n",
       "32.00    21\n",
       "16.00    20\n",
       "31.00    19\n",
       "40.00    18\n",
       "39.00    18\n",
       "34.00    17\n",
       "33.00    17\n",
       "42.00    17\n",
       "17.00    16\n",
       "45.00    14\n",
       "37.00    12\n",
       "48.00    12\n",
       "38.00    12\n",
       "4.00     11\n",
       "2.00     11\n",
       "         ..\n",
       "66.00     2\n",
       "59.00     2\n",
       "28.50     2\n",
       "45.50     2\n",
       "0.83      2\n",
       "30.50     2\n",
       "70.00     2\n",
       "0.75      2\n",
       "10.00     2\n",
       "63.00     2\n",
       "13.00     2\n",
       "40.50     2\n",
       "32.50     2\n",
       "71.00     2\n",
       "12.00     2\n",
       "0.67      1\n",
       "0.92      1\n",
       "74.00     1\n",
       "34.50     1\n",
       "14.50     1\n",
       "24.50     1\n",
       "80.00     1\n",
       "20.50     1\n",
       "53.00     1\n",
       "69.00     1\n",
       "70.50     1\n",
       "36.50     1\n",
       "23.50     1\n",
       "55.50     1\n",
       "0.42      1\n",
       "Name: Age, Length: 89, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Age'].value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41999999999999998, 80.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(training_data['Age']), max(training_data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age<=10: 73\n",
      "10<Age<=20: 149\n",
      "20<Age<=30: 303\n",
      "30<Age<=40: 184\n",
      "40<Age<=50: 106\n",
      "50<Age<=60: 46\n",
      "60<Age<=70: 21\n",
      "70<Age<=80: 5\n",
      "Age>80: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Age<=10:\",len(np.array(np.where(Final['Age']<=10)).T))\n",
    "print(\"10<Age<=20:\",len(np.array(np.where(Final['Age']<=20)).T)-len(np.array(np.where(Final['Age']<=10)).T))\n",
    "print(\"20<Age<=30:\",len(np.array(np.where(Final['Age']<=30)).T)-len(np.array(np.where(Final['Age']<=20)).T))\n",
    "print(\"30<Age<=40:\",len(np.array(np.where(Final['Age']<=40)).T)-len(np.array(np.where(Final['Age']<=30)).T))\n",
    "print(\"40<Age<=50:\",len(np.array(np.where(Final['Age']<=50)).T)-len(np.array(np.where(Final['Age']<=40)).T))\n",
    "print(\"50<Age<=60:\",len(np.array(np.where(Final['Age']<=60)).T)-len(np.array(np.where(Final['Age']<=50)).T))\n",
    "print(\"60<Age<=70:\",len(np.array(np.where(Final['Age']<=70)).T)-len(np.array(np.where(Final['Age']<=60)).T))\n",
    "print(\"70<Age<=80:\",len(np.array(np.where(Final['Age']<=80)).T)-len(np.array(np.where(Final['Age']<=70)).T))\n",
    "print(\"Age>80:\",len(np.array(np.where(Final['Age']>80)).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    604\n",
       "1    209\n",
       "2     28\n",
       "3     16\n",
       "4     18\n",
       "5      5\n",
       "8      7\n",
       "Name: Siblings/Spouses Aboard, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Siblings/Spouses Aboard'].value_counts(sort=False, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    674\n",
       "1    118\n",
       "2     80\n",
       "3      5\n",
       "4      4\n",
       "5      5\n",
       "6      1\n",
       "Name: Parents/Children Aboard, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Parents/Children Aboard'].value_counts(sort=False, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0500      43\n",
       "13.0000     42\n",
       "7.8958      36\n",
       "7.7500      33\n",
       "26.0000     31\n",
       "10.5000     24\n",
       "7.9250      18\n",
       "7.7750      16\n",
       "26.5500     15\n",
       "0.0000      15\n",
       "7.2292      15\n",
       "7.8542      13\n",
       "8.6625      13\n",
       "7.2500      13\n",
       "7.2250      12\n",
       "16.1000      9\n",
       "9.5000       9\n",
       "24.1500      8\n",
       "56.4958      7\n",
       "15.5000      7\n",
       "52.0000      7\n",
       "14.5000      7\n",
       "14.4542      7\n",
       "69.5500      7\n",
       "7.0500       7\n",
       "31.2750      7\n",
       "46.9000      6\n",
       "30.0000      6\n",
       "7.7958       6\n",
       "39.6875      6\n",
       "            ..\n",
       "7.1417       1\n",
       "42.4000      1\n",
       "211.5000     1\n",
       "12.2750      1\n",
       "61.1750      1\n",
       "8.4333       1\n",
       "51.4792      1\n",
       "7.8875       1\n",
       "8.6833       1\n",
       "7.5208       1\n",
       "34.6542      1\n",
       "28.7125      1\n",
       "25.5875      1\n",
       "7.7292       1\n",
       "12.2875      1\n",
       "8.6542       1\n",
       "8.7125       1\n",
       "61.3792      1\n",
       "6.9500       1\n",
       "9.8417       1\n",
       "8.3000       1\n",
       "13.7917      1\n",
       "9.4750       1\n",
       "13.4167      1\n",
       "26.3875      1\n",
       "8.4583       1\n",
       "9.8375       1\n",
       "8.3625       1\n",
       "14.1083      1\n",
       "17.4000      1\n",
       "Name: Fare, Length: 248, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Fare'].value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 512.32920000000001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(training_data['Fare']), max(training_data['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fare<=5: 17\n",
      "5<Fare<=10: 316\n",
      "10<Fare<=15: 122\n",
      "15<Fare<=30: 198\n",
      "30<Fare<=50: 74\n",
      "50<Fare<=100: 107\n",
      "100<Fare<=150: 24\n",
      "150<Fare<=200: 9\n",
      "200<Fare<=513: 20\n",
      "Fare>513: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Fare<=5:\",len(np.array(np.where(Final['Fare']<=5)).T))\n",
    "print(\"5<Fare<=10:\",len(np.array(np.where(Final['Fare']<=10)).T)-len(np.array(np.where(Final['Fare']<=5)).T))\n",
    "print(\"10<Fare<=15:\",len(np.array(np.where(Final['Fare']<=15)).T)-len(np.array(np.where(Final['Fare']<=10)).T))\n",
    "print(\"15<Fare<=30:\",len(np.array(np.where(Final['Fare']<=30)).T)-len(np.array(np.where(Final['Fare']<=15)).T))\n",
    "print(\"30<Fare<=50:\",len(np.array(np.where(Final['Fare']<=50)).T)-len(np.array(np.where(Final['Fare']<=30)).T))\n",
    "print(\"50<Fare<=100:\",len(np.array(np.where(Final['Fare']<=100)).T)-len(np.array(np.where(Final['Fare']<=50)).T))\n",
    "print(\"100<Fare<=150:\",len(np.array(np.where(Final['Fare']<=150)).T)-len(np.array(np.where(Final['Fare']<=100)).T))\n",
    "print(\"150<Fare<=200:\",len(np.array(np.where(Final['Fare']<=200)).T)-len(np.array(np.where(Final['Fare']<=150)).T))\n",
    "print(\"200<Fare<=513:\",len(np.array(np.where(Final['Fare']<=513)).T)-len(np.array(np.where(Final['Fare']<=200)).T))\n",
    "print(\"Fare>513:\",len(np.array(np.where(Final['Fare']>513)).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      573\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    545\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the proportion survived in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Pclass 1 survived: 0.62962962963\n",
      "Proportion of Pclass 2 survived: 0.472826086957\n",
      "Proportion of Pclass 3 survived: 0.244353182752\n"
     ]
    }
   ],
   "source": [
    "def proportions_pclass_survived():\n",
    "    X = Final.iloc[:,:] \n",
    "    y = training_data.iloc[:,0]\n",
    "    survived = Final.loc[y == 1]\n",
    "    not_survived = Final.loc[y == 0]\n",
    "\n",
    "    S1= (np.array(np.where((survived.iloc[:, 0]==1))).shape)[1]\n",
    "    S2= (np.array(np.where((survived.iloc[:, 0]==2))).shape)[1]\n",
    "    S3= (np.array(np.where((survived.iloc[:, 0]==3))).shape)[1]\n",
    "\n",
    "    P1=np.array(Final['Pclass'].value_counts(sort=False, ascending=True))[0]\n",
    "    P2=np.array(Final['Pclass'].value_counts(sort=False, ascending=True))[1]\n",
    "    P3=np.array(Final['Pclass'].value_counts(sort=False, ascending=True))[2]\n",
    "    \n",
    "    print(\"Proportion of Pclass 1 survived:\",S1/P1)\n",
    "    print(\"Proportion of Pclass 2 survived:\",S2/P2)\n",
    "    print(\"Proportion of Pclass 3 survived:\",S3/P3)\n",
    "\n",
    "proportions_pclass_survived()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Age<=10 survived: 0.5616438356164384\n",
      "Proportion of 10<Age<=20 survived: 0.348993288590604\n",
      "Proportion of 20<Age<=30 survived: 0.3432343234323432\n",
      "Proportion of 30<Age<=40 survived: 0.43478260869565216\n",
      "Proportion of 40<Age<=50 survived: 0.4056603773584906\n",
      "Proportion of 50<Age<=60 survived: 0.3695652173913043\n",
      "Proportion of 60<Age<=70 survived: 0.19047619047619047\n",
      "Proportion of 70<Age<=80 survived: 0.2\n"
     ]
    }
   ],
   "source": [
    "def proportions_age_survived():\n",
    "    X = Final.iloc[:,:] \n",
    "    y = training_data.iloc[:,0]\n",
    "    survived = Final.loc[y == 1]\n",
    "    not_survived = Final.loc[y == 0]\n",
    "    \n",
    "    S1= (np.array(np.where((survived.iloc[:, 1]<=10))).shape)[1]\n",
    "    S2= (np.array(np.where((survived.iloc[:, 1]<=20))).shape)[1] -(np.array(np.where((survived.iloc[:, 1]<=10))).shape)[1]\n",
    "    S3= (np.array(np.where((survived.iloc[:, 1]<=30))).shape)[1] -(np.array(np.where((survived.iloc[:, 1]<=20))).shape)[1]\n",
    "    S4= (np.array(np.where((survived.iloc[:, 1]<=40))).shape)[1] -(np.array(np.where((survived.iloc[:, 1]<=30))).shape)[1]\n",
    "    S5= (np.array(np.where((survived.iloc[:, 1]<=50))).shape)[1] -(np.array(np.where((survived.iloc[:, 1]<=40))).shape)[1]\n",
    "    S6= (np.array(np.where((survived.iloc[:, 1]<=60))).shape)[1] -(np.array(np.where((survived.iloc[:, 1]<=50))).shape)[1]\n",
    "    S7= (np.array(np.where((survived.iloc[:, 1]<=70))).shape)[1] -(np.array(np.where((survived.iloc[:, 1]<=60))).shape)[1]\n",
    "    S8= (np.array(np.where((survived.iloc[:, 1]<=80))).shape)[1] -(np.array(np.where((survived.iloc[:, 1]<=70))).shape)[1]\n",
    "    \n",
    "    P1= len(np.array(np.where(Final['Age']<=10)).T)\n",
    "    P2= len(np.array(np.where(Final['Age']<=20)).T)-len(np.array(np.where(Final['Age']<=10)).T)\n",
    "    P3= len(np.array(np.where(Final['Age']<=30)).T)-len(np.array(np.where(Final['Age']<=20)).T)\n",
    "    P4= len(np.array(np.where(Final['Age']<=40)).T)-len(np.array(np.where(Final['Age']<=30)).T)\n",
    "    P5= len(np.array(np.where(Final['Age']<=50)).T)-len(np.array(np.where(Final['Age']<=40)).T)\n",
    "    P6= len(np.array(np.where(Final['Age']<=60)).T)-len(np.array(np.where(Final['Age']<=50)).T)\n",
    "    P7= len(np.array(np.where(Final['Age']<=70)).T)-len(np.array(np.where(Final['Age']<=60)).T)\n",
    "    P8= len(np.array(np.where(Final['Age']<=80)).T)-len(np.array(np.where(Final['Age']<=70)).T)\n",
    "    \n",
    "    print(\"Proportion of Age<=10 survived:\",S1/P1)\n",
    "    print(\"Proportion of 10<Age<=20 survived:\",S2/P2)\n",
    "    print(\"Proportion of 20<Age<=30 survived:\",S3/P3)\n",
    "    print(\"Proportion of 30<Age<=40 survived:\",S4/P4)\n",
    "    print(\"Proportion of 40<Age<=50 survived:\",S5/P5)\n",
    "    print(\"Proportion of 50<Age<=60 survived:\",S6/P6)\n",
    "    print(\"Proportion of 60<Age<=70 survived:\",S7/P7)\n",
    "    print(\"Proportion of 70<Age<=80 survived:\",S8/P8)\n",
    "\n",
    "proportions_age_survived()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of 0 Siblings/Spouses Aboard survived: 0.347682119205\n",
      "Proportion of 1 Siblings/Spouses Aboard survived: 0.535885167464\n",
      "Proportion of 2 Siblings/Spouses Aboard survived: 0.0622009569378\n",
      "Proportion of 3 Siblings/Spouses Aboard survived: 0.0191387559809\n",
      "Proportion of 4 Siblings/Spouses Aboard survived: 0.0143540669856\n",
      "Proportion of 5 Siblings/Spouses Aboard survived: 0.0\n",
      "Proportion of 8 Siblings/Spouses Aboard survived: 0.0\n"
     ]
    }
   ],
   "source": [
    "def proportions_Siblings_Spouses_Aboard_survived():\n",
    "    X = Final.iloc[:,:] \n",
    "    y = training_data.iloc[:,0]\n",
    "    survived = Final.loc[y == 1]\n",
    "    not_survived = Final.loc[y == 0]\n",
    "\n",
    "    S1= (np.array(np.where((survived.iloc[:, 2]==0))).shape)[1]\n",
    "    S2= (np.array(np.where((survived.iloc[:, 2]==1))).shape)[1]\n",
    "    S3= (np.array(np.where((survived.iloc[:, 2]==2))).shape)[1]\n",
    "    S4= (np.array(np.where((survived.iloc[:, 2]==3))).shape)[1]\n",
    "    S5= (np.array(np.where((survived.iloc[:, 2]==4))).shape)[1]\n",
    "    S6= (np.array(np.where((survived.iloc[:, 2]==5))).shape)[1]\n",
    "    S7= (np.array(np.where((survived.iloc[:, 2]==8))).shape)[1]\n",
    "\n",
    "    P1=np.array(Final['Siblings/Spouses Aboard'].value_counts(sort=False, ascending=True))[0]\n",
    "    P2=np.array(Final['Siblings/Spouses Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P3=np.array(Final['Siblings/Spouses Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P4=np.array(Final['Siblings/Spouses Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P5=np.array(Final['Siblings/Spouses Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P6=np.array(Final['Siblings/Spouses Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P7=np.array(Final['Siblings/Spouses Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "\n",
    "    print(\"Proportion of 0 Siblings/Spouses Aboard survived:\",S1/P1)\n",
    "    print(\"Proportion of 1 Siblings/Spouses Aboard survived:\",S2/P2)\n",
    "    print(\"Proportion of 2 Siblings/Spouses Aboard survived:\",S3/P3)\n",
    "    print(\"Proportion of 3 Siblings/Spouses Aboard survived:\",S4/P4)\n",
    "    print(\"Proportion of 4 Siblings/Spouses Aboard survived:\",S5/P5)\n",
    "    print(\"Proportion of 5 Siblings/Spouses Aboard survived:\",S6/P6)\n",
    "    print(\"Proportion of 8 Siblings/Spouses Aboard survived:\",S7/P7)\n",
    "    \n",
    "proportions_Siblings_Spouses_Aboard_survived()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of 0 Parents/Children Aboard survived: 0.345697329377\n",
      "Proportion of 1 Parents/Children Aboard survived: 0.550847457627\n",
      "Proportion of 2 Parents/Children Aboard survived: 0.338983050847\n",
      "Proportion of 3 Parents/Children Aboard survived: 0.0254237288136\n",
      "Proportion of 4 Parents/Children Aboard survived: 0.0\n",
      "Proportion of 5 Parents/Children Aboard survived: 0.00847457627119\n",
      "Proportion of 6 Parents/Children Aboard survived: 0.0\n"
     ]
    }
   ],
   "source": [
    "def proportions_Parents_Children_Aboard_survived():\n",
    "    X = Final.iloc[:,:] \n",
    "    y = training_data.iloc[:,0]\n",
    "    survived = Final.loc[y == 1]\n",
    "    not_survived = Final.loc[y == 0]\n",
    "\n",
    "    S1= (np.array(np.where((survived.iloc[:, 3]==0))).shape)[1]\n",
    "    S2= (np.array(np.where((survived.iloc[:, 3]==1))).shape)[1]\n",
    "    S3= (np.array(np.where((survived.iloc[:, 3]==2))).shape)[1]\n",
    "    S4= (np.array(np.where((survived.iloc[:, 3]==3))).shape)[1]\n",
    "    S5= (np.array(np.where((survived.iloc[:, 3]==4))).shape)[1]\n",
    "    S6= (np.array(np.where((survived.iloc[:, 3]==5))).shape)[1]\n",
    "    S7= (np.array(np.where((survived.iloc[:, 3]==6))).shape)[1]\n",
    "\n",
    "    P1=np.array(Final['Parents/Children Aboard'].value_counts(sort=False, ascending=True))[0]\n",
    "    P2=np.array(Final['Parents/Children Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P3=np.array(Final['Parents/Children Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P4=np.array(Final['Parents/Children Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P5=np.array(Final['Parents/Children Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P6=np.array(Final['Parents/Children Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "    P7=np.array(Final['Parents/Children Aboard'].value_counts(sort=False, ascending=True))[1]\n",
    "\n",
    "    print(\"Proportion of 0 Parents/Children Aboard survived:\",S1/P1)\n",
    "    print(\"Proportion of 1 Parents/Children Aboard survived:\",S2/P2)\n",
    "    print(\"Proportion of 2 Parents/Children Aboard survived:\",S3/P3)\n",
    "    print(\"Proportion of 3 Parents/Children Aboard survived:\",S4/P4)\n",
    "    print(\"Proportion of 4 Parents/Children Aboard survived:\",S5/P5)\n",
    "    print(\"Proportion of 5 Parents/Children Aboard survived:\",S6/P6)\n",
    "    print(\"Proportion of 6 Parents/Children Aboard survived:\",S7/P7)\n",
    "\n",
    "proportions_Parents_Children_Aboard_survived()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Fare<=5 survived: 0.058823529411764705\n",
      "Proportion of 5<Fare<=10 survived: 0.2088607594936709\n",
      "Proportion of 10<Fare<=15 survived: 0.38524590163934425\n",
      "Proportion of 15<Fare<=30 survived: 0.46464646464646464\n",
      "Proportion of 30<Fare<=50 survived: 0.36486486486486486\n",
      "Proportion of 50<Fare<=100 survived: 0.6542056074766355\n",
      "Proportion of 100<Fare<=150 survived: 0.7916666666666666\n",
      "Proportion of 150<Fare<=200 survived: 0.6666666666666666\n",
      "Proportion of 200<Fare<=513 survived: 0.7\n"
     ]
    }
   ],
   "source": [
    "def proportions_fare_survived():\n",
    "    X = Final.iloc[:,:] \n",
    "    y = training_data.iloc[:,0]\n",
    "    survived = Final.loc[y == 1]\n",
    "    not_survived = Final.loc[y == 0]\n",
    "    \n",
    "    S1= (np.array(np.where((survived.iloc[:, 4]<=5))).shape)[1]\n",
    "    S2= (np.array(np.where((survived.iloc[:, 4]<=10))).shape)[1] -(np.array(np.where((survived.iloc[:, 4]<=5))).shape)[1]\n",
    "    S3= (np.array(np.where((survived.iloc[:, 4]<=15))).shape)[1] -(np.array(np.where((survived.iloc[:, 4]<=10))).shape)[1]\n",
    "    S4= (np.array(np.where((survived.iloc[:, 4]<=30))).shape)[1] -(np.array(np.where((survived.iloc[:, 4]<=15))).shape)[1]\n",
    "    S5= (np.array(np.where((survived.iloc[:, 4]<=50))).shape)[1] -(np.array(np.where((survived.iloc[:, 4]<=30))).shape)[1]\n",
    "    S6= (np.array(np.where((survived.iloc[:, 4]<=100))).shape)[1] -(np.array(np.where((survived.iloc[:, 4]<=50))).shape)[1]\n",
    "    S7= (np.array(np.where((survived.iloc[:, 4]<=150))).shape)[1] -(np.array(np.where((survived.iloc[:, 4]<=100))).shape)[1]\n",
    "    S8= (np.array(np.where((survived.iloc[:, 4]<=200))).shape)[1] -(np.array(np.where((survived.iloc[:, 4]<=150))).shape)[1]\n",
    "    S9= (np.array(np.where((survived.iloc[:, 4]<=513))).shape)[1] -(np.array(np.where((survived.iloc[:, 4]<=200))).shape)[1]\n",
    "    \n",
    "    P1= len(np.array(np.where(Final['Fare']<=5)).T)\n",
    "    P2= len(np.array(np.where(Final['Fare']<=10)).T)-len(np.array(np.where(Final['Fare']<=5)).T)\n",
    "    P3= len(np.array(np.where(Final['Fare']<=15)).T)-len(np.array(np.where(Final['Fare']<=10)).T)\n",
    "    P4= len(np.array(np.where(Final['Fare']<=30)).T)-len(np.array(np.where(Final['Fare']<=15)).T)\n",
    "    P5= len(np.array(np.where(Final['Fare']<=50)).T)-len(np.array(np.where(Final['Fare']<=30)).T)\n",
    "    P6= len(np.array(np.where(Final['Fare']<=100)).T)-len(np.array(np.where(Final['Fare']<=50)).T)\n",
    "    P7= len(np.array(np.where(Final['Fare']<=150)).T)-len(np.array(np.where(Final['Fare']<=100)).T)\n",
    "    P8= len(np.array(np.where(Final['Fare']<=200)).T)-len(np.array(np.where(Final['Fare']<=150)).T)\n",
    "    P9= len(np.array(np.where(Final['Fare']<=513)).T)-len(np.array(np.where(Final['Fare']<=200)).T)\n",
    "    \n",
    "    print(\"Proportion of Fare<=5 survived:\",S1/P1)\n",
    "    print(\"Proportion of 5<Fare<=10 survived:\",S2/P2)\n",
    "    print(\"Proportion of 10<Fare<=15 survived:\",S3/P3)\n",
    "    print(\"Proportion of 15<Fare<=30 survived:\",S4/P4)\n",
    "    print(\"Proportion of 30<Fare<=50 survived:\",S5/P5)\n",
    "    print(\"Proportion of 50<Fare<=100 survived:\",S6/P6)\n",
    "    print(\"Proportion of 100<Fare<=150 survived:\",S7/P7)\n",
    "    print(\"Proportion of 150<Fare<=200 survived:\",S8/P8)\n",
    "    print(\"Proportion of 200<Fare<=513 survived:\",S9/P9)\n",
    "\n",
    "proportions_fare_survived()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Male survived: 0.190226876091\n",
      "Number of male survived: 109 and total male: 573\n",
      "Proportion of Female survived: 0.742038216561\n",
      "Number of female survived: 233 and total female: 314\n"
     ]
    }
   ],
   "source": [
    "def proportions_gender_survived():\n",
    "    X = Final.iloc[:,:] \n",
    "    y = training_data.iloc[:,0]\n",
    "    survived = Final.loc[y == 1]\n",
    "    not_survived = Final.loc[y == 0]\n",
    "\n",
    "    S1= (np.array(np.where((survived.iloc[:, 5]==0))).shape)[1]\n",
    "    S2= (np.array(np.where((survived.iloc[:, 5]==1))).shape)[1]\n",
    "\n",
    "    P1=np.array(Final['Gender'].value_counts(sort=False, ascending=True))[0]\n",
    "    P2=np.array(Final['Gender'].value_counts(sort=False, ascending=True))[1]\n",
    "\n",
    "    print(\"Proportion of Male survived:\",S1/P1)\n",
    "    print(\"Number of male survived:\",S1,\"and\",\"total male:\",P1)\n",
    "    print(\"Proportion of Female survived:\",S2/P2)\n",
    "    print(\"Number of female survived:\",S2,\"and\",\"total female:\",P2)\n",
    "    \n",
    "proportions_gender_survived()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding mean, median and mode for Fare and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of fare: 32.30542018038328\n",
      "median of fare: 14.4542\n",
      "mode of fare: 0    8.05\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of fare:\", training_data['Fare'].mean())\n",
    "print(\"median of fare:\", training_data['Fare'].median()) \n",
    "print(\"mode of fare:\", training_data['Fare'].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare is positively skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of age: 29.471443066516347\n",
      "median of age: 28.0\n",
      "mode of age: 0    22.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of age:\", training_data['Age'].mean())\n",
    "print(\"median of age:\", training_data['Age'].median()) \n",
    "print(\"mode of age:\", training_data['Age'].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age is positively skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minmax normalisation\n",
    "\n",
    "We want to normalise the dataset so that some features don't converge faster than other features in the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise(X):\n",
    "    mins = np.min(X, axis = 0) \n",
    "    maxs = np.max(X, axis = 0) \n",
    "    rng = maxs - mins \n",
    "    norm_X = (X-mins)/rng \n",
    "    return norm_X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now normalise the Final dataset. Below is the first 5 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass       Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "0     1.0  0.271174                    0.125                      0.0   \n",
       "1     0.0  0.472229                    0.125                      0.0   \n",
       "2     1.0  0.321438                    0.000                      0.0   \n",
       "3     0.0  0.434531                    0.125                      0.0   \n",
       "4     1.0  0.434531                    0.000                      0.0   \n",
       "\n",
       "       Fare  Gender  \n",
       "0  0.014151     0.0  \n",
       "1  0.139136     1.0  \n",
       "2  0.015469     1.0  \n",
       "3  0.103644     1.0  \n",
       "4  0.015713     0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Norm=normalise(Final)\n",
    "Data_Norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now want to arrange our normalised dataset, Data_Norm, into a Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        ,  1.        ,  0.27117366, ...,  0.        ,\n",
       "          0.01415106,  0.        ],\n",
       "        [ 1.        ,  0.        ,  0.4722292 , ...,  0.        ,\n",
       "          0.13913574,  1.        ],\n",
       "        [ 1.        ,  1.        ,  0.32143755, ...,  0.        ,\n",
       "          0.01546857,  1.        ],\n",
       "        ..., \n",
       "        [ 1.        ,  1.        ,  0.08268409, ...,  0.33333333,\n",
       "          0.04577135,  1.        ],\n",
       "        [ 1.        ,  0.        ,  0.32143755, ...,  0.        ,\n",
       "          0.0585561 ,  0.        ],\n",
       "        [ 1.        ,  1.        ,  0.39683338, ...,  0.        ,\n",
       "          0.01512699,  0.        ]]), (887, 7))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix=np.c_[np.ones((Data_Norm.shape[0],1)),Data_Norm]\n",
    "Matrix, Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        ,  1.        ,  0.27117366, ...,  0.01415106,\n",
       "          0.        ,  0.        ],\n",
       "        [ 1.        ,  0.        ,  0.4722292 , ...,  0.13913574,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  0.32143755, ...,  0.01546857,\n",
       "          1.        ,  1.        ],\n",
       "        ..., \n",
       "        [ 1.        ,  1.        ,  0.08268409, ...,  0.04577135,\n",
       "          1.        ,  0.        ],\n",
       "        [ 1.        ,  0.        ,  0.32143755, ...,  0.0585561 ,\n",
       "          0.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  0.39683338, ...,  0.01512699,\n",
       "          0.        ,  0.        ]]), (887, 8))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combine_matrix=np.array(pd.concat([Data_Norm,Output],axis=1))\n",
    "Matrix_Combine=np.insert(Combine_matrix,0,np.array((np.ones(887))),1) #adding ones column so that we can take the matrix product\n",
    "Matrix_Combine, Matrix_Combine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An array of normalised features, with the ones column, and the output column, for use in train-test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initial weights\n",
    "w=np.array([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Probability of surviving\n",
    "def sigmoid(m,w): \n",
    "    return 1.0/(1 + np.exp(-np.dot(m,w))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to minimise the average cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(y,m,w): #Scalar\n",
    "    h=sigmoid(m,w)\n",
    "    arg= (y*np.log(h)+(1-y)*np.log(1-h)) \n",
    "    return -(arg.T.dot(arg))/len(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiating the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient(y,m,w): #procedure to find the gradient vector\n",
    "    err = sigmoid(m,w)-y\n",
    "    grad = (m.T.dot(err))/len(y) \n",
    "    return grad, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gradient descent: find updated weights from the training data, as there are no closed form solutions to grad=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(y, m, initial_w, max_iters, tau):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        loss = compute_cost(y,m,w)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}, w2={w2}, w3={w3}, w4={w4}, w5={w5}, w6={w6}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss,  w0=w[0], w1=w[1], w2=w[2], w3=w[3], w4=w[4], w5=w[5], w6=w[6]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_iter_parameters(y, m, initial_w, max_iters, tau):\n",
    "    ws = [initial_w]\n",
    "    losses = np.array([])\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "    return [w[0],w[1], w[2], w[3], w[4], w[5], w[6]] #gives a list of parameters for the last iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure below shows the losses for each iteration so that we know it converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def losses(y, m, initial_w, max_iters, tau):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        loss = compute_cost(y,m,w)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        losses.append(loss)\n",
    "        print (np.asarray(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of losses function to check if the cost converges with the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lossesplot(y, m, initial_w, max_iters, tau):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        loss = compute_cost(y,m,w)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        losses.append(loss)\n",
    "    cost = list(losses)\n",
    "    n_iterations = [x for x in range(1,max_iters+1)]\n",
    "    plt.plot(n_iterations, cost)\n",
    "    plt.xlabel('No. of iterations')\n",
    "    plt.ylabel('Cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictions(X,w):\n",
    "    preds=[]\n",
    "    for i in sigmoid(X, w):\n",
    "        if i> 0.5:\n",
    "            preds.append(1)\n",
    "        if i < 0.5:\n",
    "            preds.append(0)\n",
    "    return np.array(preds)\n",
    "\n",
    "#Using the parameters found from training set and the Matrix we find the probability of survival \n",
    "#i.e if probability is less than 0.5 then Survived =0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the accuracy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gives test accuracy for the parameters, i.e. how many predictions were correct\n",
    "def accuracy(X,w,y):\n",
    "    return len(np.array((np.where(predictions(X,w)==y))).T)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help choose the number of iterations for a certain stepsize, tau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameters_accuracies(y,x,tau,xt,yt):\n",
    "    for i in range (500,5000,500):\n",
    "        a= last_iter_parameters(y,x,w,i,tau)\n",
    "        b=accuracy(xt,a,yt)\n",
    "        print(\"with\", i,\"iterations and stepsize=\", tau, \"we get the following test accuracy:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test data split (for out of sample validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding 20% of the number of observations\n",
    "int((Matrix_Combine[:,0].shape[0])/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#out of sample validation\n",
    "np.random.seed(10) #20-80 split\n",
    "perm=np.random.permutation(887)\n",
    "x_train,x_test= Matrix_Combine[perm][177:][:,0:7],Matrix_Combine[perm][:177][:,0:7]\n",
    "y_train,y_test=Matrix_Combine[perm][177:][:,-1],Matrix_Combine[perm][:177][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((710, 7), (177, 7), (710,), (177,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide the number of iterations and stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 500 iterations and stepsize= 0.1 we get the following test accuracy: 0.7909604519774012\n",
      "with 1000 iterations and stepsize= 0.1 we get the following test accuracy: 0.7627118644067796\n",
      "with 1500 iterations and stepsize= 0.1 we get the following test accuracy: 0.7627118644067796\n",
      "with 2000 iterations and stepsize= 0.1 we get the following test accuracy: 0.7853107344632768\n",
      "with 2500 iterations and stepsize= 0.1 we get the following test accuracy: 0.7966101694915254\n",
      "with 3000 iterations and stepsize= 0.1 we get the following test accuracy: 0.8022598870056498\n",
      "with 3500 iterations and stepsize= 0.1 we get the following test accuracy: 0.8022598870056498\n",
      "with 4000 iterations and stepsize= 0.1 we get the following test accuracy: 0.8022598870056498\n",
      "with 4500 iterations and stepsize= 0.1 we get the following test accuracy: 0.7966101694915254\n",
      "None\n",
      "with 500 iterations and stepsize= 0.2 we get the following test accuracy: 0.7627118644067796\n",
      "with 1000 iterations and stepsize= 0.2 we get the following test accuracy: 0.7853107344632768\n",
      "with 1500 iterations and stepsize= 0.2 we get the following test accuracy: 0.8022598870056498\n",
      "with 2000 iterations and stepsize= 0.2 we get the following test accuracy: 0.8022598870056498\n",
      "with 2500 iterations and stepsize= 0.2 we get the following test accuracy: 0.8022598870056498\n",
      "with 3000 iterations and stepsize= 0.2 we get the following test accuracy: 0.807909604519774\n",
      "with 3500 iterations and stepsize= 0.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 0.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 0.2 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 0.3 we get the following test accuracy: 0.7627118644067796\n",
      "with 1000 iterations and stepsize= 0.3 we get the following test accuracy: 0.8022598870056498\n",
      "with 1500 iterations and stepsize= 0.3 we get the following test accuracy: 0.7966101694915254\n",
      "with 2000 iterations and stepsize= 0.3 we get the following test accuracy: 0.807909604519774\n",
      "with 2500 iterations and stepsize= 0.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 0.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 0.3 we get the following test accuracy: 0.8192090395480226\n",
      "with 4000 iterations and stepsize= 0.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 0.3 we get the following test accuracy: 0.807909604519774\n",
      "None\n",
      "with 500 iterations and stepsize= 0.4 we get the following test accuracy: 0.7853107344632768\n",
      "with 1000 iterations and stepsize= 0.4 we get the following test accuracy: 0.8022598870056498\n",
      "with 1500 iterations and stepsize= 0.4 we get the following test accuracy: 0.807909604519774\n",
      "with 2000 iterations and stepsize= 0.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 0.4 we get the following test accuracy: 0.8192090395480226\n",
      "with 3000 iterations and stepsize= 0.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 0.4 we get the following test accuracy: 0.807909604519774\n",
      "with 4000 iterations and stepsize= 0.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 0.4 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 0.5 we get the following test accuracy: 0.7966101694915254\n",
      "with 1000 iterations and stepsize= 0.5 we get the following test accuracy: 0.8022598870056498\n",
      "with 1500 iterations and stepsize= 0.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 0.5 we get the following test accuracy: 0.8192090395480226\n",
      "with 2500 iterations and stepsize= 0.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 0.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 0.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 0.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 0.5 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 0.6 we get the following test accuracy: 0.8022598870056498\n",
      "with 1000 iterations and stepsize= 0.6 we get the following test accuracy: 0.807909604519774\n",
      "with 1500 iterations and stepsize= 0.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 0.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 0.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 0.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 0.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 0.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 0.6 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 0.7 we get the following test accuracy: 0.8022598870056498\n",
      "with 1000 iterations and stepsize= 0.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 0.7 we get the following test accuracy: 0.8192090395480226\n",
      "with 2000 iterations and stepsize= 0.7 we get the following test accuracy: 0.807909604519774\n",
      "with 2500 iterations and stepsize= 0.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 0.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 0.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 0.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 0.7 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 0.8 we get the following test accuracy: 0.8022598870056498\n",
      "with 1000 iterations and stepsize= 0.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 0.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 0.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 0.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 0.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 0.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 0.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 0.8 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 0.9 we get the following test accuracy: 0.7966101694915254\n",
      "with 1000 iterations and stepsize= 0.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 0.9 we get the following test accuracy: 0.807909604519774\n",
      "with 2000 iterations and stepsize= 0.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 0.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 0.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 0.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 0.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 0.9 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.0 we get the following test accuracy: 0.8022598870056498\n",
      "with 1000 iterations and stepsize= 1.0 we get the following test accuracy: 0.8192090395480226\n",
      "with 1500 iterations and stepsize= 1.0 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.0 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.0 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.0 we get the following test accuracy: 0.8135593220338984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 3500 iterations and stepsize= 1.0 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.0 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.0 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.1 we get the following test accuracy: 0.8022598870056498\n",
      "with 1000 iterations and stepsize= 1.1 we get the following test accuracy: 0.8192090395480226\n",
      "with 1500 iterations and stepsize= 1.1 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.1 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.1 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.1 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.1 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.1 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.1 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.2 we get the following test accuracy: 0.807909604519774\n",
      "with 1000 iterations and stepsize= 1.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 1.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.2 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.2 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.3 we get the following test accuracy: 0.807909604519774\n",
      "with 1000 iterations and stepsize= 1.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 1.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.3 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.3 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 1000 iterations and stepsize= 1.4 we get the following test accuracy: 0.807909604519774\n",
      "with 1500 iterations and stepsize= 1.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.4 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.4 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 1000 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.5 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 1000 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.6 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 1000 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.7 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 1000 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.8 we get the following test accuracy: 0.8135593220338984\n",
      "None\n",
      "with 500 iterations and stepsize= 1.9 we get the following test accuracy: 0.8192090395480226\n",
      "with 1000 iterations and stepsize= 1.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 1500 iterations and stepsize= 1.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 2000 iterations and stepsize= 1.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 2500 iterations and stepsize= 1.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 3000 iterations and stepsize= 1.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 3500 iterations and stepsize= 1.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 4000 iterations and stepsize= 1.9 we get the following test accuracy: 0.8135593220338984\n",
      "with 4500 iterations and stepsize= 1.9 we get the following test accuracy: 0.8135593220338984\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,2,0.1):\n",
    "    print(parameters_accuracies(y_train,x_train,i,x_test,y_test)) #choose gamma=1.9, max_iters=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose stepsize, tau=1.9, max_iters=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/499): loss=-25.54935547662346, w0=-0.13361691524718355, w1=1.1137775151848084, w2=2.570044586640156, w3=3.922173244073798, w4=4.9356071984352985, w5=5.952796635156053, w6=6.818039716065224\n",
      "Gradient Descent(1/499): loss=-13.859355322734316, w0=-1.1558339511530056, w1=0.3056622852445027, w2=2.1805789662302755, w3=3.8463075526161394, w4=4.872366713836063, w5=5.90921138265668, w6=6.636146354404791\n",
      "Gradient Descent(2/499): loss=-7.551189948344418, w0=-1.8347903518742323, w1=-0.23435658695861383, w2=1.9173566320322157, w3=3.7780221173491655, w4=4.81357355398487, w5=5.876030046174744, w6=6.454673025319569\n",
      "Gradient Descent(3/499): loss=-4.984044521393974, w0=-2.2150690372376727, w1=-0.5443995413943019, w2=1.7690237581028876, w3=3.720343588098924, w4=4.761594631832302, w5=5.853218815612455, w6=6.2745976535739105\n",
      "Gradient Descent(4/499): loss=-3.8811204165886637, w0=-2.461540749255681, w1=-0.7582760438992979, w2=1.6732586971419512, w3=3.6700486003495767, w4=4.714772067233664, w5=5.836122386299532, w6=6.097032515673697\n",
      "Gradient Descent(5/499): loss=-3.2561654133744073, w0=-2.63702575619779, w1=-0.9237740827272501, w2=1.6051890572310064, w3=3.6248592297051196, w4=4.671659170349825, w5=5.822533431869686, w6=5.923229001103462\n",
      "Gradient Descent(6/499): loss=-2.8479329011473378, w0=-2.7670771422348315, w1=-1.0590375767760964, w2=1.554499138587052, w3=3.5834586975345237, w4=4.631360305832293, w5=5.811382073766344, w6=5.754630797083912\n",
      "Gradient Descent(7/499): loss=-2.5626950186040687, w0=-2.864049031823523, w1=-1.17219940951273, w2=1.5161161070246534, w3=3.5450168222716036, w4=4.593293198489675, w5=5.802059179492695, w6=5.592783902591192\n",
      "Gradient Descent(8/499): loss=-2.3563816087321845, w0=-2.9347209569733317, w1=-1.2673443832466713, w2=1.487201687915376, w3=3.5089654428396697, w4=4.557052141873934, w5=5.79417189671148, w6=5.439158042647603\n",
      "Gradient Descent(9/499): loss=-2.2039159407770725, w0=-2.983342718260834, w1=-1.3468276841782867, w2=1.4659567262995987, w3=3.4748840137944117, w4=4.522332796480979, w5=5.787437748815464, w6=5.294923332186392\n",
      "Gradient Descent(10/499): loss=-2.0889455946514683, w0=-3.0130691955298206, w1=-1.4123526951407464, w2=1.4510657670360938, w3=3.4424362492164007, w4=4.488888774762823, w5=5.781632579280154, w6=5.160757142108633\n",
      "Gradient Descent(11/499): loss=-1.9999205813609127, w0=-3.0266514886251534, w1=-1.4654796643515837, w2=1.4414287463239217, w3=3.411335360046685, w4=4.456507124002732, w5=5.776564708158774, w6=5.036757022710646\n",
      "Gradient Descent(12/499): loss=-1.928486821535468, w0=-3.026706182808843, w1=-1.507806728403739, w2=1.4360482300439656, w3=3.381327555132353, w4=4.424996558680912, w5=5.7720639326193615, w6=4.922488392169014\n",
      "Gradient Descent(13/499): loss=-1.8687149646681127, w0=-3.0157469143849753, w1=-1.5409651756172702, w2=1.434002229877477, w3=3.352186791094981, w4=4.394184042242891, w5=5.767978723408555, w6=4.81713291338984\n",
      "Gradient Descent(14/499): loss=-1.8165751356667488, w0=-2.996114658898216, w1=-1.5665383182943278, w2=1.4344547894716484, w3=3.32371492842456, w4=4.363915674918662, w5=5.764176876090085, w6=4.719670862221379\n",
      "Gradient Descent(15/499): loss=-1.7694704281148421, w0=-2.9698967089368935, w1=-1.585976818156505, w2=1.4366737893209025, w3=3.295743028054137, w4=4.334058619473465, w5=5.760546569283325, w6=4.629040447521265\n",
      "Gradient Descent(16/499): loss=-1.7258155960015233, w0=-2.9388764751500784, w1=-1.600543773478334, w2=1.4400414164391138, w3=3.2681315333800005, w4=4.304502139668247, w5=5.756996417939777, w6=4.544247150655589\n",
      "Gradient Descent(17/499): loss=-1.6846900840436285, w0=-2.904521857721032, w1=-1.6112945056127583, w2=1.4440540045026093, w3=3.2407687539085552, w4=4.275157128981083, w5=5.7534542800236395, w6=4.464422267904698\n",
      "Gradient Descent(18/499): loss=-1.6455808742675364, w0=-2.8680033894354575, w1=-1.6190827201528109, w2=1.4483134561247841, w3=3.213567994203287, w4=4.245954328623638, w5=5.749865147592464, w6=4.388842794705303\n",
      "Gradient Descent(19/499): loss=-1.6082088382920001, w0=-2.830229517914493, w1=-1.6245820285614783, w2=1.4525138850282096, w3=3.1864639585409247, w4=4.2168417465240395, w5=5.746188587946059, w6=4.316927156196055\n",
      "Gradient Descent(20/499): loss=-1.572420379021376, w0=-2.791888513119425, w1=-1.6283138982540848, w2=1.4564265945937702, w3=3.1594089960019205, w4=4.187781780420106, w5=5.7423961209250685, w6=4.248218563125145\n",
      "Gradient Descent(21/499): loss=-1.538124344308646, w0=-2.7534901085975387, w1=-1.6306762517639408, w2=1.4598854544511264, w3=3.132369567298419, w4=4.158748409865136, w5=5.738468780591846, w6=4.182363861542502\n",
      "Gradient Descent(22/499): loss=-1.5052576621313543, w0=-2.715403141048557, w1=-1.6319695898900137, w2=1.4627737884881036, w3=3.105323136897272, w4=4.129724669526859, w5=5.7343949871856115, w6=4.119092415621715\n",
      "Gradient Descent(23/499): loss=-1.4737679450963517, w0=-2.6778876343886684, w1=-1.6324193108851728, w2=1.4650132229430841, w3=3.0782555641122746, w4=4.100700496912188, w5=5.730168769717086, w6=4.058197255456392\n",
      "Gradient Descent(24/499): loss=-1.4436055071251483, w0=-2.641121080356635, w1=-1.632193957330752, w2=1.4665545423240862, w3=3.0511589867624562, w4=4.071670969937724, w5=5.725788328519212, w6=3.9995193146377397\n",
      "Gradient Descent(25/499): loss=-1.4147202757771828, w0=-2.605219351649661, w1=-1.631419671244068, w2=1.467370390339253, w3=3.024030148953871, w4=4.042634906271581, w5=5.721254901197974, w6=3.942934813433345\n",
      "Gradient Descent(26/499): loss=-1.387061059841614, w0=-2.570252978099739, w1=-1.630191373352939, w2=1.4674495629468824, w3=2.996869107424927, w4=4.013593776426135, w5=5.716571885605175, w6=3.8883454754509574\n",
      "Gradient Descent(27/499): loss=-1.3605758231321217, w0=-2.5362595888464248, w1=-1.6285812422102366, w2=1.4667926198789007, w3=2.96967824838594, w4=3.984550877021779, w5=5.711744172838916, w6=3.8356711286826006\n",
      "Gradient Descent(28/499): loss=-1.3352122923713492, w0=-2.503253280986983, w1=-1.626645039258941, w2=1.4654085564105084, w3=2.942461551900904, w4=3.9555107129527047, w5=5.706777647352007, w6=3.7848442270012\n",
      "Gradient Descent(29/499): loss=-1.3109185919151156, w0=-2.4712315814527237, w1=-1.6244267573670401, w2=1.4633123088350586, w3=2.9152240492953623, w4=3.9264785432052105, w5=5.701678817273576, w6=3.735805871032606\n",
      "Gradient Descent(30/499): loss=-1.287643784240082, w0=-2.4401805594160018, w1=-1.621961990224144, w2=1.4605229038148981, w3=2.8879714283630094, w4=3.8974600523548912, w5=5.696454544478059, w6=3.688502971942588\n",
      "Gradient Descent(31/499): loss=-1.2653382839432759, w0=-2.410078539879053, w1=-1.6192803423032107, w2=1.4570620975822142, w3=2.86070974998792, w4=3.8684611169696397, w5=5.69111184996774, w6=3.6428862693776756\n",
      "Gradient Descent(32/499): loss=-1.2439541513170365, w0=-2.380898773859139, w1=-1.61640713015104, w2=1.4529533830400307, w3=2.8334452476011776, w4=3.8394876426249906, w5=5.685657775411402, w6=3.5989089767654665\n",
      "Gradient Descent(33/499): loss=-1.223445285089486, w0=-2.3526113398839974, w1=-1.6133645677201462, w2=1.4482212701060044, w3=2.806184187450679, w4=3.810545452749116, w5=5.680099286094035, w6=3.5565258799991977\n",
      "Gradient Descent(34/499): loss=-1.2037675361658713, w0=-2.325184485538885, w1=-1.6101725812787848, w2=1.442890767049731, w3=2.778932772995615, w4=3.781640215026091, w5=5.67444320410551, w6=3.5156927585884343\n",
      "Gradient Descent(35/499): loss=-1.1848787619298415, w0=-2.2985855653114973, w1=-1.6068493621028663, w2=1.4369870084801246, w3=2.7516970809615837, w4=3.752777394676369, w5=5.668696163418243, w6=3.476366032375574\n",
      "Gradient Descent(36/499): loss=-1.1667388370509002, w0=-2.27278169011252, w1=-1.6034117362354177, w2=1.4305349896360604, w3=2.7244830198692136, w4=3.723962226727606, w5=5.662864580687957, w6=3.4385025631601573\n",
      "Gradient Descent(37/499): loss=-1.1493096331657897, w0=-2.2477401726184936, w1=-1.5998754086049505, w2=1.4235593773708395, w3=2.6972963043458735, w4=3.6951997015234603, w5=5.656954637272768, w6=3.4020595604269706\n",
      "Gradient Descent(38/499): loss=-1.1325549767526837, w0=-2.223428829105894, w1=-1.596255122335904, w2=1.4160843763229742, w3=2.6701424404025067, w4=3.666494559322436, w5=5.650972269210018, w6=3.3669945551462592\n",
      "Gradient Descent(39/499): loss=-1.1164405920994103, w0=-2.1998161810564274, w1=-1.5925647619516856, w2=1.4081336347888656, w3=2.6430267182420026, w4=3.6378512910277054, w5=5.6449231628096035, w6=3.3332654164434348\n",
      "Gradient Descent(40/499): loss=-1.1009340344238845, w0=-2.1768715871093174, w1=-1.5888174203521637, w2=1.3997301792303938, w3=2.615954210175818, w4=3.6092741429584225, w5=5.638812754193504, w6=3.3008303937662467\n",
      "Gradient Descent(41/499): loss=-1.0860046168319553, w0=-2.154565326771979, w1=-1.5850254431239774, w2=1.3908963695505745, w3=2.5889297719540085, w4=3.5807671242015697, w5=5.632646231595621, w6=3.269648172767402\n",
      "Gradient Descent(42/499): loss=-1.0716233337883496, w0=-2.1328686507675743, w1=-1.5812004592677433, w2=1.3816538695629126, w3=2.5619580463332645, w4=3.5523340155327707, w5=5.626428539582291, w6=3.2396779370620807\n",
      "Gradient Descent(43/499): loss=-1.057762783039367, w0=-2.1117538082922227, w1=-1.577353404302474, w2=1.3720236287060654, w3=2.5350434680741376, w4=3.5239783792125863, w5=5.620164384599367, w6=3.2108794307653357\n",
      "Gradient Descent(44/499): loss=-1.0443970873890702, w0=-2.091194058240847, w1=-1.5734945395564963, w2=1.362025872198796, w3=2.5081902698149467, w4=3.4957035691879295, w5=5.613858241424681, w6=3.18321301860358\n",
      "Gradient Descent(45/499): loss=-1.0315018173393409, w0=-2.071163669239192, w1=-1.569633469994588, w2=1.3516800976286063, w3=2.48140248844751, w4=3.467512741383416, w5=5.60751436022581, w6=3.1566397416779512\n",
      "Gradient Descent(46/499): loss=-1.0190539153177405, w0=-2.051637911797051, w1=-1.5657791619566974, w2=1.34100507652224, w3=2.454683971742085, w4=3.4394088638746276, w5=5.601136774007821, w6=3.131121367817493\n",
      "Gradient Descent(47/499): loss=-1.0070316220063835, w0=-2.0325930448618905, w1=-1.5619399615454839, w2=1.330018859830835, w3=2.42803838505245, w4=3.4113947268087617, w5=5.594729306294803, w6=3.106620436027568\n",
      "Gradient Descent(48/499): loss=-0.9954144051287864, w0=-2.0140062983514344, w1=-1.5581236139917691, w2=1.3187387865293863, w3=2.4014692179888786, w4=3.383472951988285, w5=5.588295578930562, w6=3.083100294906215\n",
      "Gradient Descent(49/499): loss=-0.9841828909348859, w0=-1.9958558527717831, w1=-1.5543372840741023, w2=1.3071814947163116, w3=2.3749797909852735, w4=3.355646002067243, w5=5.581839019913149, w6=3.060525135133048\n",
      "Gradient Descent(50/499): loss=-0.9733187985363794, w0=-1.9781208167100799, w1=-1.5505875775190257, w2=1.2953629347300382, w3=2.3485732617127466, w4=3.3279161893329055, w5=5.575362871198874, w6=3.0388600162765567\n",
      "Gradient Descent(51/499): loss=-0.9628048771776679, w0=-1.9607812027766958, w1=-1.546880563226611, w2=1.2832983838934027, w3=2.32225263130957, w4=3.3002856840609343, w5=5.56887019642664, w6=3.0180708882469442\n",
      "Gradient Descent(52/499): loss=-0.9526248464765237, w0=-1.9438179024266813, w1=-1.543221796127176, w2=1.2710024625652938, w3=2.2960207504093506, w4=3.2727565224426782, w5=5.562363888524696, w6=2.9981246077637365\n",
      "Gradient Descent(53/499): loss=-0.9427633396293196, w0=-1.927212659990538, w1=-1.5396163404635412, w2=1.258489151230537, w3=2.269880324957415, w4=3.245330614090162, w5=5.555846677170413, w6=2.9789889502242204\n",
      "Gradient Descent(54/499): loss=-0.9332058495454811, w0=-1.9109480461746622, w1=-1.5360687932979862, w2=1.2457718083989386, w3=2.2438339218109786, w4=3.2180097491289463, w5=5.549321136080247, w6=2.9606326173596065\n",
      "Gradient Descent(55/499): loss=-0.9239386778526975, w0=-1.8950074312418426, w1=-1.532583308057167, w2=1.2328631891162778, w3=2.2178839741225125, w4=3.19079560489206, w5=5.542789690112293, w6=2.9430252410567728\n",
      "Gradient Descent(56/499): loss=-0.9149488866968645, w0=-1.8793749580452654, w1=-1.5291636179471613, w2=1.2197754639162481, w3=2.1920327865084137, w4=3.1636897522301193, w5=5.536254622168014, w6=2.926137383708498\n",
      "Gradient Descent(57/499): loss=-0.9062242532476491, w0=-1.8640355150612247, w1=-1.5258130590916439, w2=1.2065202380644542, w3=2.1662825400069674, w4=3.136693661453923, w5=5.529718079883191, w6=2.909940535436841\n",
      "Gradient Descent(58/499): loss=-0.8977532268110155, w0=-1.8489747095433435, w1=-1.5225345932672347, w2=1.1931085709646148, w3=2.1406352968309124, w4=3.109808707926447, w5=5.523182082101027, w6=2.894407108514396\n",
      "Gradient Descent(59/499): loss=-0.8895248884434677, w0=-1.8341788409027888, w1=-1.5193308301302628, w2=1.1795509956137733, w3=2.115093004920857, w4=3.083036177321418, w5=5.516648525122734, w6=2.879510429287622\n",
      "Gradient Descent(60/499): loss=-0.8815289129584862, w0=-1.819634874403534, w1=-1.5162040488479915, w2=1.165857538008055, w3=2.0896575023064234, w4=3.0563772705656493, w5=5.510119188732992, w6=2.8652247278859386\n",
      "Gradient Descent(61/499): loss=-0.8737555332133682, w0=-1.805330415248462, w1=-1.513156219064467, w2=1.152037736413633, w3=2.0643305212824457, w4=3.0298331084821113, w5=5.5035957419993835, w6=2.8515251259802223\n",
      "Gradient Descent(62/499): loss=-0.8661955065639148, w0=-1.7912536831205141, w1=-1.5101890211465077, w2=1.1381006604293162, w3=2.039113692407789, w4=3.0034047361503693, w5=5.49707974884637, w6=2.838387622834962\n",
      "Gradient Descent(63/499): loss=-0.8588400833749751, w0=-1.777393487232854, w1=-1.507303865668938, w2=1.124054929777704, w3=2.0140085483345187, w4=2.9770931270005736, w5=5.490572673405625, w6=2.825789079879763\n",
      "Gradient Descent(64/499): loss=-0.8516809774764272, w0=-1.7637392019329319, w1=-1.504501912110084, w2=1.1099087327713146, w3=1.989016527475172, w4=2.950899186656659, w5=5.484075885145557, w6=2.8137072040082187\n",
      "Gradient Descent(65/499): loss=-0.8447103384565573, w0=-1.750280742897224, w1=-1.5017840867389023, w2=1.095669844408571, w3=1.9641389775158455, w4=2.9248237565438315, w5=5.477590663783722, w6=2.8021205297954164\n",
      "Gradient Descent(66/499): loss=-0.8379207256878355, w0=-1.7370085439461964, w1=-1.499151099684021, w2=1.081345644062135, w3=1.9393771587827118, w4=2.8988676172748, w5=5.471118203986547, w6=2.791008400809517\n",
      "Gradient Descent(67/499): loss=-0.8313050839835804, w0=-1.7239135345025831, w1=-1.4966034611825902, w2=1.066943132728869, w3=1.914732247469411, w4=2.873031491828576, w5=5.46465961986134, w6=2.780350950177935\n",
      "Gradient Descent(68/499): loss=-0.8248567207878833, w0=-1.7109871177103348, w1=-1.4941414970132867, w2=1.0524689498167794, w3=1.8902053387325664, w4=2.8473160485349993, w5=5.458215949246054, w6=2.7701290805546366\n",
      "Gradient Descent(69/499): loss=-0.8185692848052752, w0=-1.698221149226491, w1=-1.4917653631232164, w2=1.0379293894496864, w3=1.865797449662435, w4=2.8217219038774775, w5=5.4517881578026, w6=2.7603244436219176\n",
      "Gradient Descent(70/499): loss=-0.812436745980888, w0=-1.6856079166937123, w1=-1.4894750594629471, w2=1.0233304162751582, w3=1.8415095221354496, w4=2.7962496251257924, w5=5.445377142919797, w6=2.7509194192477247\n",
      "Gradient Descent(71/499): loss=-0.806453376746226, w0=-1.6731401198972369, w1=-1.4872704430475667, w2=1.0086776807654874, w3=1.8173424255551192, w4=2.770899732810141, w5=5.438983737432222, w6=2.741897094408081\n",
      "Gradient Descent(72/499): loss=-0.8006137344500466, w0=-1.6608108516065216, w1=-1.4851512402646154, w2=0.9939765340052158, w3=1.793296959487468, w4=2.7456727030469574, w5=5.432608713161369, w6=2.7332412419734506\n",
      "Gradient Descent(73/499): loss=-0.7949126448981931, w0=-1.6486135790987895, w1=-1.4831170584520679, w2=0.9792320419620026, w3=1.7693738561968824, w4=2.7205689697264286, w5=5.426252784285566, w6=2.7249362994478843\n",
      "Gradient Descent(74/499): loss=-0.7893451869305146, w0=-1.6365421263590412, w1=-1.481167396771328, w2=0.9644489992404902, w3=1.7455737830879323, w4=2.695588926571011, w5=5.419916610545147, w6=2.7169673477405203\n",
      "Gradient Descent(75/499): loss=-0.7839066779671924, w0=-1.6245906569488104, w1=-1.4793016564015116, w2=0.9496319423213199, w3=1.7218973450584139, w4=2.6707329290736657, w5=5.413600800289328, w6=2.7093200900403884\n",
      "Gradient Descent(76/499): loss=-0.7785926604608397, w0=-1.6127536575339747, w1=-1.4775191500822018, w2=0.9347851622896082, w3=1.6983450867685572, w4=2.646001296323972, w5=5.407305913371201, w6=2.701980830857502\n",
      "Gradient Descent(77/499): loss=-0.7733988891946698, w0=-1.6010259220602732, w1=-1.4758191110324252, w2=0.9199127170590486, w3=1.6749174948310326, w4=2.6213943127297314, w5=5.401032463897138, w6=2.694936455285851\n",
      "Gradient Descent(78/499): loss=-0.7683213193707666, w0=-1.5894025365637774, w1=-1.4742007012738645, w2=0.9050184430993875, w3=1.6516149999260898, w4=2.596912229641168, w5=5.394780922836823, w6=2.6881744085371078\n",
      "Gradient Descent(79/499): loss=-0.7633560954360896, w0=-1.5778788646023998, w1=-1.4726630193863361, w2=0.8901059666763613, w3=1.6284379788458716, w4=2.5725552668843363, w5=5.388551720499963, w6=2.6816826757876124\n",
      "Gradient Descent(80/499): loss=-0.7584995405972552, w0=-1.5664505332935725, w1=-1.471205107723374, w2=0.8751787146143053, w3=1.605386756471661, w4=2.5483236142098864, w5=5.382345248885605, w6=2.675449762375434\n",
      "Gradient Descent(81/499): loss=-0.7537481469783684, w0=-1.5551134199424654, w1=-1.4698259591153877, w2=0.8602399245925673, w3=1.5824616076875493, w4=2.524217432662897, w5=5.376161863909797, w6=2.669464674379054\n",
      "Gradient Descent(82/499): loss=-0.7490985663792494, w0=-1.54386363924452, w1=-1.468524523087352, w2=0.8452926549876139, w3=1.5596627592337489, w4=2.5002368558790766, w5=5.370001887517187, w6=2.663716899604387\n",
      "Gradient Descent(83/499): loss=-0.7445476015942745, w0=-1.5326975310456266, w1=-1.46729971161736, w2=0.8303397942733135, w3=1.5369903915025334, w4=2.47638199131224, w5=5.363865609681958, w6=2.6581963890024496\n",
      "Gradient Descent(84/499): loss=-0.7400921982547777, w0=-1.5216116486429598, w1=-1.4661504044616427, w2=0.8153840699923403, w3=1.5144446402795437, w4=2.4526529213976116, w5=5.357753290303312, w6=2.652893538535991\n",
      "Gradient Descent(85/499): loss=-0.7357294371604945, w0=-1.5106027476092891, w1=-1.4650754540708684, w2=0.8004280573119834, w3=1.492025598432985, w4=2.4290497046551622, w5=5.351665161000534, w6=2.647799171509753\n",
      "Gradient Descent(86/499): loss=-0.7314565270679303, w0=-1.4996677751234804, w1=-1.464073690121682, w2=0.7854741871778788, w3=1.4697333175530258, w4=2.405572376736863, w5=5.3456014268124905, w6=2.642904521375731\n",
      "Gradient Descent(87/499): loss=-0.727270797905756, w0=-1.4888038597898994, w1=-1.4631439236865542, w2=0.770524754079317, w3=1.4475678095435183, w4=2.382220951421457, w5=5.339562267806189, w6=2.638201215021836\n",
      "Gradient Descent(88/499): loss=-0.7231696943894262, w0=-1.4780083019294958, w1=-1.462284951064089, w2=0.7555819234398397, w3=1.4255290481679797, w4=2.3589954215600657, w5=5.3335478405988965, w6=2.6336812565496652\n",
      "Gradient Descent(89/499): loss=-0.7191507700091575, w0=-1.4672785643254782, w1=-1.461495557291008, w2=0.7406477386468193, w3=1.4036169705516013, w4=2.335895759975692, w5=5.3275582797980805, w6=2.629337011544696\n",
      "Gradient Descent(90/499): loss=-0.7152116813672104, w0=-1.4566122634066867, w1=-1.4607745193560857, w2=0.725724127733642, w3=1.3818314786409023, w4=2.312921920319451, w5=5.32159369936327, w6=2.6251611918400513\n",
      "Gradient Descent(91/499): loss=-0.7113501828421077, w0=-1.4460071608520093, w1=-1.4601206091353705, w2=0.7108129097279784, w3=1.3601724406225022, w4=2.290073837886138, w5=5.315654193893774, w6=2.621146840773076\n",
      "Gradient Descent(92/499): loss=-0.707564121558985, w0=-1.4354611555994725, w1=-1.4595325960670917, w2=0.6959158006794538, w3=1.3386396923023536, w4=2.2673514303915385, w5=5.3097398398459905, w6=2.617287318932258\n",
      "Gradient Descent(93/499): loss=-0.7038514326467189, w0=-1.4249722762439512, w1=-1.4590092495837392, w2=0.6810344193798098, w3=1.3172330384466626, w4=2.244754598713713, w5=5.303850696683894, w6=2.613576290390523\n",
      "Gradient Descent(94/499): loss=-0.7002101347638331, w0=-1.4145386738077945, w1=-1.4585493413178923, w2=0.6661702927884008, w3=1.2959522540856145, w4=2.2222832276002995, w5=5.297986807966121, w6=2.610007709419616\n",
      "Gradient Descent(95/499): loss=-0.6966383258764297, w0=-1.4041586148690328, w1=-1.458151647097505, w2=0.6513248611755917, w3=1.2747970857809288, w4=2.1999371863437363, w5=5.292148202372897, w6=2.606575807679128\n",
      "Gradient Descent(96/499): loss=-0.693134179272547, w0=-1.3938304750322175, w1=-1.4578149487454901, w2=0.6364994829963231, w3=1.2537672528581794, w4=2.1777163294261577, w5=5.28633489467592, w6=2.6032750818727233\n",
      "Gradient Descent(97/499): loss=-0.6896959397984314, w0=-1.3835527327273562, w1=-1.4575380356976184, w2=0.621695439505791, w3=1.2328624486047428, w4=2.155620497135584, w5=5.2805468866541565, w6=2.6001002818632735\n",
      "Gradient Descent(98/499): loss=-0.6863219203031917, w0=-1.3733239633228163, w1=-1.4573197064519543, w2=0.6069139391288578, w3=1.2120823414341657, w4=2.1336495161549083, w5=5.274784167958355, w6=2.5970463992378603\n",
      "Gradient Descent(99/499): loss=-0.6830104982792351, w0=-1.3631428335384956, w1=-1.4571587698622688, w2=0.5921561215944644, w3=1.1914265760176876, w4=2.11180320012507, w5=5.269046716926966, w6=2.5941086563130047\n",
      "Gradient Descent(100/499): loss=-0.6797601126867298, w0=-1.3530080961459887, w1=-1.4570540462871366, w2=0.577423061845963, w3=1.1708947743836027, w4=2.0900813501837154, w5=5.263334501356004, w6=2.591282495569961\n",
      "Gradient Descent(101/499): loss=-0.6765692609511345, w0=-1.3429185849429048, w1=-1.4570043686057141, w2=0.5627157737379337, w3=1.1504865369850967, w4=2.0684837554805373, w5=5.257647479225279, w6=2.5885635695095113\n",
      "Gradient Descent(102/499): loss=-0.6734364961235619, w0=-1.3328732099889324, w1=-1.4570085831105115, w2=0.5480352135296848, w3=1.1302014437371646, w4=2.0470101936704195, w5=5.251985599383295, w6=2.5859477309153474\n",
      "Gradient Descent(103/499): loss=-0.6703604241944208, w0=-1.3228709530916687, w1=-1.4570655502868304, w2=0.5333822831852794, w3=1.1100390550231736, w4=2.025660431385427, w5=5.2463488021930065, w6=2.5834310235149034\n",
      "Gradient Descent(104/499): loss=-0.6673397015514099, w0=-1.3129108635306626, w1=-1.4571741454879177, w2=0.5187578334895664, w3=1.089998912671619, w4=2.004434224686619, w5=5.240737020140496, w6=2.581009673026296\n",
      "Gradient Descent(105/499): loss=-0.664373032573514, w0=-1.3029920540085458, w1=-1.4573332595143025, w2=0.5041626669893391, w3=1.070080540903591, w4=1.9833313194965954, w5=5.235150178408562, w6=2.5786800785799215\n",
      "Gradient Descent(106/499): loss=-0.661459167353195, w0=-1.2931136968185377, w1=-1.4575417991052197, w2=0.4895975407683875, w3=1.050283447251458, w4=1.9623514520136367, w5=5.229588195417072, w6=2.576438804503201\n",
      "Gradient Descent(107/499): loss=-0.658596899539465, w0=-1.2832750202180254, w1=-1.457798687349506, w2=0.4750631690648642, w3=1.0306071234492573, w4=1.941494349108241, w5=5.224050983331869, w6=2.574282572456937\n",
      "Gradient Descent(108/499): loss=-0.6557850642949942, w0=-1.27347530499832, w1=-1.4581028640228413, w2=0.46056022573903577, w3=1.011051046295274, w4=1.9207597287028175, w5=5.218538448543905, w6=2.5722082539117928\n",
      "Gradient Descent(109/499): loss=-0.6530225363608338, w0=-1.263713881241087, w1=-1.4584532858577506, w2=0.44608934659915883, w3=0.9916146784872794, w4=1.9001473001352558, w5=5.213050492120212, w6=2.5702128629534577\n",
      "Gradient Descent(110/499): loss=-0.6503082282227346, w0=-1.253990125252333, w1=-1.4588489267523201, w2=0.4316511315928869, w3=0.9722974694309003, w4=1.8796567645070472, w5=5.207587010228225, w6=2.5682935494051784\n",
      "Gradient Descent(111/499): loss=-0.6476410883734071, w0=-1.244303456665206, w1=-1.4592887779231711, w2=0.41724614687129513, w3=0.9530988560215847, w4=1.859287815016604, w5=5.202147894534885, w6=2.566447592256465\n",
      "Gradient Descent(112/499): loss=-0.6450200996654221, w0=-1.2346533357032352, w1=-1.459771848007835, w2=0.40287492673229397, w3=0.934018263400628, w4=1.8390401372783882, w5=5.196733032581907, w6=2.564672393386934\n",
      "Gradient Descent(113/499): loss=-0.6424442777497593, w0=-1.2250392605959903, w1=-1.4602971631212998, w2=0.38853797544990154, w3=0.9150551056857277, w4=1.818913409628436, w5=5.191342308138481, w6=2.562965471574446\n",
      "Gradient Descent(114/499): loss=-0.6399126695953187, w0=-1.2154607651394889, w1=-1.4608637668711486, w2=0.37423576899554534, w3=0.8962087866765335, w4=1.7989073034168301, w5=5.185975601532657, w6=2.5613244567768776\n",
      "Gradient Descent(115/499): loss=-0.6374243520849832, w0=-1.2059174163940094, w1=-1.4614707203353805, w2=0.3599687566572808, w3=0.8774787005356645, w4=1.7790214832876585, w5=5.180632789962568, w6=2.559747084677101\n",
      "Gradient Descent(116/499): loss=-0.6349784306840786, w0=-1.1964088125123016, w1=-1.4621171020066965, w2=0.3457373625625351, w3=0.8588642324456666, w4=1.7592556074469676, w5=5.175313747788588, w6=2.5582311914809663\n",
      "Gradient Descent(117/499): loss=-0.6325740381773208, w0=-1.1869345806914906, w1=-1.4628020077067452, w2=0.3315419871097185, w3=0.8403647592423893, w4=1.7396093279192013, w5=5.170018346807478, w6=2.5567747089583195\n",
      "Gradient Descent(118/499): loss=-0.6302103334705642, w0=-1.1774943752422817, w1=-1.4635245504735488, w2=0.31738300831378624, w3=0.8219796500252631, w4=1.7200822907925981, w5=5.164746456509505, w6=2.555375659717349\n",
      "Gradient Descent(119/499): loss=-0.6278865004538748, w0=-1.1680878757693591, w1=-1.4642838604250812, w2=0.3032607830705875, w3=0.8037082667449639, w4=1.700674136454, w5=5.159497944319486, w6=2.554032152702802\n",
      "Gradient Descent(120/499): loss=-0.6256017469226511, w0=-1.1587147854571616, w1=-1.4650790846017299, w2=0.2891756483445957, w3=0.7855499647689552, w4=1.6813844998135106, w5=5.154272675822628, w6=2.5527423789088792\n",
      "Gradient Descent(121/499): loss=-0.6233553035536996, w0=-1.1493748294554824, w1=-1.4659093867901543, w2=0.2751279222843873, w3=0.7675040934254013, w4=1.662213010519429, w5=5.149070514976021, w6=2.551504607297878\n",
      "Gradient Descent(122/499): loss=-0.621146422933339, w0=-1.14006775335961, w1=-1.4667739473308488, w2=0.26111790527001444, w3=0.7495699965259488, w4=1.643159293163863, w5=5.143891324306582, w6=2.550317180915925\n",
      "Gradient Descent(123/499): loss=-0.6189743786347806, w0=-1.130793321779969, w1=-1.467671962911524, w2=0.24714588089620398, w3=0.7317470128678779, w4=1.6242229674794197, w5=5.138734965096197, w6=2.549178513197409\n",
      "Gradient Descent(124/499): loss=-0.6168384643421703, w0=-1.1215513169964735, w1=-1.468602646348243, w2=0.23321211689511465, w3=0.7140344767161249, w4=1.6054036485273573, w5=5.133601297554799, w6=2.5480870844499908\n",
      "Gradient Descent(125/499): loss=-0.614737993018834, w0=-1.112341537693026, w1=-1.4695652263560846, w2=0.21931686600218755, w3=0.6964317182656816, w4=1.5867009468775644, w5=5.128490180982038, w6=2.5470414385123363\n",
      "Gradient Descent(126/499): loss=-0.612672296117389, w0=-1.103163797767827, w1=-1.4705589473109493, w2=0.20546036676844112, w3=0.6789380640848781, w4=1.5681144687807298, w5=5.123401473918199, w6=2.546040179576984\n",
      "Gradient Descent(127/499): loss=-0.6106407228295233, w0=-1.0940179252153681, w1=-1.4715830690039822, w2=0.19164284432238254, w3=0.6615528375400545, w4=1.5496438163330468, w5=5.118335034284989, w6=2.5450819691710223\n",
      "Gradient Descent(128/499): loss=-0.6086426393733505, w0=-1.0849037610761878, w1=-1.4726368663899518, w2=0.17786451108453893, w3=0.6442753592021286, w4=1.5312885876337916, w5=5.113290719516744, w6=2.544165523287511\n",
      "Gradient Descent(129/499): loss=-0.606677428316372, w0=-1.0758211584506672, w1=-1.4737196293308064, w2=0.16412556743744897, w3=0.6271049472355671, w4=1.5130483769360998, w5=5.108268386682627, w6=2.543289609660838\n",
      "Gradient Descent(130/499): loss=-0.6047444879321714, w0=-1.0667699815733267, w1=-1.4748306623355087, w2=0.15042620235380139, w3=0.6100409177702611, w4=1.4949227747912595, w5=5.1032678926003285, w6=2.5424530451794496\n",
      "Gradient Descent(131/499): loss=-0.6028432315890784, w0=-1.0577501049442661, w1=-1.4759692842971501, w2=0.1367665939852597, w3=0.5930825852568128, w4=1.4769113681868247, w5=5.098289093941751, w6=2.5416546934296482\n",
      "Gradient Descent(132/499): loss=-0.6009730871691187, w0=-1.0487614125145626, w1=-1.477134828228245, w2=0.12314691021437173, w3=0.576229262805728, w4=1.4590137406788493, w5=5.093331847331157, w6=2.5408934623643806\n",
      "Gradient Descent(133/499): loss=-0.5991334965156686, w0=-1.0398037969226013, w1=-1.4783266409950195, w2=0.10956730917182964, w3=0.5594802625110145, w4=1.4412294725185248, w5=5.088396009436213, w6=2.5401683020911876\n",
      "Gradient Descent(134/499): loss=-0.5973239149083084, w0=-1.0308771587784744, w1=-1.479544083051421, w2=0.09602793972121897, w3=0.542834895758675, w4=1.4235581407735038, w5=5.08348143705234, w6=2.539478202773709\n",
      "Gradient Descent(135/499): loss=-0.5955438105634479, w0=-1.0219814059937282, w1=-1.480786528173505, w2=0.08252894191327408, w3=0.5262924735205833, w4=1.405999319444175, w5=5.078587987180779, w6=2.538822192641361\n",
      "Gradient Descent(136/499): loss=-0.5937926641593765, w0=-1.0131164531538848, w1=-1.4820533631947814, w2=0.06907044741154336, w3=0.5098523066342227, w4=1.3885525795751517, w5=5.073715517100734, w6=2.538199336102031\n",
      "Gradient Descent(137/499): loss=-0.5920699683844572, w0=-1.0042822209312967, w1=-1.4833439877430388, w2=0.05565257989125839, w3=0.49351370606876477, w4=1.3712174893622238, w5=5.068863884435948, w6=2.537608731952833\n",
      "Gradient Descent(138/499): loss=-0.5903752275072528, w0=-0.9954786355360237, w1=-1.4846578139791082, w2=0.04227545541309751, w3=0.4772759831779557, w4=1.3539936142550173, w5=5.064032947216048, w6=2.5370495116841845\n",
      "Gradient Descent(139/499): loss=-0.588707956967433, w0=-0.9867056282025433, w1=-1.4859942663379715, w2=0.02893918277343699, w3=0.46113844994027114, w4=1.3368805170555926, w5=5.059222563932976, w6=2.5365208378726614\n",
      "Gradient Descent(140/499): loss=-0.5870676829863759, w0=-0.9779631347102246, w1=-1.487352781272569, w2=0.01564386383258915, w3=0.44510041918679516, w4=1.3198777580132093, w5=5.054432593592797, w6=2.536021902658279\n",
      "Gradient Descent(141/499): loss=-0.5854539421964283, w0=-0.9692510949356038, w1=-1.4887328070006223, w2=0.0023895938224394227, w3=0.4291612048172686, w4=1.302984894915473, w5=5.049662895763184, w6=2.5355519263020363\n",
      "Gradient Descent(142/499): loss=-0.5838662812878508, w0=-0.9605694524346085, w1=-1.4901338032547342, w2=-0.010823538365189464, w3=0.4133201220047448, w4=1.2862014831760742, w5=5.044913330616822, w6=2.535110155819741\n",
      "Gradient Descent(143/499): loss=-0.5823042566725133, w0=-0.951918154052976, w1=-1.4915552410360067, w2=-0.023995449908196922, w3=0.3975764873892818, w4=1.269527075919318, w5=5.040183758971014, w6=2.5346958636883126\n",
      "Gradient Descent(144/499): loss=-0.580767434163469, w0=-0.9432971495632095, w1=-1.4929966023713666, w2=-0.037126063800713094, w3=0.3819296192610907, w4=1.2529612240616395, w5=5.035474042323702, w6=2.5343083466209175\n",
      "Gradient Descent(145/499): loss=-0.579255388669568, w0=-0.9347063913265019, w1=-1.4944573800747698, w2=-0.05021530861535258, w3=0.36637883773355134, w4=1.2365034763902867, w5=5.030784042886142, w6=2.5339469244074686\n",
      "Gradient Descent(146/499): loss=-0.5777677039043236, w0=-0.9261458339781489, w1=-1.4959370775124203, w2=-0.06326311828017657, w3=0.35092346490649634, w4=1.2201533796393516, w5=5.026113623612451, w6=2.533610938817164\n",
      "Gradient Descent(147/499): loss=-0.5763039721082818, w0=-0.9176154341350504, w1=-1.4974352083721172, w2=-0.07626943186938927, w3=0.3355628250201548, w4=1.203910478563314, w5=5.0214626482262075, w6=2.5332997525599024\n",
      "Gradient Descent(148/499): loss=-0.5748637937841842, w0=-0.9091151501239799, w1=-1.4989512964368177, w2=-0.08923419340685483, w3=0.32029624460013717, w4=1.1877743160082632, w5=5.016830981244323, w6=2.533012748303552\n",
      "Gradient Descent(149/499): loss=-0.5734467774442535, w0=-0.9006449417293719, w1=-1.5004848753624853, w2=-0.10215735168157675, w3=0.3051230525938334, w4=1.171744432980951, w5=5.012218487998344, w6=2.5327493277441846\n",
      "Gradient Descent(150/499): loss=-0.5720525393689634, w0=-0.892204769959451, w1=-1.5020354884602714, w2=-0.11503886007433514, w3=0.2900425804985842, w4=1.1558203687158215, w5=5.007625034653363, w6=2.532508910726539\n",
      "Gradient Descent(151/499): loss=-0.5706807033766879, w0=-0.8837945968295892, w1=-1.5036026884830636, w2=-0.12787867639472775, w3=0.2750541624819788, w4=1.1400016607401593, w5=5.003050488224695, w6=2.5322909344120803\n",
      "Gradient Descent(152/499): loss=-0.5693309006036629, w0=-0.8754143851618426, w1=-1.5051860374164179, w2=-0.14067676272790716, w3=0.26015713549461744, w4=1.1242878449374885, w5=4.99849471659248, w6=2.5320948524921723\n",
      "Gradient Descent(153/499): loss=-0.5680027692937131, w0=-0.867064098399677, w1=-1.506785106273878, w2=-0.15343308529035232, w3=0.24535083937567165, w4=1.1086784556093472, w5=4.993957588514334, w6=2.531920134443979\n",
      "Gradient Descent(154/499): loss=-0.5666959545972338, w0=-0.8587437004369486, w1=-1.5083994748966725, w2=-0.16614761429405348, w3=0.2306346169515609, w4=1.093173025535559, w5=4.989438973636213, w6=2.531766264826838\n",
      "Gradient Descent(155/499): loss=-0.5654101083789417, w0=-0.8504531554602587, w1=-1.5100287317577736, w2=-0.1788203238185301, w3=0.21600781412805659, w4=1.0777710860331118, w5=4.984938742501588, w6=2.531632742616949\n",
      "Gradient Descent(156/499): loss=-0.5641448890339334, w0=-0.8421924278038523, w1=-1.5116724737702858, w2=-0.19145119169013824, w3=0.20146977997611307, w4=1.0624721670137531, w5=4.980456766559065, w6=2.5315190805783305\n",
      "Gradient Descent(157/499): loss=-0.5628999613116168, w0=-0.8339614818162782, w1=-1.5133303061001298, w2=-0.20404019936815893, w3=0.18701986681171573, w4=1.0472757970403994, w5=4.975992918168567, w6=2.5314248046680996\n",
      "Gradient Descent(158/499): loss=-0.5616749961471008, w0=-0.8257602817380713, w1=-1.515001841982976, w2=-0.21658733183719256, w3=0.17265743027002575, w4=1.0321815033824555, w5=4.971547070606164, w6=2.5313494534742165\n",
      "Gradient Descent(159/499): loss=-0.5604696704996561, w0=-0.8175887915897639, w1=-1.5166867025453805, w2=-0.22909257750541498, w3=0.158381829374092, w4=1.0171888120701318, w5=4.967119098067682, w6=2.53129257768394\n",
      "Gradient Descent(160/499): loss=-0.5592836671978734, w0=-0.8094469750695696, w1=-1.5183845166300614, w2=-0.2415559281082803, w3=0.1441924265983899, w4=1.0022972479478425, w5=4.9627088756711535, w6=2.5312537395813144\n",
      "Gradient Descent(161/499): loss=-0.5581166747911712, w0=-0.8013347954601224, w1=-1.5200949206252627, w2=-0.25397737861728326, w3=0.13008858792743844, w4=0.9875063347267603, w5=4.958316279458216, w6=2.531232512572108\n",
      "Gradient Descent(162/499): loss=-0.5569683874073217, w0=-0.7932522155436923, w1=-1.5218175582981355, w2=-0.2663569271534194, w3=0.11606968290973628, w4=0.9728155950366026, w5=4.953941186394539, w6=2.5312284807346828\n",
      "Gradient Descent(163/499): loss=-0.5558385046156802, w0=-0.785199197525328, w1=-1.5235520806320704, w2=-0.278694574905006, w3=0.10213508470724933, w4=0.9582245504767126, w5=4.949583474369356, w6=2.5312412383953737\n",
      "Gradient Descent(164/499): loss=-0.5547267312958234, w0=-0.7771757029634128, w1=-1.525298145667912, w2=-0.2909903260495488, w3=0.08828417014067257, w4=0.9437327216664989, w5=4.945243022194171, w6=2.5312703897270126\n",
      "Gradient Descent(165/499): loss=-0.553632777511313, w0=-0.7691816927071486, w1=-1.5270554183489813, w2=-0.3032441876793622, w3=0.07451631973068036, w4=0.9293396282952908, w5=4.940919709600715, w6=2.531315548369308\n",
      "Gradient Descent(166/499): loss=-0.5525563583883224, w0=-0.7612171268405125, w1=-1.5288235703698305, w2=-0.3154561697306693, w3=0.06083091773537082, w4=0.9150447891716607, w5=4.936613417238219, w6=2.531376337069857\n",
      "Gradient Descent(167/499): loss=-0.5514971939988728, w0=-0.7532819646322548, w1=-1.530602280028657, w2=-0.3276262849159278, w3=0.04722735218410111, w4=0.9008477222722616, w5=4.932324026670046, w6=2.5314523873446357\n",
      "Gradient Descent(168/499): loss=-0.5504550092484426, w0=-0.745376164491538, w1=-1.532391232083298, w2=-0.33975454865914567, w3=0.033705014907902536, w4=0.8867479447902253, w5=4.928051420369769, w6=2.5315433391568565\n",
      "Gradient Descent(169/499): loss=-0.5494295337677257, w0=-0.7374996839288334, w1=-1.534190117610728, w2=-0.3518409790339659, w3=0.02026330156665621, w4=0.8727449731831577, w5=4.923795481716719, w6=2.5316488406131636\n",
      "Gradient Descent(170/499): loss=-0.5484205018083249, w0=-0.7296524795217204, w1=-1.5359986338699834, w2=-0.3638855967043169, w3=0.006901611673202187, w4=0.8588383232207697, w5=4.919556094991069, w6=2.5317685476761733\n",
      "Gradient Descent(171/499): loss=-0.5474276521421818, w0=-0.7218345068852524, w1=-1.5378164841684334, w2=-0.3758884248674382, w3=-0.006380651385452506, w4=0.8450275100321751, w5=4.915333145368502, w6=2.5319021238924244\n",
      "Gradient Descent(172/499): loss=-0.5464507279645513, w0=-0.7140457206465727, w1=-1.5396433777313234, w2=-0.3878494891991047, w3=-0.019584080329668963, w4=0.8313120481528836, w5=4.911126518914489, w6=2.532049240134855\n",
      "Gradient Descent(173/499): loss=-0.5454894768003438, w0=-0.7062860744234842, w1=-1.5414790295745096, w2=-0.39976881780088774, w3=-0.03270926397130369, w4=0.8176914515715137, w5=4.906936102578245, w6=2.5322095743589697\n",
      "Gradient Descent(174/499): loss=-0.5445436504136625, w0=-0.698555520806695, w1=-1.543323160380312, w2=-0.41164644114929894, w3=-0.04575678720028409, w4=0.8041652337762486, w5=4.902761784186377, w6=2.5323828113719036\n",
      "Gradient Descent(175/499): loss=-0.5436130047203797, w0=-0.690854011345476, w1=-1.5451754963764073, w2=-0.4234823920466788, w3=-0.05872723097349483, w4=0.7907329078010538, w5=4.898603452436267, w6=2.5325686426136302\n",
      "Gradient Descent(176/499): loss=-0.5426972997035953, w0=-0.6831814965364856, w1=-1.547035769217688, w2=-0.4352767055736989, w3=-0.07162117230584426, w4=0.7773939862716711, w5=4.894460996889229, w6=2.5327667659496114\n",
      "Gradient Descent(177/499): loss=-0.5417962993318415, w0=-0.6755379258155315, w1=-1.5489037158710128, w2=-0.44702941904335736, w3=-0.08443918426338612, w4=0.7641479814514046, w5=4.890334307963468, w6=2.532976885474213\n",
      "Gradient Descent(178/499): loss=-0.5409097714798909, w0=-0.6679232475520492, w1=-1.5507790785027769, w2=-0.4587405719563571, w3=-0.09718183595837791, w4=0.7509944052867075, w5=4.886223276926856, w6=2.533198711324256\n",
      "Gradient Descent(179/499): loss=-0.5400374878520486, w0=-0.6603374090460973, w1=-1.552661604369228, w2=-0.4704102059577641, w3=-0.10984969254616314, w4=0.7379327694525792, w5=4.882127795889576, w6=2.5334319595021024\n",
      "Gradient Descent(180/499): loss=-0.5391792239077984, w0=-0.6527803565276753, w1=-1.5545510457094616, w2=-0.4820383647948509, w3=-0.12244331522377, w4=0.7249625853977792, w5=4.878047757796641, w6=2.5336763517077143\n",
      "Gradient Descent(181/499): loss=-0.5383347587896992, w0=-0.6452520351581869, w1=-1.5564471596410203, w2=-0.49362509427603785, w3=-0.1349632612301246, w4=0.7120833643898605, w5=4.87398305642031, w6=2.5339316151791493\n",
      "Gradient Descent(182/499): loss=-0.5375038752534163, w0=-0.6377523890338781, w1=-1.5583497080580373, w2=-0.5051704422308524, w3=-0.14741008384778173, w4=0.6992946175600259, w5=4.869933586352435, w6=2.5341974825409896\n",
      "Gradient Descent(183/499): loss=-0.5366863595997902, w0=-0.6302813611910941, w1=-1.560258457531849, w2=-0.5166744584708323, w3=-0.15978433240608175, w4=0.6865958559478068, w5=4.865899242996742, w6=2.534473691660228\n",
      "Gradient Descent(184/499): loss=-0.5358820016088461, w0=-0.6228388936132055, w1=-1.5621731792140197, w2=-0.528137194751304, w3=-0.17208655228564576, w4=0.673986590545564, w5=4.861879922561083, w6=2.5347599855091665\n",
      "Gradient Descent(185/499): loss=-0.5350905944756523, w0=-0.615424927239066, w1=-1.5640936487417092, w2=-0.5395587047339759, w3=-0.18431728492412688, w4=0.6614663323428059, w5=4.857875522049657, w6=2.5350561120348996\n",
      "Gradient Descent(186/499): loss=-0.5343119347479444, w0=-0.6080394019728707, w1=-1.5660196461453237, w2=-0.5509390439502861, w3=-0.19647706782313942, w4=0.6490345923703219, w5=4.853885939255224, w6=2.535361824034987\n",
      "Gradient Descent(187/499): loss=-0.5335458222654322, w0=-0.600682256695293, w1=-1.56795095575839, w2=-0.5622782697654564, w3=-0.20856643455629134, w4=0.6366908817441229, w5=4.849911072751327, w6=2.5356768790389377\n",
      "Gradient Descent(188/499): loss=-0.5327920601007163, w0=-0.5933534292757874, w1=-1.569887366129591, w2=-0.5735764413432005, w3=-0.22058591477825043, w4=0.6244347117091846, w5=4.845950821884533, w6=2.5360010391951544\n",
      "Gradient Descent(189/499): loss=-0.5320504545017372, w0=-0.5860528565859489, w1=-1.571828669936909, w2=-0.584833619611047, w3=-0.2325360342347774, w4=0.6122655936829834, w5=4.8420050867667, w6=2.5363340711630027\n",
      "Gradient Descent(190/499): loss=-0.5313208148356956, w0=-0.5787804745138302, w1=-1.5737746639038173, w2=-0.5960498672262331, w3=-0.24441731477366335, w4=0.600183039298817, w5=4.838073768267289, w6=2.5366757460096907\n",
      "Gradient Descent(191/499): loss=-0.5306029535343748, w0=-0.5715362179791237, w1=-1.5757251487174648, w2=-0.6072252485421363, w3=-0.25623027435651236, w4=0.5881865604489003, w5=4.834156768005727, w6=2.537025839111667\n",
      "Gradient Descent(192/499): loss=-0.5298966860408062, w0=-0.5643200209491189, w1=-1.5776799289488048, w2=-0.6183598295752097, w3=-0.2679754270713131, w4=0.5762756693272251, w5=4.83025398834382, w6=2.5373841300602558\n",
      "Gradient Descent(193/499): loss=-0.5292018307572215, w0=-0.5571318164553546, w1=-1.5796388129746104, w2=-0.6294536779723904, w3=-0.2796532831457469, w4=0.5644498784721728, w5=4.826365332378247, w6=2.537750402571269\n",
      "Gradient Descent(194/499): loss=-0.5285182089942374, w0=-0.5499715366108888, w1=-1.5816016129013302, w2=-0.6405068629789558, w3=-0.29126434896118175, w4=0.5527087008088684, w5=4.822490703933112, w6=2.5381244443983513\n",
      "Gradient Descent(195/499): loss=-0.5278456449212202, w0=-0.5428391126281152, w1=-1.583568144490732, w2=-0.6515194554068022, w3=-0.30280912706730634, w4=0.5410516496912634, w5=4.818630007552588, w6=2.538506047249825\n",
      "Gradient Descent(196/499): loss=-0.5271839655177853, w0=-0.5357344748370584, w1=-1.5855382270872889, w2=-0.662491527603124, w3=-0.3142881161973586, w4=0.5294782389439345, w5=4.814783148493637, w6=2.5388950067088203\n",
      "Gradient Descent(197/499): loss=-0.5265330005263831, w0=-0.5286575527040869, w1=-1.587511683547261, w2=-0.6734231534194742, w3=-0.3257018112839079, w4=0.5179879829035856, w5=4.81095003271883, w6=2.5392911221564853\n",
      "Gradient Descent(198/499): loss=-0.52589258240593, w0=-0.5216082748509849, w1=-1.5894883401694246, w2=-0.6843144081811883, w3=-0.33705070347515137, w4=0.5065803964602391, w5=4.807130566889249, w6=2.539694196698086\n",
      "Gradient Descent(199/499): loss=-0.5252625462864445, w0=-0.514586569074329, w1=-1.5914680266274095, w2=-0.6951653686571558, w3=-0.3483352801516867, w4=0.495254995098104, w5=4.8033246583574964, w6=2.5401040370918166\n",
      "Gradient Descent(200/499): loss=-0.5246427299246484, w0=-0.5075923623651182, w1=-1.5934505759035964, w2=-0.7059761130299261, w3=-0.35955602494372785, w4=0.48401129493610556, w5=4.799532215160802, w6=2.5405204536801533\n",
      "Gradient Descent(201/499): loss=-0.5240329736604984, w0=-0.5006255809286129, w1=-1.5954358242245386, w2=-0.7167467208661353, w3=-0.3707134177487299, w4=0.4728488127680645, w5=4.795753146014233, w6=2.5409432603235924\n",
      "Gradient Descent(202/499): loss=-0.523433120374613, w0=-0.4936861502043359, w1=-1.5974236109978615, w2=-0.727477273087244, w3=-0.3818079347493925, w4=0.4617670661025107, w5=4.7919873603040095, w6=2.5413722743366263\n",
      "Gradient Descent(203/499): loss=-0.5228430154465636, w0=-0.48677399488619727, w1=-1.599413778750605, w2=-0.7381678519405757, w3=-0.3928400484320134, w4=0.45076557320211863, w5=4.7882347680809305, w6=2.541807316425819\n",
      "Gradient Descent(204/499): loss=-0.5222625067139983, w0=-0.47988903894270374, w1=-1.6014061730689695, w2=-0.7488185409706487, w3=-0.4038102276051645, w4=0.4398438531227499, w5=4.784495280053905, w6=2.542248210629851\n",
      "Gradient Descent(205/499): loss=-0.5216914444325687, w0=-0.4730312056372189, w1=-1.6034006425394256, w2=-0.7594294249907932, w3=-0.4147189374186648, w4=0.42900142575209066, w5=4.780768807583595, w6=2.5426947842614163\n",
      "Gradient Descent(206/499): loss=-0.521129681236635, w0=-0.46620041754824093, w1=-1.6053970386911571, w2=-0.7700005900550477, w3=-0.4255666393828269, w4=0.41823781184786984, w5=4.777055262676166, w6=2.5431468678508504\n",
      "Gradient Descent(207/499): loss=-0.5205770721007212, w0=-0.45939659658966775, w1=-1.6073952159397966, w2=-0.7805321234303298, w3=-0.43635379138795416, w4=0.4075525330756451, w5=4.773354557977154, w6=2.5436042950913937\n",
      "Gradient Descent(208/499): loss=-0.5200334743016971, w0=-0.45261966403102255, w1=-1.6093950315324217, w2=-0.7910241135688768, w3=-0.4470808477240673, w4=0.3969451120461444, w5=4.769666606765435, w6=2.544066902785984\n",
      "Gradient Descent(209/499): loss=-0.5194987473816634, w0=-0.4458695405176135, w1=-1.611396345493781, w2=-0.8014766500809521, w3=-0.45774825910084105, w4=0.38641507235215006, w5=4.7659913229473165, w6=2.5445345307954903\n",
      "Gradient Descent(210/499): loss=-0.5189727531115182, w0=-0.43914614609060415, w1=-1.6133990205737139, w2=-0.8118898237078156, w3=-0.46835647266773217, w4=0.3759619386049135, w5=4.762328621050724, w6=2.545007021988298\n",
      "Gradient Descent(211/499): loss=-0.5184553554551856, w0=-0.4324494002069726, w1=-1.6154029221957353, w2=-0.8222637262949537, w3=-0.4789059320342815, w4=0.3655852364700891, w5=4.758678416219511, w6=2.545484222191169\n",
      "Gradient Descent(212/499): loss=-0.5179464205344836, w0=-0.42577922175934, w1=-1.6174079184067547, w2=-0.8325984507655695, w3=-0.48939707729057375, w4=0.3552844927031752, w5=4.75504062420787, w6=2.5459659801413017\n",
      "Gradient Descent(213/499): loss=-0.5174458165946144, w0=-0.4191355290956495, w1=-1.6194138798278985, w2=-0.8428940910943299, w3=-0.49983034502783974, w4=0.34505923518445164, w5=4.751415161374851, w6=2.5464521474395174\n",
      "Gradient Descent(214/499): loss=-0.5169534139702622, w0=-0.41251824003867865, w1=-1.6214206796064101, w2=-0.8531507422813699, w3=-0.5102061683591868, w4=0.3349089929534037, w5=4.747801944678987, w6=2.5469425785045137\n",
      "Gradient Descent(215/499): loss=-0.5164690850522752, w0=-0.4059272719053711, w1=-1.623428193368596, w2=-0.8633685003265528, w3=-0.5205249769404442, w4=0.3248332962426215, w5=4.74420089167303, w6=2.5474371305281203\n",
      "Gradient Descent(216/499): loss=-0.5159927042549229, w0=-0.3993625415259722, w1=-1.625436299173794, w2=-0.8735474622039868, w3=-0.530787196991111, w4=0.31483167651116595, w5=4.740611920498777, w6=2.5479356634315056\n",
      "Gradient Descent(217/499): loss=-0.5155241479837082, w0=-0.392823965262957, w1=-1.6274448774693364, w2=-0.8836877258367983, w3=-0.5409932513153939, w4=0.3049036664773915, w5=4.737034949882014, w6=2.548438039822276\n",
      "Gradient Descent(218/499): loss=-0.5150632946037234, w0=-0.3863114590297382, w1=-1.6294538110464798, w2=-0.8937893900721604, w3=-0.5511435593233254, w4=0.29504880015121776, w5=4.733469899127547, w6=2.5489441249524267\n",
      "Gradient Descent(219/499): loss=-0.5146100244085341, w0=-0.3798249383091448, w1=-1.6314629849972822, w2=-0.9038525546565798, w3=-0.5612385370519509, w4=0.2852666128658414, w5=4.729916688114335, w6=2.549453786677094\n",
      "Gradient Descent(220/499): loss=-0.5141642195895801, w0=-0.3733643181716616, w1=-1.633472286672398, w2=-0.9138773202114412, w3=-0.5712785971865759, w4=0.2755566413088801, w5=4.726375237290723, w6=2.5499668954140677\n",
      "Gradient Descent(221/499): loss=-0.5137257642060787, w0=-0.36692951329342055, w1=-1.6354816056397712, w2=-0.9238637882088102, w3=-0.581264149082063, w4=0.2659184235529431, w5=4.722845467669766, w6=2.550483324104033\n",
      "Gradient Descent(222/499): loss=-0.5132945441554199, w0=-0.36052043797393857, w1=-1.6374908336442002, w2=-0.9338120609474964, w3=-0.591195598784172, w4=0.25635149908561966, w5=4.719327300824644, w6=2.5510029481714915\n",
      "Gradient Descent(223/499): loss=-0.5128704471440428, w0=-0.3541370061535933, w1=-1.639499864567757, w2=-0.9437222415293766, w3=-0.6010733490509342, w4=0.246855408838881, w5=4.7158206588841685, w6=2.5515256454863455\n",
      "Gradient Descent(224/499): loss=-0.5124533626587808, w0=-0.34777913143083233, w1=-1.6415085943910337, w2=-0.9535944338359812, w3=-0.6108977993740531, w4=0.237429695217889, w5=4.7123254645283765, w6=2.5520512963261006\n",
      "Gradient Descent(225/499): loss=-0.5120431819386664, w0=-0.3414467270791108, w1=-1.6435169211552, w2=-0.9634287425053426, w3=-0.6206693460003251, w4=0.22807390212920747, w5=4.708841640984215, w6=2.5525797833386688\n",
      "Gradient Descent(226/499): loss=-0.5116397979471853, w0=-0.335139706063553, w1=-1.6455247449248496, w2=-0.973225272909109, w3=-0.6303883819530745, w4=0.21878757500841065, w5=4.705369112021297, w6=2.5531109915057404\n",
      "Gradient Descent(227/499): loss=-0.5112431053449716, w0=-0.3288579810573345, w1=-1.6475319677516131, w2=-0.9829841311299229, w3=-0.6400552970535943, w4=0.20957026084708558, w5=4.701907801947757, w6=2.553644808106704\n",
      "Gradient Descent(228/499): loss=-0.5108530004629329, w0=-0.32260146445778237, w1=-1.6495384936385245, w2=-0.9927054239390676, w3=-0.6496704779425903, w4=0.2004215082192244, w5=4.698457635606167, w6=2.55418112268309\n",
      "Gradient Descent(229/499): loss=-0.5104693812757983, w0=-0.3163700684021903, w1=-1.6515442285051152, w2=-1.0023892587743808, w3=-0.6592343081016191, w4=0.19134086730700364, w5=4.695018538369541, w6=2.5547198270035203\n",
      "Gradient Descent(230/499): loss=-0.5100921473760818, w0=-0.31016370478334754, w1=-1.653549080153223, w2=-1.012035743718438, w3=-0.6687471678745197, w4=0.18232788992594823, w5=4.691590436137414, w6=2.5552608150291425\n",
      "Gradient Descent(231/499): loss=-0.50972119994845, w0=-0.3039822852647805, w1=-1.6555529582334958, w2=-1.0216449874770062, w3=-0.6782094344888296, w4=0.17338212954947774, w5=4.6881732553319875, w6=2.5558039828795365\n",
      "Gradient Descent(232/499): loss=-0.50935644174449, w0=-0.2978257212957055, w1=-1.6575557742125722, w2=-1.0312170993577685, w3=-0.6876214820771833, w4=0.16450314133283372, w5=4.68476692289435, w6=2.5563492287990712\n",
      "Gradient Descent(233/499): loss=-0.5089977770578682, w0=-0.291693924125693, w1=-1.6595574413409249, w2=-1.0407521892493217, w3=-0.6969836816986886, w4=0.1556904821363869, w5=4.681371366280766, w6=2.556896453123703\n",
      "Gradient Descent(234/499): loss=-0.5086451116998726, w0=-0.2855868048190432, w1=-1.6615578746213484, w2=-1.0502503676004469, w3=-0.7062964013602765, w4=0.14694371054832353, w5=4.677986513459027, w6=2.5574455582481983\n",
      "Gradient Descent(235/499): loss=-0.5082983529753341, w0=-0.2795042742688728, w1=-1.6635569907780763, w2=-1.059711745399654, w3=-0.7155600060380204, w4=0.13826238690671108, w5=4.674612292904872, w6=2.5579964485937725\n",
      "Gradient Descent(236/499): loss=-0.5079574096589164, w0=-0.2734462432109149, w1=-1.6655547082265112, w2=-1.0691364341550016, w3=-0.7247748576984226, w4=0.1296460733209431, w5=4.671248633598463, w6=2.558549030576132\n",
      "Gradient Descent(237/499): loss=-0.5076221919717735, w0=-0.26741262223703166, w1=-1.6675509470435557, w2=-1.0785245458741906, w3=-0.7339413153196632, w4=0.12109433369256434, w5=4.667895465020929, w6=2.5591032125739073\n",
      "Gradient Descent(238/499): loss=-0.5072926115585614, w0=-0.26140332180844283, w1=-1.6695456289385253, w2=-1.087876193044936, w3=-0.7430597349128087, w4=0.11260673373547703, w5=4.664552717150958, w6=2.5596589048974736\n",
      "Gradient Descent(239/499): loss=-0.506968581464806, w0=-0.2554182522686699, w1=-1.6715386772246341, w2=-1.0971914886156147, w3=-0.752130469542978, w4=0.10418284099553017, w5=4.66122032046145, w6=2.560216019758145\n",
      "Gradient Descent(240/499): loss=-0.5066500161146152, w0=-0.24945732385619906, w1=-1.6735300167910345, w2=-1.1064705459761868, w3=-0.7611538693504618, w4=0.09582222486949346, w5=4.6578982059162275, w6=2.560774471237737\n",
      "Gradient Descent(241/499): loss=-0.5063368312887334, w0=-0.2435204467168653, w1=-1.675519574075402, w2=-1.115713478939399, w3=-0.7701302815717938, w4=0.0875244566234184, w5=4.654586304966785, w6=2.5613341752584935\n",
      "Gradient Descent(242/499): loss=-0.5060289441029303, w0=-0.2376075309159584, w1=-1.6775072770370494, w2=-1.12492040172226, w3=-0.7790600505607702, w4=0.07928910941038923, w5=4.6512845495491035, w6=2.5618950495533634\n",
      "Gradient Descent(243/499): loss=-0.5057262729867209, w0=-0.23171848645005552, w1=-1.6794930551305576, w2=-1.1340914289277966, w3=-0.7879435178094162, w4=0.07111575828766675, w5=4.647992872080501, w6=2.562457013636633\n",
      "Gradient Descent(244/499): loss=-0.5054287376624104, w0=-0.22585322325858107, w1=-1.6814768392799142, w2=-1.1432266755270835, w3=-0.7967810219688953, w4=0.06300398023322851, w5=4.6447112054565345, w6=2.5630199887748994\n",
      "Gradient Descent(245/499): loss=-0.5051362591244597, w0=-0.22001165123509844, w1=-1.6834585618531424, w2=-1.1523262568415518, w3=-0.8055728988703619, w4=0.05495335416170897, w5=4.641439483047948, w6=2.563583897958383\n",
      "Gradient Descent(246/499): loss=-0.5048487596191652, w0=-0.2141936802383353, w1=-1.6854381566374135, w2=-1.1613902885255731, w3=-0.814319481545752, w4=0.046963460939743906, w5=4.638177638697659, w6=2.5641486658725787\n",
      "Gradient Descent(247/499): loss=-0.50456616262465, w0=-0.20839922010294654, w1=-1.6874155588146293, w2=-1.1704188865493188, w3=-0.8230211002485127, w4=0.0390338834007232, w5=4.634925606717783, w6=2.564714218870233\n",
      "Gradient Descent(248/499): loss=-0.5042883928311612, w0=-0.20262818065001728, w1=-1.689390704937463, w2=-1.1794121671818942, w3=-0.8316780824742671, w4=0.03116420635895694, w5=4.631683321886708, w6=2.5652804849436563\n",
      "Gradient Descent(249/499): loss=-0.5040153761216675, w0=-0.19688047169731052, w1=-1.6913635329058503, w2=-1.1883702469747486, w3=-0.8402907529814126, w4=0.02335401662325944, w5=4.628450719446198, w6=2.5658473936973545\n",
      "Gradient Descent(250/499): loss=-0.5037470395527548, w0=-0.1911560030692614, w1=-1.6933339819439173, w2=-1.1972932427453569, w3=-0.8488594338116523, w4=0.015602903009956776, w5=4.625227735098529, w6=2.566414876320984\n",
      "Gradient Descent(251/499): loss=-0.503483311335815, w0=-0.18545468460672293, w1=-1.6953019925773378, w2=-1.2061812715611757, w3=-0.8573844443104555, w4=0.00791045635532299, w5=4.622014305003676, w6=2.5669828655626272\n",
      "Gradient Descent(252/499): loss=-0.503224120818521, w0=-0.17977642617646583, w1=-1.6972675066111076, w2=-1.2150344507238697, w3=-0.8658661011474479, w4=0.0002762695274508148, w5=4.61881036577651, w6=2.5675512957023825\n",
      "Gradient Descent(253/499): loss=-0.5029693984665886, w0=-0.17412113768043713, w1=-1.6992304671077285, w2=-1.223852897753809, w3=-0.8743047183367288, w4=-0.007300062562437195, w5=4.615615854484047, w6=2.5681201025262705\n",
      "Gradient Descent(254/499): loss=-0.5027190758458169, w0=-0.16848872906478018, w1=-1.7011908183657918, w2=-1.232636730374836, w3=-0.8827006072571142, w4=-0.014818942949230958, w5=4.612430708642716, w6=2.5686892233004524\n",
      "Gradient Descent(255/499): loss=-0.5024730856044053, w0=-0.16287911032862074, w1=-1.7031485058989513, w2=-1.2413860664993002, w3=-0.8910540766723027, w4=-0.022280772603722267, w5=4.6092548662156565, w6=2.569258596745757\n",
      "Gradient Descent(256/499): loss=-0.5022313614555437, w0=-0.1572921915326223, w1=-1.7051034764152782, w2=-1.250101024213359, w3=-0.8993654327509667, w4=-0.029685950422934725, w5=4.606088265610051, w6=2.569828163012519\n",
      "Gradient Descent(257/499): loss=-0.5019938381602698, w0=-0.1517278828073154, w1=-1.7070556777969894, w2=-1.2587817217625439, w3=-0.9076349790867625, w4=-0.037034873220987585, w5=4.602930845674474, w6=2.5703978636557214\n",
      "Gradient Descent(258/499): loss=-0.5017604515105915, w0=-0.14618609436120325, w1=-1.7090050590805406, w2=-1.26742827753759, w3=-0.9158630167182622, w4=-0.0443279357204865, w5=4.599782545696273, w6=2.5709676416104466\n",
      "Gradient Descent(259/499): loss=-0.5015311383128717, w0=-0.14066673648864933, w1=-1.7109515704370744, w2=-1.2760408100605278, w3=-0.924049844148804, w4=-0.05156553054443425, w5=4.596643305398972, w6=2.5715374411676275\n",
      "Gradient Descent(260/499): loss=-0.5013058363714672, w0=-0.1351697195775495, w1=-1.7128951631532194, w2=-1.284619437971034, w3=-0.9321957573662597, w4=-0.058748048208654244, w5=4.593513064939696, w6=2.5721072079501033\n",
      "Gradient Descent(261/499): loss=-0.5010844844726255, w0=-0.12969495411679305, w1=-1.7148357896122284, w2=-1.2931642800130412, w3=-0.9403010498627193, w4=-0.06587587711471944, w5=4.590391764906619, w6=2.572676888888975\n",
      "Gradient Descent(262/499): loss=-0.500867022368628, w0=-0.12424235070351651, w1=-1.7167734032754502, w2=-1.301675455021603, w3=-0.9483660126540907, w4=-0.0729494035433794, w5=4.587279346316435, w6=2.573246432200262\n",
      "Gradient Descent(263/499): loss=-0.5006533907621815, w0=-0.11881182005015432, w1=-1.7187079586641294, w2=-1.3101530819100147, w3=-0.9563909342996131, w4=-0.07996901164847779, w5=4.584175750611841, w6=2.5738157873618546\n",
      "Gradient Descent(264/499): loss=-0.5004435312910533, w0=-0.1134032729912895, w1=-1.7206394113415229, w2=-1.318597279657184, w3=-0.9643761009212843, w4=-0.08693508345135276, w5=4.581080919659051, w6=2.5743849050907657\n",
      "Gradient Descent(265/499): loss=-0.5002373865129454, w0=-0.10801662049030909, w1=-1.7225677178953307, w2=-1.3270081672952543, w3=-0.9723217962231997, w4=-0.09384799883571254, w5=4.577994795745318, w6=2.5749537373206755\n",
      "Gradient Descent(266/499): loss=-0.5000348998906055, w0=-0.10265177364586772, w1=-1.7244928359204315, w2=-1.3353858638974725, w3=-0.980228301510802, w4=-0.10070813554297842, w5=4.574917321576476, w6=2.575522237179772\n",
      "Gradient Descent(267/499): loss=-0.49983601577717024, w0=-0.0973086436981627, w1=-1.7264147240019168, w2=-1.343730488566306, w3=-0.9880958957100416, w4=-0.10751586916808713, w5=4.5718484402745005, w6=2.5760903589688855\n",
      "Gradient Descent(268/499): loss=-0.49964067940174084, w0=-0.09198714203502537, w1=-1.7283333416984192, w2=-1.3520421604217996, w3=-0.9959248553864464, w4=-0.11427157315574493, w5=4.5687880953750835, w6=2.5766580581399103\n",
      "Gradient Descent(269/499): loss=-0.4994488368551817, w0=-0.08668718019783157, w1=-1.730248649525726, w2=-1.3603209985901759, w3=-1.003715454764098, w4=-0.12097561879712523, w5=4.565736230825222, w6=2.5772252912745213\n",
      "Gradient Descent(270/499): loss=-0.49926043507614587, w0=-0.08140866988723532, w1=-1.7321606089406736, w2=-1.3685671221926716, w3=-1.0114679657445185, w4=-0.1276283752270018, w5=4.562692790980822, w6=2.577792016063177\n",
      "Gradient Descent(271/499): loss=-0.4990754218373193, w0=-0.07615152296872961, w1=-1.734069182325317, w2=-1.3767806503346125, w3=-1.0191826579254597, w4=-0.1342302094213095, w5=4.5596577206043145, w6=2.57835819128441\n",
      "Gradient Descent(272/499): loss=-0.49889374573188233, w0=-0.07091565147803724, w1=-1.7359743329713682, w2=-1.384961702094719, w3=-1.0268597986196017, w4=-0.14078148619512454, w5=4.556630964862286, w6=2.5789237767844027\n",
      "Gradient Descent(273/499): loss=-0.498715356160186, w0=-0.06570096762633615, w1=-1.7378760250648984, w2=-1.3931103965146445, w3=-1.0344996528731543, w4=-0.14728256820105598, w5=4.553612469323124, w6=2.5794887334568504\n",
      "Gradient Descent(274/499): loss=-0.4985402033166389, w0=-0.060507383805322175, w1=-1.7397742236712972, w2=-1.401226852588742, w3=-1.0421024834843626, w4=-0.1537338159280406, w5=4.550602179954662, w6=2.5800530232231034\n",
      "Gradient Descent(275/499): loss=-0.4983682381768032, w0=-0.055334812592112946, w1=-1.7416688947204861, w2=-1.4093111892540544, w3=-1.0496685510219168, w4=-0.16013558770053282, w5=4.5476000431218555, w6=2.5806166090125924\n",
      "Gradient Descent(276/499): loss=-0.4981994124846945, w0=-0.050183166753996464, w1=-1.7435600049923792, w2=-1.4173635253805308, w3=-1.0571981138432638, w4=-0.16648823967808163, w5=4.544606005584448, w6=2.5811794547435345\n",
      "Gradient Descent(277/499): loss=-0.4980336787402853, w0=-0.045052359253027606, w1=-1.7454475221025854, w2=-1.4253839797614598, w3=-1.064691428112821, w4=-0.17279212585528655, w5=4.541620014494662, w6=2.581741525303915\n",
      "Gradient Descent(278/499): loss=-0.49787099018720754, w0=-0.03994230325047622, w1=-1.7473314144883512, w2=-1.4333726711041235, w3=-1.0721487478200915, w4=-0.1790475980621244, w5=4.538642017394892, w6=2.5823027865327477\n",
      "Gradient Descent(279/499): loss=-0.49771130080065124, w0=-0.034852912111129675, w1=-1.7492116513947342, w2=-1.4413297180206632, w3=-1.0795703247976798, w4=-0.1852550059646388, w5=4.5356719622154085, w6=2.5828632052016083\n",
      "Gradient Descent(280/499): loss=-0.49755456527545766, w0=-0.029784099407453593, w1=-1.7510882028610066, w2=-1.4492552390191604, w3=-1.0869564087392072, w4=-0.19141469706598457, w5=4.532709797272074, w6=2.5834227489964423\n",
      "Gradient Descent(281/499): loss=-0.49740073901440285, w0=-0.024735778923613783, w1=-1.7529610397072821, w2=-1.457149352494924, w3=-1.094307247217127, w4=-0.1975270167078187, w5=4.5297554712640595, w6=2.5839813864996426\n",
      "Gradient Descent(282/499): loss=-0.4972497781166697, w0=-0.019707864659362608, w1=-1.7548301335213632, w2=-1.4650121767219861, w3=-1.1016230857004383, w4=-0.20359230807203024, w5=4.52680893327158, w6=2.5845390871723968\n",
      "Gradient Descent(283/499): loss=-0.4971016393665059, w0=-0.014700270833792606, w1=-1.7566954566458035, w2=-1.472843829844801, w3=-1.1089041675722986, w4=-0.2096109121828012, w5=4.523870132753628, w6=2.585095821337302\n",
      "Gradient Descent(284/499): loss=-0.49695628022206384, w0=-0.009712911888961031, w1=-1.7585569821651816, w2=-1.4806444298701438, w3=-1.116150734147533, w4=-0.21558316790899013, w5=4.520939019545721, w6=2.585651560161245\n",
      "Gradient Descent(285/499): loss=-0.4968136588044216, w0=-0.00474570249338778, w1=-1.7604146838935821, w2=-1.4884140946592086, w3=-1.1233630246900417, w4=-0.22150941196683127, w5=4.518015543857651, w6=2.586206275638544\n",
      "Gradient Descent(286/499): loss=-0.49667373388678, w0=0.00020144245457002705, w1=-1.7622685363622808, w2=-1.4961529419199011, w3=-1.1305412764301044, w4=-0.22738997892294097, w5=4.5150996562712455, w6=2.5867599405743564\n",
      "Gradient Descent(287/499): loss=-0.49653646488383757, w0=0.005128607823464095, w1=-1.7641185148076275, w2=-1.5038610891993236, w3=-1.1376857245815801, w4=-0.2332252011976238, w5=4.512191307738133, w6=2.5873125285683387\n",
      "Gradient Descent(288/499): loss=-0.49640181184133364, w0=0.010035878245618494, w1=-1.7659645951591276, w2=-1.5115386538764493, w3=-1.1447966023590037, w4=-0.239015409068471, w5=4.509290449577517, w6=2.5878640139985705\n",
      "Gradient Descent(289/499): loss=-0.49626973542576513, w0=0.014923338114108203, w1=-1.767806754027713, w2=-1.5191857531549833, w3=-1.1518741409945774, w4=-0.24476093067424326, w5=4.506397033473949, w6=2.588414372005728\n",
      "Gradient Descent(290/499): loss=-0.49614019691426825, w0=0.019791071579849728, w1=-1.7696449686942028, w2=-1.5268025040564077, w3=-1.1589185697550584, w4=-0.25046209201903075, w5=4.503511011475119, w6=2.588963578477515\n",
      "Gradient Descent(291/499): loss=-0.4960131581846658, w0=0.024639162548801094, w1=-1.77147921709795, w2=-1.5343890234132072, w3=-1.1659301159585398, w4=-0.2561192169766826, w5=4.5006323359896445, w6=2.589511610033338\n",
      "Gradient Descent(292/499): loss=-0.4958885817056771, w0=0.02946769467926858, w1=-1.7733094778256684, w2=-1.5419454278622726, w3=-1.1729090049911275, w4=-0.26173262729549907, w5=4.497760959784866, w6=2.590058444009238\n",
      "Gradient Descent(293/499): loss=-0.4957664305272874, w0=0.0342767513793176, w1=-1.7751357301004385, w2=-1.5494718338384805, w3=-1.1798554603235103, w4=-0.2673026426031782, w5=4.494896835984649, w6=2.590604058443059\n",
      "Gradient Descent(294/499): loss=-0.49564666827127474, w0=0.039066415804285236, w1=-1.7769579537708893, w2=-1.5569683575684437, w3=-1.1867697035274243, w4=-0.2728295804120109, w5=4.492039918067193, w6=2.5911484320598683\n",
      "Gradient Descent(295/499): loss=-0.4955292591218924, w0=0.043836770854391874, w1=-1.7787761293005513, w2=-1.564435115064433, w3=-1.193651954292011, w4=-0.2783137561243164, w5=4.489190159862843, w6=2.5916915442576114\n",
      "Gradient Descent(296/499): loss=-0.49541416781670383, w0=0.04858789917244932, w1=-1.7805902377573788, w2=-1.571872222118465, w3=-1.2005024304400682, w4=-0.283755483038112, w5=4.486347515551908, w6=2.5922333750930084\n",
      "Gradient Descent(297/499): loss=-0.49530135963756794, w0=0.05331988314166356, w1=-1.7824002608034388, w2=-1.579279794296553, w3=-1.2073213479441947, w4=-0.2891550723530089, w5=4.483511939662487, w6=2.592773905267689\n",
      "Gradient Descent(298/499): loss=-0.49519080040177327, w0=0.058032804883529125, w1=-1.7842061806847618, w2=-1.5866579469331217, w3=-1.2141089209428277, w4=-0.294512833176329, w5=4.4806833870682965, w6=2.593313116114557\n",
      "Gradient Descent(299/499): loss=-0.4950824564533174, w0=0.06272674625581307, w1=-1.7860079802213538, w2=-1.5940067951255767, w3=-1.2208653617561733, w4=-0.299829072529434, w5=4.477861812986502, w6=2.5938509895843875\n",
      "Gradient Descent(300/499): loss=-0.49497629465433024, w0=0.06740178885062655, w1=-1.7878056427973652, w2=-1.601326453729033, w3=-1.2275908809020286, w4=-0.3051040953542624, w5=4.475047172975562, w6=2.594387508232656\n",
      "Gradient Descent(301/499): loss=-0.49487228237663855, w0=0.0720580139925814, w1=-1.7895991523514154, w2=-1.6086170373511948, w3=-1.2342856871114982, w4=-0.3103382045200653, w5=4.472239422933069, w6=2.5949226552065907\n",
      "Gradient Descent(302/499): loss=-0.49477038749347063, w0=0.07669550273702978, w1=-1.7913884933670676, w2=-1.6158786603473856, w3=-1.240949987344601, w4=-0.3155317008303368, w5=4.469438519093601, w6=2.5954564142324474\n",
      "Gradient Descent(303/499): loss=-0.4946705783712978, w0=0.08131433586838469, w1=-1.793173650863455, w2=-1.6231114368157267, w3=-1.2475839868057712, w4=-0.3206848830299318, w5=4.466644418026576, w6=2.5959887696030104\n",
      "Gradient Descent(304/499): loss=-0.4945728238618097, w0=0.08591459389851935, w1=-1.7949546103860528, w2=-1.6303154805924596, w3=-1.25418788895925, w4=-0.3257980478123639, w5=4.463857076634109, w6=2.596519706165307\n",
      "Gradient Descent(305/499): loss=-0.49447709329402467, w0=0.09049635706524359, w1=-1.796731357997595, w2=-1.6374909052474114, w3=-1.2607618955443702, w4=-0.33087148982727926, w5=4.461076452148882, w6=2.597049209308542\n",
      "Gradient Descent(306/499): loss=-0.49438335646652926, w0=0.09505970533085473, w1=-1.7985038802691329, w2=-1.6446378240795996, w3=-1.2673062065907337, w4=-0.3359055016880991, w5=4.458302502132009, w6=2.597577264952244\n",
      "Gradient Descent(307/499): loss=-0.49429158363984715, w0=0.09960471838076188, w1=-1.8002721642712334, w2=-1.651756350112974, w3=-1.2738210204332794, w4=-0.3409003739798246, w5=4.455535184470913, w6=2.598103859534621\n",
      "Gradient Descent(308/499): loss=-0.49420174552893503, w0=0.10413147562218086, w1=-1.802036197565315, w2=-1.658846596092293, w3=-1.280306533727245, w4=-0.3458563952669996, w5=4.452774457377208, w6=2.598628980001128\n",
      "Gradient Descent(309/499): loss=-0.49411381329580323, w0=0.10864005618289861, w1=-1.803795968195118, w2=-1.6659086744791312, w3=-1.2867629414630202, w4=-0.35077385210182394, w5=4.450020279384582, w6=2.5991526137932373\n",
      "Gradient Descent(310/499): loss=-0.49402775854225894, w0=0.11313053891010495, w1=-1.8055514646783075, w2=-1.6729426974480177, w3=-1.2931904369808915, w4=-0.3556530290324133, w5=4.4472726093466886, w6=2.599674748837413\n",
      "Gradient Descent(311/499): loss=-0.49394355330276973, w0=0.11760300236928985, w1=-1.807302675998209, w2=-1.6799487768827004, w3=-1.2995892119856811, w4=-0.3604942086111982, w5=4.444531406435045, w6=2.600195373534284\n",
      "Gradient Descent(312/499): loss=-0.4938611700374478, w0=0.12205752484320494, w1=-1.8090495915956684, w2=-1.6869270243725345, w3=-1.3059594565612767, w4=-0.3652976714034583, w5=4.441796630136932, w6=2.60071447674802\n",
      "Gradient Descent(313/499): loss=-0.493780581625149, w0=0.12649418433088705, w1=-1.8107922013610431, w2=-1.6938775512089939, w3=-1.312301359185054, w4=-0.3700636959959861, w5=4.439068240253301, w6=2.601232047795896\n",
      "Gradient Descent(314/499): loss=-0.4937017613566892, w0=0.13091305854674246, w1=-1.8125304956263144, w2=-1.7008004683823008, w3=-1.318615106742193, w4=-0.37479255900587405, w5=4.436346196896684, w6=2.6017480764380534\n",
      "Gradient Descent(315/499): loss=-0.4936246829281722, w0=0.13531422491969025, w1=-1.8142644651573223, w2=-1.707695886578174, w3=-1.3249008845398846, w4=-0.3794845350894214, w5=4.433630460489121, w6=2.60226255286745\n",
      "Gradient Descent(316/499): loss=-0.49354932043443034, w0=0.1396977605923628, w1=-1.815994101146123, w2=-1.7145639161746908, w3=-1.3311588763214335, w4=-0.38413989695115447, w5=4.430920991760071, w6=2.602775467699998\n",
      "Gradient Descent(317/499): loss=-0.4934756483625743, w0=0.14406374242036277, w1=-1.8177193952034614, w2=-1.721404667239262, w3=-1.3373892642802512, w4=-0.3887589153529557, w5=4.428217751744351, w6=2.603286811964885\n",
      "Gradient Descent(318/499): loss=-0.4934036415856509, w0=0.14841224697157407, w1=-1.819440339351364, w2=-1.7282182495257163, w3=-1.3435922290737436, w4=-0.3933418591232974, w5=4.42552070178007, w6=2.6037965770950784\n",
      "Gradient Descent(319/499): loss=-0.49333327535640736, w0=0.15274335052552598, w1=-1.8211569260158436, w2=-1.7350047724714943, w3=-1.3497679498370925, w4=-0.3978889951665741, w5=4.422829803506566, w6=2.6043047549180094\n",
      "Gradient Descent(320/499): loss=-0.49326452530115933, w0=0.15705712907280883, w1=-1.8228691480197177, w2=-1.7417643451949458, w3=-1.3559166041969295, w4=-0.40240058847253024, w5=4.420145018862358, w6=2.6048113376464324\n",
      "Gradient Descent(321/499): loss=-0.49319736741376297, w0=0.16135365831454007, w1=-1.824576998575539, w2=-1.7484970764927321, w3=-1.3620383682849053, w4=-0.4068769021257775, w5=4.417466310083095, w6=2.605316317869461\n",
      "Gradient Descent(322/499): loss=-0.4931317780496871, w0=0.16563301366187863, w1=-1.826280471278634, w2=-1.7552030748373297, w3=-1.3681334167511519, w4=-0.411318197315398, w5=4.414793639699522, w6=2.6058196885437734\n",
      "Gradient Descent(323/499): loss=-0.49306773392018444, w0=0.16989527023558754, w1=-1.827979560100251, w2=-1.761882448374632, w3=-1.3742019227776403, w4=-0.41572473334462884, w5=4.41212697053544, w6=2.6063214429849877\n",
      "Gradient Descent(324/499): loss=-0.4930052120865622, w0=0.17414050286564228, w1=-1.829674259380812, w2=-1.7685353049216488, w3=-1.3802440580914321, w4=-0.4200967676406237, w5=4.40946626570568, w6=2.606821574859205\n",
      "Gradient Descent(325/499): loss=-0.49294418995454753, w0=0.17836878609088413, w1=-1.83136456382327, w2=-1.7751617519643004, w3=-1.3862599929778268, w4=-0.424434555764287, w5=4.406811488614082, w6=2.607320078174716\n",
      "Gradient Descent(326/499): loss=-0.4928846452687482, w0=0.1825801941587174, w1=-1.8330504684865705, w2=-1.7817618966553046, w3=-1.3922498962934036, w4=-0.4287383514201774, w5=4.404162602951481, w6=2.607816947273867\n",
      "Gradient Descent(327/499): loss=-0.4928265561072061, w0=0.18677480102484922, w1=-1.8347319687792112, w2=-1.7883358458121548, w3=-1.3982139354789598, w4=-0.4330084064664755, w5=4.401519572693698, w6=2.608312176825089\n",
      "Gradient Descent(328/499): loss=-0.4927699008760424, w0=0.1909526803530705, w1=-1.8364090604529044, w2=-1.7948837059151863, w3=-1.4041522765723449, w4=-0.4372449709250127, w5=4.398882362099538, w6=2.6088057618150793\n",
      "Gradient Descent(329/499): loss=-0.4927146583041928, w0=0.19511390551507743, w1=-1.8380817395963358, w2=-1.8014055831057296, w3=-1.4100650842211901, w4=-0.44144829299135746, w5=4.396250935708798, w6=2.609297697541141\n",
      "Gradient Descent(330/499): loss=-0.4926608074382314, w0=0.1992585495903319, w1=-1.8397500026290199, w2=-1.8079015831843495, w3=-1.415952521695536, w4=-0.44561861904495437, w5=4.393625258340275, w6=2.6097879796036714\n",
      "Gradient Descent(331/499): loss=-0.49260832763728096, w0=0.20338668536595994, w1=-1.8414138462952512, w2=-1.8143718116091654, w3=-1.421814750900356, w4=-0.44975619365931324, w5=4.39100529508979, w6=2.6102766038988\n",
      "Gradient Descent(332/499): loss=-0.49255719856800945, w0=0.2074983853366872, w1=-1.8430732676581496, w2=-1.8208163734942548, w3=-1.4276519323879784, w4=-0.4538612596122445, w5=4.388391011328212, w6=2.6107635666111753\n",
      "Gradient Descent(333/499): loss=-0.49250740019971134, w0=0.21159372170481058, w1=-1.8447282640937968, w2=-1.8272353736081346, w3=-1.4334642253704046, w4=-0.4579340578961371, w5=4.385782372699493, w6=2.611248864206894\n",
      "Gradient Descent(334/499): loss=-0.4924589127994696, w0=0.2156727663802043, w1=-1.8463788332854643, w2=-1.8336289163723203, w3=-1.4392517877315276, w4=-0.461974827728276, w5=4.38317934511871, w6=2.6117324934265724\n",
      "Gradient Descent(335/499): loss=-0.4924117169274012, w0=0.21973559098036052, w1=-1.848024973217931, w2=-1.8399971058599611, w3=-1.4450147760392473, w4=-0.46598380656119565, w5=4.380581894770108, w6=2.61221445127856\n",
      "Gradient Descent(336/499): loss=-0.4923657934319821, w0=0.22378226683046254, w1=-1.8496666821718897, w2=-1.8463400457945487, w3=-1.450753345557486, w4=-0.46996123009306623, w5=4.377989988105165, w6=2.612694735032287\n",
      "Gradient Descent(337/499): loss=-0.49232112344544976, w0=0.22781286496349026, w1=-1.8513039587184386, w2=-1.8526578395486981, w3=-1.4564676502581027, w4=-0.4739073322781099, w5=4.37540359184065, w6=2.6131733422117494\n",
      "Gradient Descent(338/499): loss=-0.49227768837928465, w0=0.2318274561203566, w1=-1.8529368017136603, w2=-1.8589505901429997, w3=-1.4621578428327082, w4=-0.47782234533704354, w5=4.372822672956693, w6=2.613650270589126\n",
      "Gradient Descent(339/499): loss=-0.4922354699197668, w0=0.23582611075007454, w1=-1.8545652102932841, w2=-1.865218400244939, w3=-1.4678240747043796, w4=-0.4817064997675455, w5=4.370247198694869, w6=2.614125518178527\n",
      "Gradient Descent(340/499): loss=-0.4921944500236071, w0=0.23980889900995314, w1=-1.856189183867432, w2=-1.8714613721678852, w3=-1.4734664960392756, w4=-0.4855600243547427, w5=4.367677136556284, w6=2.614599083229868\n",
      "Gradient Descent(341/499): loss=-0.4921546109136533, w0=0.24377589076582246, w1=-1.8578087221154456, w2=-1.8776796078701434, w3=-1.4790852557581546, w4=-0.4893831461817165, w5=4.365112454299665, w6=2.615070964222875\n",
      "Gradient Descent(342/499): loss=-0.4921159350746657, w0=0.24772715559228595, w1=-1.8594238249807944, w2=-1.8838732089540724, w3=-1.4846805015477929, w4=-0.4931760906400232, w5=4.36255311993947, w6=2.61554115986121\n",
      "Gradient Descent(343/499): loss=-0.49207840524916785, w0=0.251662762773, w1=-1.8610344926660636, w2=-1.8900422766652645, w3=-1.4902523798723055, w4=-0.4969390814402277, w5=4.359999101743996, w6=2.6160096690667167\n",
      "Gradient Descent(344/499): loss=-0.4920420044333624, w0=0.25558278130097933, w1=-1.8626407256280195, w2=-1.8961869118917856, w3=-1.495801035984371, w4=-0.5006723406224468, w5=4.357450368233496, w6=2.6164764909737923\n",
      "Gradient Descent(345/499): loss=-0.4920067158731194, w0=0.2594872798789281, w1=-1.8642425245727527, w2=-1.9023072151634761, w3=-1.5013266139363572, w4=-0.5043760885669005, w5=4.354906888178313, w6=2.61694162492387\n",
      "Gradient Descent(346/499): loss=-0.49197252306003064, w0=0.2633763269195954, w1=-1.8658398904508962, w2=-1.9084032866513085, w3=-1.5068292565913537, w4=-0.508050544004468, w5=4.35236863059701, w6=2.6174050704600216\n",
      "Gradient Descent(347/499): loss=-0.4919394097275296, w0=0.26724999054615456, w1=-1.8674328244529192, w2=-1.9144752261668023, w3=-1.5123091056341056, w4=-0.5116959240272467, w5=4.349835564754521, w6=2.6178668273216696\n",
      "Gradient Descent(348/499): loss=-0.4919073598470777, w0=0.271108338592606, w1=-1.8690213280044952, w2=-1.920523133161494, w3=-1.5177663015818543, w4=-0.5153124440991114, w5=4.347307660160295, w6=2.6183268954394157\n",
      "Gradient Descent(349/499): loss=-0.4918763576244146, w0=0.2749514386042024, w1=-1.8706054027619408, w2=-1.9265471067264603, w3=-1.5232009837950828, w4=-0.5189003180662718, w5=4.344784886566468, w6=2.6187852749299747\n",
      "Gradient Descent(350/499): loss=-0.4918463874958703, w0=0.2787793578378954, w1=-1.872185050607728, w2=-1.9325472455918948, w3=-1.5286132904881662, w4=-0.5224597581678262, w5=4.342267213966027, w6=2.619241966091217\n",
      "Gradient Descent(351/499): loss=-0.4918174341247412, w0=0.28259216326280406, w1=-1.873760273646066, w2=-1.9385236481267343, w3=-1.5340033587399295, w4=-0.5259909750463085, w5=4.3397546125909905, w6=2.6196969693973164\n",
      "Gradient Descent(352/499): loss=-0.4917894823977248, w0=0.28638992156070303, w1=-1.8753310741985523, w2=-1.944476412338336, w3=-1.5393713245041127, w4=-0.5294941777582278, w5=4.337247052910599, w6=2.6201502854940024\n",
      "Gradient Descent(353/499): loss=-0.4917625174214154, w0=0.2901726991265317, w1=-1.8768974547998936, w2=-1.9504056358722033, w3=-1.544717322619742, w4=-0.5329695737845971, w5=4.334744505629509, w6=2.6206019151939133\n",
      "Gradient Descent(354/499): loss=-0.4917365245188589, w0=0.2939405620689215, w1=-1.8784594181936922, w2=-1.9563114160117578, w3=-1.5500414868214096, w4=-0.5364173690414503, w5=4.332246941685999, w6=2.6210518594720487\n",
      "Gradient Descent(355/499): loss=-0.49171148922616476, w0=0.29769357621074266, w1=-1.880016967328301, w2=-1.9621938496781586, w3=-1.5553439497494632, w4=-0.5398377678903457, w5=4.329754332250189, w6=2.6215001194613206\n",
      "Gradient Descent(356/499): loss=-0.49168739728917443, w0=0.3014318070896688, w1=-1.8815701053527414, w2=-1.968053033430165, w3=-1.5606248429601033, w4=-0.5432309731488526, w5=4.327266648722257, w6=2.6219466964482008\n",
      "Gradient Descent(357/499): loss=-0.49166423466018644, w0=0.30515531995875916, w1=-1.8831188356126887, w2=-1.9738890634640438, w3=-1.5658842969353899, w4=-0.5465971861010217, w5=4.324783862730681, w6=2.622391591868462\n",
      "Gradient Descent(358/499): loss=-0.49164198749473587, w0=0.3088641797870574, w1=-1.8846631616465188, w2=-1.9797020356135193, w3=-1.5711224410931615, w4=-0.5499366065078353, w5=4.322305946130473, w6=2.6228348073030117\n",
      "Gradient Descent(359/499): loss=-0.4916206421484278, w0=0.3125584512602075, w1=-1.8862030871814188, w2=-1.9854920453497638, w3=-1.5763394037968628, w4=-0.553249432617637, w5=4.319832871001436, w6=2.623276344473815\n",
      "Gradient Descent(360/499): loss=-0.4916001851738238, w0=0.3162381987810854, w1=-1.8877386161295582, w2=-1.9912591877814285, w3=-1.5815353123652849, w4=-0.5565358611765395, w5=4.317364609646425, w6=2.6237162052399117\n",
      "Gradient Descent(361/499): loss=-0.49158060331738007, w0=0.3199034864704456, w1=-1.8892697525843218, w2=-1.9970035576547145, w3=-1.586710293082218, w4=-0.5597960874388074, w5=4.314901134589614, w6=2.6241543915935135\n",
      "Gradient Descent(362/499): loss=-0.49156188351643737, w0=0.32355437816758315, w1=-1.8907965008166034, w2=-2.0027252493534804, w3=-1.5918644712060148, w4=-0.5630303051772152, w5=4.312442418574777, w6=2.6245909056561936\n",
      "Gradient Descent(363/499): loss=-0.49154401289626093, w0=0.32719093743100996, w1=-1.8923188652711558, w2=-2.0084243568993876, w3=-1.5969979709790696, w4=-0.5662387066933788, w5=4.3099884345635795, w6=2.6250257496751552\n",
      "Gradient Descent(364/499): loss=-0.4915269787671294, w0=0.3308132275391448, w1=-1.893836850563002, w2=-2.014100973952083, w3=-1.6021109156372089, w4=-0.569421482828058, w5=4.307539155733874, w6=2.6254589260195855\n",
      "Gradient Descent(365/499): loss=-0.49151076862147347, w0=0.3344213114910175, w1=-1.895350461473902, w2=-2.0197551938094143, w3=-1.607203427418998, w4=-0.5725788229714296, w5=4.30509455547801, w6=2.6258904371770897\n",
      "Gradient Descent(366/499): loss=-0.49149537013106076, w0=0.3380152520069851, w1=-1.8968597029488763, w2=-2.02538710940768, w3=-1.6122756275749617, w4=-0.5757109150733297, w5=4.302654607401151, w6=2.6263202857502037\n",
      "Gradient Descent(367/499): loss=-0.49148077114422856, w0=0.3415951115294615, w1=-1.8983645800927855, w2=-2.0309968133219147, w3=-1.6173276363767206, w4=-0.5788179456534643, w5=4.300219285319604, w6=2.626748474452985\n",
      "Gradient Descent(368/499): loss=-0.49146695968316223, w0=0.3451609522236588, w1=-1.899865098166965, w2=-2.0365843977662035, w3=-1.622359573126044, w4=-0.5819000998115861, w5=4.297788563259151, w6=2.62717500610768\n",
      "Gradient Descent(369/499): loss=-0.4914539239412196, w0=0.3487128359783407, w1=-1.9013612625859124, w2=-2.042149954594029, w3=-1.6273715561638191, w4=-0.5849575612376364, w5=4.295362415453403, w6=2.6275998836414645\n",
      "Gradient Descent(370/499): loss=-0.4914416522802985, w0=0.352250824406587, w1=-1.9028530789140297, w2=-2.04769357529865, w3=-1.6323637028789375, w4=-0.5879905122218528, w5=4.292940816342151, w6=2.62802311008326\n",
      "Gradient Descent(371/499): loss=-0.4914301332282495, w0=0.3557749788465691, w1=-1.904340552862417, w2=-2.053215351013506, w3=-1.6373361297170996, w4=-0.5909991336648391, w5=4.290523740569733, w6=2.6284446885606205\n",
      "Gradient Descent(372/499): loss=-0.4914193554763304, w0=0.359285360362336, w1=-1.9058236902857186, w2=-2.0587153725126557, w3=-1.6422889521895385, w4=-0.5939836050875976, w5=4.288111162983411, w6=2.628864622296687\n",
      "Gradient Descent(373/499): loss=-0.4914093078767039, w0=0.36278202974461055, w1=-1.9073024971790193, w2=-2.064193730211237, w3=-1.6472222848816616, w4=-0.5969441046415235, w5=4.285703058631759, w6=2.629282914607217\n",
      "Gradient Descent(374/499): loss=-0.4913999794399762, w0=0.36626504751159555, w1=-1.908776979674791, w2=-2.06965051416596, w3=-1.6521362414616125, w4=-0.5998808091183591, w5=4.283299402763051, w6=2.6296995688976743\n",
      "Gradient Descent(375/499): loss=-0.4913913593327763, w0=0.36973447390978914, w1=-1.9102471440398898, w2=-2.0750858140756203, w3=-1.657030934688754, w4=-0.6027938939601074, w5=4.2809001708236725, w6=2.630114588660392\n",
      "Gradient Descent(376/499): loss=-0.4913834368753759, w0=0.37319036891480933, w1=-1.9117129966725999, w2=-2.080499719281645, w3=-1.6619064764220703, w4=-0.6056835332689051, w5=4.278505338456536, w6=2.630527977471794\n",
      "Gradient Descent(377/499): loss=-0.49137620153934825, w0=0.3766327922322273, w1=-1.9131745440997276, w2=-2.085892318768655, w3=-1.6667629776284931, w4=-0.6085498998168526, w5=4.2761148814995, w6=2.6309397389896865\n",
      "Gradient Descent(378/499): loss=-0.49136964294526553, w0=0.380061803298409, w1=-1.9146317929737413, w2=-2.0912637011650563, w3=-1.6716005483911474, w4=-0.6113931650558012, w5=4.273728775983811, w6=2.6313498769506047\n",
      "Gradient Descent(379/499): loss=-0.491363750860435, w0=0.3834774612813652, w1=-1.9160847500699576, w2=-2.0966139547436557, w3=-1.6764192979175212, w4=-0.6142134991270969, w5=4.271346998132542, w6=2.631758395167227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(380/499): loss=-0.49135851519667145, w0=0.3868798250816086, w1=-1.9175334222837752, w2=-2.1019431674222937, w3=-1.6812193345475595, w4=-0.6170110708712794, w5=4.268969524359052, w6=2.632165297525845\n",
      "Gradient Descent(381/499): loss=-0.491353926008107, w0=0.39026895333301936, w1=-1.918977816627952, w2=-2.107251426764503, w3=-1.6860007657616802, w4=-0.6197860478377358, w5=4.266596331265446, w6=2.6325705879838934\n",
      "Gradient Descent(382/499): loss=-0.4913499734890373, w0=0.3936449044037167, w1=-1.9204179402299284, w2=-2.112538819980188, w3=-1.6907636981887162, w4=-0.6225385962943091, w5=4.264227395641052, w6=2.6329742705675376\n",
      "Gradient Descent(383/499): loss=-0.4913466479718022, w0=0.39700773639693815, w1=-1.9218538003291925, w2=-2.117805433926322, w3=-1.6955082376137813, w4=-0.6252688812368591, w5=4.2618626944609055, w6=2.6333763493693163\n",
      "Gradient Descent(384/499): loss=-0.49134393992470216, w0=0.4003575071519251, w1=-1.9232854042746914, w2=-2.1230513551076675, w3=-1.7002344889860637, w4=-0.6279770663987775, w5=4.2595022048842415, w6=2.63377682854584\n",
      "Gradient Descent(385/499): loss=-0.491341839949948, w0=0.4036942742448145, w1=-1.9247127595222822, w2=-2.1282766696775135, w3=-1.704942556426543, w4=-0.6306633142604544, w5=4.257145904253, w6=2.634175712315544\n",
      "Gradient Descent(386/499): loss=-0.4913403387816456, w0=0.407018094989537, w1=-1.9261358736322263, w2=-2.1334814634384314, w3=-1.7096325432356378, w4=-0.633327786058697, w5=4.25479377009034, w6=2.634573004956491\n",
      "Gradient Descent(387/499): loss=-0.4913394272838123, w0=0.4103290264387203, w1=-1.9275547542667257, w2=-2.138665821843049, w3=-1.7143045519007771, w4=-0.6359706417960995, w5=4.252445780099163, w6=2.6349687108042312\n",
      "Gradient Descent(388/499): loss=-0.4913390964484259, w0=0.4136271253845984, w1=-1.9289694091874985, w2=-2.1438298299948437, w3=-1.7189586841039026, w4=-0.6385920402503641, w5=4.250101912160646, w6=2.6353628342497073\n",
      "Gradient Descent(389/499): loss=-0.4913393373935067, w0=0.4169124483599256, w1=-1.9303798462533956, w2=-2.1489735726489476, w3=-1.723595040728898, w4=-0.6411921389835717, w5=4.2477621443327855, w6=2.635755379737212\n",
      "Gradient Descent(390/499): loss=-0.49134014136123016, w0=0.42018505163889613, w1=-1.9317860734180565, w2=-2.154097134212974, w3=-1.7282137218689488, w4=-0.6437710943514035, w5=4.245426454848953, w6=2.6361463517623926\n",
      "Gradient Descent(391/499): loss=-0.4913414997160696, w0=0.42344499123806817, w1=-1.9331880987276038, w2=-2.1592005987478573, w3=-1.732814826833831, w4=-0.6463290615123105, w5=4.243094822116455, w6=2.6365357548703052\n",
      "Gradient Descent(392/499): loss=-0.49134340394297066, w0=0.42669232291729203, w1=-1.9345859303183768, w2=-2.1642840499687064, w3=-1.7373984541571308, w4=-0.6488661944366344, w5=4.240767224715108, w6=2.636923593653513\n",
      "Gradient Descent(393/499): loss=-0.49134584564555445, w0=0.42992710218064345, w1=-1.9359795764147023, w2=-2.169347571245675, w3=-1.7419647016033954, w4=-0.6513826459156752, w5=4.238443641395822, w6=2.6373098727502313\n",
      "Gradient Descent(394/499): loss=-0.4913488165443506, w0=0.4331493842773601, w1=-1.9373690453267025, w2=-2.1743912456048458, w3=-1.7465136661752152, w4=-0.6538785675707082, w5=4.236124051079193, w6=2.6376945968425174\n",
      "Gradient Descent(395/499): loss=-0.4913523084750585, w0=0.4363592242027825, w1=-1.9387543454481395, w2=-2.179415155729126, w3=-1.751045444120238, w4=-0.6563541098619488, w5=4.2338084328541035, w6=2.6380777706545033\n",
      "Gradient Descent(396/499): loss=-0.49135631338683683, w0=0.43955667669929827, w1=-1.9401354852542965, w2=-2.184419383959159, w3=-1.7555601309381175, w4=-0.6588094220974656, w5=4.231496765976339, w6=2.6384593989506717\n",
      "Gradient Descent(397/499): loss=-0.49136082334062114, w0=0.44274179625728965, w1=-1.941512473299894, w2=-2.1894040122942444, w3=-1.7600578213873919, w4=-0.6612446524420408, w5=4.229189029867209, w6=2.6388394865341733\n",
      "Gradient Descent(398/499): loss=-0.4913658305074689, w0=0.4459146371160848, w1=-1.9428853182170414, w2=-2.1943691223932755, w3=-1.7645386094923006, w4=-0.663659947925977, w5=4.226885204112176, w6=2.639218038245185\n",
      "Gradient Descent(399/499): loss=-0.4913713271669306, w0=0.44907525326491166, w1=-1.944254028713222, w2=-2.1993147955756838, w3=-1.7690025885495322, w4=-0.6660554544538531, w5=4.224585268459502, w6=2.6395950589593085\n",
      "Gradient Descent(400/499): loss=-0.49137730570544735, w0=0.4522236984438546, w1=-1.9456186135693136, w2=-2.204241112822397, w3=-1.7734498511349093, w4=-0.6684313168132245, w5=4.222289202818897, w6=2.6399705535860085\n",
      "Gradient Descent(401/499): loss=-0.49138375861477507, w0=0.455360026144814, w1=-1.9469790816376413, w2=-2.209148154776807, w3=-1.7778804891100075, w4=-0.6707876786832728, w5=4.219996987260181, w6=2.6403445270670884\n",
      "Gradient Descent(402/499): loss=-0.4913906784904336, w0=0.45848428961246795, w1=-1.948335441840064, w2=-2.214036001745749, w3=-1.782294593628713, w4=-0.6731246826433994, w5=4.217708602011957, w6=2.640716984375203\n",
      "Gradient Descent(403/499): loss=-0.4913980580301805, w0=0.4615965418452365, w1=-1.9496877031660922, w2=-2.21890473370049, w3=-1.7866922551437139, w4=-0.6754424701817671, w5=4.215424027460285, w6=2.6410879305124095\n",
      "Gradient Descent(404/499): loss=-0.49140589003250956, w0=0.46469683559624797, w1=-1.9510358746710394, w2=-2.2237544302777255, w3=-1.7910735634129318, w4=-0.6777411817037872, w5=4.213143244147383, w6=2.6414573705087534\n",
      "Gradient Descent(405/499): loss=-0.4914141673951742, w0=0.46778522337430706, w1=-1.9523799654742036, w2=-2.2285851707805886, w3=-1.7954386075058888, w4=-0.6800209565405532, w5=4.210866232770316, w6=2.6418253094208897\n",
      "Gradient Descent(406/499): loss=-0.4914228831137335, w0=0.4708617574448646, w1=-1.95371998475708, w2=-2.2333970341796654, w3=-1.7997874758100152, w4=-0.6822819329572198, w5=4.208592974179713, w6=2.642191752330738\n",
      "Gradient Descent(407/499): loss=-0.49143203028012217, w0=0.4739264898309894, w1=-1.9550559417616056, w2=-2.2381900991140182, w3=-1.804120256036894, w4=-0.6845242481613287, w5=4.206323449378482, w6=2.6425567043441727\n",
      "Gradient Descent(408/499): loss=-0.4914416020812431, w0=0.4769794723143411, w1=-1.9563878457884307, w2=-2.2429644438922196, w3=-1.808437035228447, w4=-0.6867480383110792, w5=4.204057639520539, w6=2.6429201705897434\n",
      "Gradient Descent(409/499): loss=-0.49145159179758313, w0=0.4800207564361446, w1=-1.957715706195224, w2=-2.2477201464933914, w3=-1.8127378997630588, w4=-0.6889534385235455, w5=4.2017955259095485, w6=2.643282156217431\n",
      "Gradient Descent(410/499): loss=-0.49146199280184955, w0=0.4830503934981652, w1=-1.9590395323950034, w2=-2.252457284568253, w3=-1.8170229353616443, w4=-0.6911405828828391, w5=4.1995370899976665, w6=2.6436426663974326\n",
      "Gradient Descent(411/499): loss=-0.49147279855763, w0=0.4860684345636854, w1=-1.9603593338544973, w2=-2.2571759354401753, w3=-1.8212922270936545, w4=-0.6933096044482173, w5=4.197282313384301, w6=2.644001706318978\n",
      "Gradient Descent(412/499): loss=-0.49148400261807235, w0=0.48907493045848194, w1=-1.9616751200925344, w2=-2.261876176106241, w3=-1.8255458593830254, w4=-0.6954606352621374, w5=4.195031177814877, w6=2.6443592811891756\n",
      "Gradient Descent(413/499): loss=-0.49149559862458686, w0=0.4920699317718039, w1=-1.9629869006784593, w2=-2.266558083238315, w3=-1.8297839160140692, w4=-0.6975938063582562, w5=4.192783665179611, w6=2.6447153962318906\n",
      "Gradient Descent(414/499): loss=-0.4915075803055674, w0=0.49505348885735145, w1=-1.9642946852305776, w2=-2.2712217331841145, w3=-1.8340064801373084, w4=-0.6997092477693756, w5=4.1905397575122985, w6=2.645070056686647\n",
      "Gradient Descent(415/499): loss=-0.4915199414751344, w0=0.4980256518342549, w1=-1.965598483414627, w2=-2.2758672019682904, w3=-1.8382136342752518, w4=-0.7018070885353337, w5=4.188299436989104, w6=2.645423267807563\n",
      "Gradient Descent(416/499): loss=-0.49153267603189726, w0=0.5009864705880539, w1=-1.966898304942275, w2=-2.2804945652935116, w3=-1.8424054603281164, w4=-0.7038874567108419, w5=4.186062685927369, w6=2.64577503486231\n",
      "Gradient Descent(417/499): loss=-0.4915457779577361, w0=0.5039359947716775, w1=-1.968194159569643, w2=-2.2851038985415553, w3=-1.846582039579492, w4=-0.7059504793732676, w5=4.18382948678442, w6=2.6461253631311012\n",
      "Gradient Descent(418/499): loss=-0.4915592413166029, w0=0.5068742738064234, w1=-1.969486057095856, w2=-2.2896952767744017, w3=-1.8507434527019517, w4=-0.707996282630363, w5=4.181599822156395, w6=2.6464742579057052\n",
      "Gradient Descent(419/499): loss=-0.49157306025334174, w0=0.5098013568829379, w1=-1.9707740073616165, w2=-2.2942687747353334, w3=-1.8548897797626063, w4=-0.7100249916279393, w5=4.179373674777069, w6=2.646821724488485\n",
      "Gradient Descent(420/499): loss=-0.49158722899252766, w0=0.5127172929621955, w1=-1.9720580202478064, w2=-2.2988244668500393, w3=-1.8590211002286068, w4=-0.7120367305574878, w5=4.1771510275166985, w6=2.647167768191462\n",
      "Gradient Descent(421/499): loss=-0.4916017418373237, w0=0.515622130776478, w1=-1.9733381056741095, w2=-2.3033624272277233, w3=-1.8631374929725912, w4=-0.7140316226637464, w5=4.174931863380868, w6=2.6475123943354086\n",
      "Gradient Descent(422/499): loss=-0.49161659316835543, w0=0.5185159188303538, w1=-1.9746142735976615, w2=-2.3078827296622153, w3=-1.8672390362780795, w4=-0.7160097902522126, w5=4.172716165509348, w6=2.647855608248958\n",
      "Gradient Descent(423/499): loss=-0.49163177744260445, w0=0.5213987054016557, w1=-1.9758865340117215, w2=-2.3123854476330874, w3=-1.8713258078448154, w4=-0.7179713546966026, w5=4.170503917174963, w6=2.6481974152677434\n",
      "Gradient Descent(424/499): loss=-0.4916472891923177, w0=0.5242705385424596, w1=-1.9771548969443686, w2=-2.316870654306773, w3=-1.875397884794056, w4=-0.7199164364462574, w5=4.168295101782466, w6=2.6485378207335564\n",
      "Gradient Descent(425/499): loss=-0.4916631230239355, w0=0.5271314660800616, w1=-1.9784193724572199, w2=-2.3213384225376874, w3=-1.87945534367381, w4=-0.7218451550334947, w5=4.166089702867424, w6=2.6488768299935304\n",
      "Gradient Descent(426/499): loss=-0.4916792736170344, w0=0.5299815356179537, w1=-1.9796799706441726, w2=-2.3257888248693552, w3=-1.8834982604640247, w4=-0.7237576290809081, w5=4.163887704095112, w6=2.6492144483993454\n",
      "Gradient Descent(427/499): loss=-0.4916957357232883, w0=0.5328207945368003, w1=-1.980936701630168, w2=-2.3302219335355363, w3=-1.8875267105817228, w4=-0.7256539763086131, w5=4.161689089259412, w6=2.6495506813064527\n",
      "Gradient Descent(428/499): loss=-0.4917125041654453, w0=0.5356492899954127, w1=-1.9821895755699774, w2=-2.3346378204613565, w3=-1.8915407688860877, w4=-0.7275343135414393, w5=4.159493842281729, w6=2.649885534073323\n",
      "Gradient Descent(429/499): loss=-0.49172957383631966, w0=0.5384670689317224, w1=-1.9834386026470097, w2=-2.33903655726444, w3=-1.8955405096835003, w4=-0.7293987567160711, w5=4.157301947209907, w6=2.6502190120607128\n",
      "Gradient Descent(430/499): loss=-0.4917469396978004, w0=0.5412741780637538, w1=-1.9846837930721397, w2=-2.343418215256045, w3=-1.8995260067325268, w4=-0.7312474208881348, w5=4.155113388217158, w6=2.650551120630952\n",
      "Gradient Descent(431/499): loss=-0.4917645967798755, w0=0.5440706638905957, w1=-1.9859251570825587, w2=-2.3477828654421993, w3=-1.9034973332488565, w4=-0.7330804202392329, w5=4.152928149600999, w6=2.6508818651472517\n",
      "Gradient Descent(432/499): loss=-0.4917825401796697, w0=0.5468565726933708, w1=-1.9871627049406444, w2=-2.352130578524838, w3=-1.9074545619101921, w4=-0.7348978680839275, w5=4.150746215782199, w6=2.65121125097303\n",
      "Gradient Descent(433/499): loss=-0.4918007650604992, w0=0.5496319505362051, w1=-1.9883964469328523, w2=-2.3564614249029456, w3=-1.9113977648610925, w4=-0.73669987687667, w5=4.14856757130373, w6=2.6515392834712563\n",
      "Gradient Descent(434/499): loss=-0.4918192666509394, w0=0.5523968432671941, w1=-1.989626393368626, w2=-2.3607754746736944, w3=-1.9153270137177671, w4=-0.7384865582186797, w5=4.146392200829733, w6=2.6518659680038152\n",
      "Gradient Descent(435/499): loss=-0.4918380402439082, w0=0.5551512965193695, w1=-1.9908525545793279, w2=-2.365072797633589, w3=-1.9192423795728248, w4=-0.7402580228647702, w5=4.1442200891444845, w6=2.652191309930888\n",
      "Gradient Descent(436/499): loss=-0.4918570811957625, w0=0.5578953557116624, w1=-1.9920749409171887, w2=-2.3693534632796083, w3=-1.9231439329999749, w4=-0.7420143807301248, w5=4.142051221151379, w6=2.6525153146103495\n",
      "Gradient Descent(437/499): loss=-0.49187638492540925, w0=0.5606290660498663, w1=-1.9932935627542774, w2=-2.37361754081035, w3=-1.9270317440586828, w4=-0.7437557408970203, w5=4.1398855818719165, w6=2.652837987397186\n",
      "Gradient Descent(438/499): loss=-0.4918959469134303, w0=0.5633524725275973, w1=-1.9945084304814873, w2=-2.3778650991271766, w3=-1.9309058822987808, w4=-0.7454822116214994, w5=4.137723156444694, w6=2.653159333642926\n",
      "Gradient Descent(439/499): loss=-0.4919157627012195, w0=0.5660656199272535, w1=-1.9957195545075437, w2=-2.382096206835359, w3=-1.9347664167650322, w4=-0.7471939003399924, w5=4.135563930124415, w6=2.653479358695089\n",
      "Gradient Descent(440/499): loss=-0.49193582789013485, w0=0.5687685528209713, w1=-1.9969269452580274, w2=-2.3863109322452236, w3=-1.9386134160016524, w4=-0.7488909136758887, w5=4.1334078882808996, w6=2.65379806789665\n",
      "Gradient Descent(441/499): loss=-0.4919561381406623, w0=0.5714613155715811, w1=-1.9981306131744172, w2=-2.390509343373298, w3=-1.9424469480567843, w4=-0.7505733574460566, w5=4.131255016398102, w6=2.6541154665855196\n",
      "Gradient Descent(442/499): loss=-0.4919766891715929, w0=0.5741439523335601, w1=-1.9993305687131493, w2=-2.394691507943457, w3=-1.9462670804869309, w4=-0.7522413366673145, w5=4.129105300073142, w6=2.654431560094039\n",
      "Gradient Descent(443/499): loss=-0.4919974767592119, w0=0.5768165070539832, w1=-2.0005268223446953, w2=-2.398857493388068, w3=-1.9500738803613442, w4=-0.7538949555628509, w5=4.126958725015341, w6=2.6547463537484903\n",
      "Gradient Descent(444/499): loss=-0.49201849673650144, w0=0.5794790234734722, w1=-2.001719384552655, w2=-2.403007366849139, w3=-1.953867414266371, w4=-0.7555343175685949, w5=4.124815277045265, w6=2.6550598528686216\n",
      "Gradient Descent(445/499): loss=-0.492039744992354, w0=0.5821315451271423, w1=-2.0029082658328687, w2=-2.407141195179462, w3=-1.9576477483097563, w4=-0.7571595253395377, w5=4.122674942093776, w6=2.6553720627671833\n",
      "Gradient Descent(446/499): loss=-0.49206121747079884, w0=0.5847741153455465, w1=-2.0040934766925442, w2=-2.4112590449437588, w3=-1.9614149481249048, w4=-0.7587706807560041, w5=4.120537706201096, w6=2.6556829887494837\n",
      "Gradient Descent(447/499): loss=-0.4920829101702399, w0=0.5874067772556183, w1=-2.0052750276494, w2=-2.415360982419826, w3=-1.9651690788751002, w4=-0.7603678849298757, w5=4.1184035555158705, w6=2.655992636112953\n",
      "Gradient Descent(448/499): loss=-0.4921048191427047, w0=0.5900295737816114, w1=-2.006452929230825, w2=-2.419447073599679, w3=-1.9689102052576835, w4=-0.7619512382107652, w5=4.116272476294245, w6=2.6563010101467217\n",
      "Gradient Descent(449/499): loss=-0.49212694049310524, w0=0.5926425476460372, w1=-2.007627191973055, w2=-2.4235173841906943, w3=-1.9726383915081909, w4=-0.7635208401921413, w5=4.114144454898951, w6=2.6566081161312156\n",
      "Gradient Descent(450/499): loss=-0.4921492703785101, w0=0.5952457413706, w1=-2.0087978264203628, w2=-2.4275719796167516, w3=-1.9763537014044503, w4=-0.765076789717407, w5=4.112019477798392, w6=2.656913959337757\n",
      "Gradient Descent(451/499): loss=-0.4921718050074273, w0=0.5978391972771298, w1=-2.009964843124263, w2=-2.4316109250193767, w3=-1.980056198270638, w4=-0.7666191848859284, w5=4.109897531565749, w6=2.657218545028184\n",
      "Gradient Descent(452/499): loss=-0.49219454063909795, w0=0.6004229574885119, w1=-2.0111282526427354, w2=-2.43563428525888, w3=-1.9837459449812962, w4=-0.7681481230590169, w5=4.107778602878079, w6=2.6575218784544776\n",
      "Gradient Descent(453/499): loss=-0.49221747358280055, w0=0.6029970639296158, w1=-2.0122880655394595, w2=-2.439642124915495, w3=-1.9874230039653111, w4=-0.7696637008658632, w5=4.105662678515435, w6=2.657823964858403\n",
      "Gradient Descent(454/499): loss=-0.49224060019716576, w0=0.6055615583282188, w1=-2.013444292383064, w2=-2.4436345082905175, w3=-1.9910874372098513, w4=-0.7711660142094247, w5=4.103549745359983, w6=2.6581248094711616\n",
      "Gradient Descent(455/499): loss=-0.49226391688950155, w0=0.6081164822159291, w1=-2.0145969437463935, w2=-2.4476114994074405, w3=-1.9947393062642684, w4=-0.7726551582722653, w5=4.101439790395133, w6=2.658424417513054\n",
      "Gradient Descent(456/499): loss=-0.4922874201151285, w0=0.6106618769291055, w1=-2.0157460302057855, w2=-2.4515731620130885, w3=-1.9983786722439603, w4=-0.7741312275223498, w5=4.099332800704674, w6=2.658722794193154\n",
      "Gradient Descent(457/499): loss=-0.49231110637672487, w0=0.6131977836097744, w1=-2.0168915623403625, w2=-2.455519559578752, w3=-2.002005595834194, w4=-0.7755943157187905, w5=4.0972287634719144, w6=2.659019944708992\n",
      "Gradient Descent(458/499): loss=-0.4923349722236816, w0=0.6157242432065442, w1=-2.0180335507313387, w2=-2.459450755301317, w3=-2.0056201372938953, w4=-0.7770445159175488, w5=4.095127665978839, w6=2.6593158742462526\n",
      "Gradient Descent(459/499): loss=-0.4923590142514665, w0=0.6182412964755161, w1=-2.01917200596134, w2=-2.463366812104395, w3=-2.009222356459396, w4=-0.7784819204770904, w5=4.09302949560526, w6=2.6596105879784764\n",
      "Gradient Descent(460/499): loss=-0.4923832291009988, w0=0.6207489839811937, w1=-2.0203069386137353, w2=-2.4672677926394524, w3=-2.0128123127481508, w4=-0.7799066210639954, w5=4.090934239827986, w6=2.6599040910667773\n",
      "Gradient Descent(461/499): loss=-0.49240761345803225, w0=0.6232473460973885, w1=-2.0214383592719822, w2=-2.4711537592869335, w3=-2.0163900651624114, w4=-0.7813187086585232, w5=4.08884188621999, w6=2.6601963886595663\n",
      "Gradient Descent(462/499): loss=-0.4924321640525475, w0=0.6257364230081226, w1=-2.022566278518985, w2=-2.475024774157386, w3=-2.0199556722928707, w4=-0.7827182735601315, w5=4.086752422449594, w6=2.6604874858922853\n",
      "Gradient Descent(463/499): loss=-0.4924568776581538, w0=0.6282162547085289, w1=-2.023690706936466, w2=-2.4788808990925824, w3=-2.0235091923222672, w4=-0.7841054053929524, w5=4.084665836279649, w6=2.660777387887151\n",
      "Gradient Descent(464/499): loss=-0.49248175109149916, w0=0.6306868810057484, w1=-2.024811655104348, w2=-2.4827221956666388, w3=-2.0270506830289565, w4=-0.7854801931112224, w5=4.082582115566733, w6=2.6610660997529054\n",
      "Gradient Descent(465/499): loss=-0.49250678121168967, w0=0.6331483415198241, w1=-2.0259291336001484, w2=-2.486548725187133, w3=-2.030580201790446, w4=-0.7868427250046696, w5=4.080501248260345, w6=2.6613536265845794\n",
      "Gradient Descent(466/499): loss=-0.49253196491971685, w0=0.6356006756845921, w1=-2.0270431529983886, w2=-2.4903605486962186, w3=-2.0340978055868977, w4=-0.7881930887038558, w5=4.078423222402117, w6=2.6616399734632594\n",
      "Gradient Descent(467/499): loss=-0.49255729915789437, w0=0.6380439227485699, w1=-2.0281537238700102, w2=-2.4941577269717383, w3=-2.0376035510045947, w4=-0.7895313711854768, w5=4.076348026125026, w6=2.661925145455867\n",
      "Gradient Descent(468/499): loss=-0.4925827809093014, w0=0.6404781217758415, w1=-2.029260856781807, w2=-2.497940320528334, w3=-2.0410974942393754, w4=-0.7908576587776175, w5=4.074275647652612, w6=2.6622091476149428\n",
      "Gradient Descent(469/499): loss=-0.4926084071972362, w0=0.6429033116469396, w1=-2.0303645622958655, w2=-2.5017083896185532, w3=-2.044579691100032, w4=-0.792172037164966, w5=4.072206075298207, w6=2.6624919849784425\n",
      "Gradient Descent(470/499): loss=-0.492634175084676, w0=0.6453195310597241, w1=-2.031464850969017, w2=-2.5054619942339564, w3=-2.0480501970116793, w4=-0.7934745913939834, w5=4.070139297464169, w6=2.6627736625695375\n",
      "Gradient Descent(471/499): loss=-0.49266008167374586, w0=0.647726818530258, w1=-2.032561733352304, w2=-2.5092011941062182, w3=-2.0515090670190883, w4=-0.7947654058780321, w5=4.06807530264112, w6=2.6630541853964225\n",
      "Gradient Descent(472/499): loss=-0.49268612410519486, w0=0.6501252123936807, w1=-2.033655219990451, w2=-2.512926048708227, w3=-2.054956355789987, w4=-0.7960445644024625, w5=4.066014079407193, w6=2.6633335584521345\n",
      "Gradient Descent(473/499): loss=-0.49271229955788, w0=0.6525147508050767, w1=-2.034745321421353, w2=-2.516636617255183, w3=-2.0583921176183306, w4=-0.7973121501296565, w5=4.063955616427287, w6=2.663611786714374\n",
      "Gradient Descent(474/499): loss=-0.4927386052482578, w0=0.6548954717403426, w1=-2.035832048175568, w2=-2.520332958705692, w3=-2.06181640642754, w4=-0.7985682456040307, w5=4.061899902452326, w6=2.6638888751453367\n",
      "Gradient Descent(475/499): loss=-0.49276503842988245, w0=0.65726741299705, w1=-2.0369154107758254, w2=-2.5240151317628574, w3=-2.065229275773707, w4=-0.7998129327569979, w5=4.0598469263185235, w6=2.664164828691551\n",
      "Gradient Descent(476/499): loss=-0.4927915963929129, w0=0.6596306121953057, w1=-2.0379954197365393, w2=-2.5276831948753693, w3=-2.0686307788487697, w4=-0.8010462929118881, w5=4.057796676946657, w6=2.6644396522837215\n",
      "Gradient Descent(477/499): loss=-0.49281827646362564, w0=0.6619851067786081, w1=-2.039072085563337, w2=-2.531337206238589, w3=-2.072020968483657, w4=-0.802268406788828, w5=4.055749143341344, w6=2.6647133508365792\n",
      "Gradient Descent(478/499): loss=-0.49284507600393523, w0=0.6643309340147011, w1=-2.040145418752592, w2=-2.5349772237956336, w3=-2.0753998971514034, w4=-0.8034793545095816, w5=4.0537043145903295, w6=2.6649859292487394\n",
      "Gradient Descent(479/499): loss=-0.4928719924109213, w0=0.6666681309964242, w1=-2.0412154297909715, w2=-2.538603305238455, w3=-2.07876761697023, w4=-0.804679215602349, w5=4.051662179863777, w6=2.6652573924025638\n",
      "Gradient Descent(480/499): loss=-0.4928990231163632, w0=0.6689967346425597, w1=-2.0422821291549886, w2=-2.5422155080089173, w3=-2.082124179706601, w4=-0.805868069006527, w5=4.049622728413563, w6=2.66552774516403\n",
      "Gradient Descent(481/499): loss=-0.49292616558628016, w0=0.671316781698676, w1=-2.043345527310568, w2=-2.54581388929987, w3=-2.085469636778246, w4=-0.8070459930774293, w5=4.047585949572584, w6=2.6657969923826053\n",
      "Gradient Descent(482/499): loss=-0.4929534173204793, w0=0.6736283087379688, w1=-2.0444056347126183, w2=-2.5493985060562196, w3=-2.088804039257155, w4=-0.8082130655909678, w5=4.045551832754064, w6=2.6660651388911285\n",
      "Gradient Descent(483/499): loss=-0.49298077585210953, w0=0.6759313521620971, w1=-2.045462461804614, w2=-2.5529694149759963, w3=-2.092127437872545, w4=-0.8093693637482954, w5=4.043520367450868, w6=2.6663321895056957\n",
      "Gradient Descent(484/499): loss=-0.49300823874722177, w0=0.6782259482020183, w1=-2.046516019018187, w2=-2.5565266725114193, w3=-2.0954398830137952, w4=-0.810514964180409, w5=4.041491543234829, w6=2.6665981490255515\n",
      "Gradient Descent(485/499): loss=-0.4930358036043356, w0=0.6805121329188178, w1=-2.0475663167727247, w2=-2.560070334869958, w3=-2.098741424733358, w4=-0.8116499429527159, w5=4.039465349756071, w6=2.666863022232986\n",
      "Gradient Descent(486/499): loss=-0.4930634680540125, w0=0.6827899422045367, w1=-2.048613365474979, w2=-2.5636004580153893, w3=-2.102032112749637, w4=-0.8127743755695606, w5=4.037441776742341, w6=2.667126813893236\n",
      "Gradient Descent(487/499): loss=-0.4930912297584343, w0=0.6850594117829951, w1=-2.0496571755186834, w2=-2.5671170976688527, w3=-2.1053119964498417, w4=-0.813888336978715, w5=4.0354208139983525, w6=2.667389528754394\n",
      "Gradient Descent(488/499): loss=-0.4931190864109886, w0=0.6873205772106131, w1=-2.0506977572841754, w2=-2.570620309309902, w3=-2.108581124892811, w4=-0.8149919015758302, w5=4.033402451405127, w6=2.6676511715473183\n",
      "Gradient Descent(489/499): loss=-0.4931470357358595, w0=0.6895734738772274, w1=-2.0517351211380324, w2=-2.5741101481775543, w3=-2.1118395468118107, w4=-0.816085143208852, w5=4.031386678919346, w6=2.6679117469855496\n",
      "Gradient Descent(490/499): loss=-0.4931750754876246, w0=0.691818137006906, w1=-2.0527692774327093, w2=-2.5775866692713323, w3=-2.115087310617307, w4=-0.8171681351823984, w5=4.029373486572706, w6=2.668171259765233\n",
      "Gradient Descent(491/499): loss=-0.49320320345085694, w0=0.6940546016587571, w1=-2.05380023650619, w2=-2.581049927352308, w3=-2.1183244643997066, w4=-0.8182409502621021, w5=4.027362864471282, w6=2.668429714565044\n",
      "Gradient Descent(492/499): loss=-0.49323141743973353, w0=0.6962829027277374, w1=-2.054828008681642, w2=-2.58449997694414, w3=-2.1215510559320774, w4=-0.8193036606789149, w5=4.025354802794894, w6=2.6686871160461183\n",
      "Gradient Descent(493/499): loss=-0.49325971529764917, w0=0.6985030749454553, w1=-2.055852604267081, w2=-2.587936872334107, w3=-2.124767132672838, w4=-0.8203563381333773, w5=4.023349291796479, w6=2.6689434688519857\n",
      "Gradient Descent(494/499): loss=-0.493288094896835, w0=0.7007151528809706, w1=-2.0568740335550415, w2=-2.591360667574142, w3=-2.127972741768423, w4=-0.8213990537998516, w5=4.021346321801472, w6=2.6691987776085098\n",
      "Gradient Descent(495/499): loss=-0.4933165541379834, w0=0.7029191709415924, w1=-2.0578923068222568, w2=-2.594771416481856, w3=-2.1311679300559243, w4=-0.8224318783307198, w5=4.019345883207187, w6=2.66945304692383\n",
      "Gradient Descent(496/499): loss=-0.4933450909498778, w0=0.7051151633736713, w1=-2.058907434329344, w2=-2.598169172641565, w3=-2.134352744065704, w4=-0.8234548818605468, w5=4.017347966482208, w6=2.669706281388309\n",
      "Gradient Descent(497/499): loss=-0.4933737032890275, w0=0.7073031642633906, w1=-2.0599194263204974, w2=-2.6015539894053097, w3=-2.1375272300239847, w4=-0.8244681340102072, w5=4.015352562165784, w6=2.6699584855744813\n",
      "Gradient Descent(498/499): loss=-0.493402389139308, w0=0.7094832075375519, w1=-2.0609282930231885, w2=-2.6049259198938732, w3=-2.1406914338554124, w4=-0.8254717038909791, w5=4.013359660867229, w6=2.670209664037011\n",
      "Gradient Descent(499/499): loss=-0.493431146511606, w0=0.7116553269643592, w1=-2.061934044647873, w2=-2.608285016997794, w3=-2.143845401185597, w4=-0.8264656601086021, w5=4.011369253265325, w6=2.6704598213126456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-25.549355476623461,\n",
       "  -13.859355322734316,\n",
       "  -7.551189948344418,\n",
       "  -4.9840445213939741,\n",
       "  -3.8811204165886637,\n",
       "  -3.2561654133744073,\n",
       "  -2.8479329011473378,\n",
       "  -2.5626950186040687,\n",
       "  -2.3563816087321845,\n",
       "  -2.2039159407770725,\n",
       "  -2.0889455946514683,\n",
       "  -1.9999205813609127,\n",
       "  -1.928486821535468,\n",
       "  -1.8687149646681127,\n",
       "  -1.8165751356667488,\n",
       "  -1.7694704281148421,\n",
       "  -1.7258155960015233,\n",
       "  -1.6846900840436285,\n",
       "  -1.6455808742675364,\n",
       "  -1.6082088382920001,\n",
       "  -1.572420379021376,\n",
       "  -1.5381243443086461,\n",
       "  -1.5052576621313543,\n",
       "  -1.4737679450963517,\n",
       "  -1.4436055071251483,\n",
       "  -1.4147202757771828,\n",
       "  -1.387061059841614,\n",
       "  -1.3605758231321217,\n",
       "  -1.3352122923713492,\n",
       "  -1.3109185919151156,\n",
       "  -1.2876437842400821,\n",
       "  -1.2653382839432759,\n",
       "  -1.2439541513170365,\n",
       "  -1.2234452850894859,\n",
       "  -1.2037675361658713,\n",
       "  -1.1848787619298415,\n",
       "  -1.1667388370509002,\n",
       "  -1.1493096331657897,\n",
       "  -1.1325549767526837,\n",
       "  -1.1164405920994103,\n",
       "  -1.1009340344238845,\n",
       "  -1.0860046168319553,\n",
       "  -1.0716233337883496,\n",
       "  -1.057762783039367,\n",
       "  -1.0443970873890702,\n",
       "  -1.0315018173393409,\n",
       "  -1.0190539153177405,\n",
       "  -1.0070316220063835,\n",
       "  -0.99541440512878643,\n",
       "  -0.98418289093488587,\n",
       "  -0.97331879853637937,\n",
       "  -0.96280487717766794,\n",
       "  -0.95262484647652368,\n",
       "  -0.94276333962931957,\n",
       "  -0.93320584954548114,\n",
       "  -0.92393867785269745,\n",
       "  -0.91494888669686447,\n",
       "  -0.9062242532476491,\n",
       "  -0.89775322681101555,\n",
       "  -0.88952488844346767,\n",
       "  -0.88152891295848623,\n",
       "  -0.87375553321336819,\n",
       "  -0.86619550656391475,\n",
       "  -0.85884008337497508,\n",
       "  -0.85168097747642724,\n",
       "  -0.8447103384565573,\n",
       "  -0.83792072568783549,\n",
       "  -0.83130508398358038,\n",
       "  -0.8248567207878833,\n",
       "  -0.81856928480527524,\n",
       "  -0.812436745980888,\n",
       "  -0.80645337674622597,\n",
       "  -0.80061373445004658,\n",
       "  -0.79491264489819313,\n",
       "  -0.78934518693051459,\n",
       "  -0.78390667796719238,\n",
       "  -0.77859266046083975,\n",
       "  -0.77339888919466981,\n",
       "  -0.76832131937076664,\n",
       "  -0.76335609543608962,\n",
       "  -0.75849954059725522,\n",
       "  -0.75374814697836845,\n",
       "  -0.74909856637924943,\n",
       "  -0.74454760159427447,\n",
       "  -0.74009219825477768,\n",
       "  -0.73572943716049455,\n",
       "  -0.7314565270679303,\n",
       "  -0.72727079790575599,\n",
       "  -0.72316969438942624,\n",
       "  -0.7191507700091575,\n",
       "  -0.71521168136721036,\n",
       "  -0.71135018284210771,\n",
       "  -0.70756412155898496,\n",
       "  -0.7038514326467189,\n",
       "  -0.70021013476383309,\n",
       "  -0.69663832587642971,\n",
       "  -0.69313417927254695,\n",
       "  -0.68969593979843136,\n",
       "  -0.68632192030319172,\n",
       "  -0.6830104982792351,\n",
       "  -0.67976011268672976,\n",
       "  -0.67656926095113445,\n",
       "  -0.67343649612356193,\n",
       "  -0.67036042419442077,\n",
       "  -0.66733970155140987,\n",
       "  -0.66437303257351399,\n",
       "  -0.66145916735319499,\n",
       "  -0.65859689953946499,\n",
       "  -0.65578506429499417,\n",
       "  -0.65302253636083385,\n",
       "  -0.6503082282227346,\n",
       "  -0.64764108837340706,\n",
       "  -0.64502009966542206,\n",
       "  -0.64244427774975932,\n",
       "  -0.63991266959531867,\n",
       "  -0.63742435208498316,\n",
       "  -0.63497843068407855,\n",
       "  -0.63257403817732083,\n",
       "  -0.63021033347056421,\n",
       "  -0.62788650045387484,\n",
       "  -0.62560174692265114,\n",
       "  -0.62335530355369961,\n",
       "  -0.62114642293333899,\n",
       "  -0.61897437863478055,\n",
       "  -0.61683846434217027,\n",
       "  -0.61473799301883403,\n",
       "  -0.61267229611738905,\n",
       "  -0.61064072282952331,\n",
       "  -0.6086426393733505,\n",
       "  -0.60667742831637195,\n",
       "  -0.60474448793217139,\n",
       "  -0.60284323158907838,\n",
       "  -0.60097308716911868,\n",
       "  -0.59913349651566861,\n",
       "  -0.59732391490830838,\n",
       "  -0.59554381056344785,\n",
       "  -0.59379266415937648,\n",
       "  -0.59206996838445725,\n",
       "  -0.5903752275072528,\n",
       "  -0.58870795696743305,\n",
       "  -0.5870676829863759,\n",
       "  -0.58545394219642832,\n",
       "  -0.58386628128785079,\n",
       "  -0.58230425667251329,\n",
       "  -0.58076743416346899,\n",
       "  -0.57925538866956805,\n",
       "  -0.57776770390432364,\n",
       "  -0.57630397210828177,\n",
       "  -0.57486379378418417,\n",
       "  -0.57344677744425354,\n",
       "  -0.57205253936896339,\n",
       "  -0.57068070337668786,\n",
       "  -0.56933090060366287,\n",
       "  -0.56800276929371307,\n",
       "  -0.56669595459723376,\n",
       "  -0.56541010837894168,\n",
       "  -0.56414488903393345,\n",
       "  -0.56289996131161679,\n",
       "  -0.56167499614710081,\n",
       "  -0.56046967049965613,\n",
       "  -0.55928366719787337,\n",
       "  -0.55811667479117122,\n",
       "  -0.55696838740732169,\n",
       "  -0.55583850461568018,\n",
       "  -0.55472673129582339,\n",
       "  -0.55363277751131301,\n",
       "  -0.5525563583883224,\n",
       "  -0.55149719399887276,\n",
       "  -0.55045500924844259,\n",
       "  -0.54942953376772574,\n",
       "  -0.54842050180832491,\n",
       "  -0.54742765214218181,\n",
       "  -0.5464507279645513,\n",
       "  -0.54548947680034376,\n",
       "  -0.54454365041366248,\n",
       "  -0.54361300472037966,\n",
       "  -0.54269729970359526,\n",
       "  -0.54179629933184148,\n",
       "  -0.54090977147989094,\n",
       "  -0.54003748785204864,\n",
       "  -0.53917922390779838,\n",
       "  -0.53833475878969916,\n",
       "  -0.53750387525341625,\n",
       "  -0.53668635959979016,\n",
       "  -0.53588200160884614,\n",
       "  -0.53509059447565233,\n",
       "  -0.53431193474794436,\n",
       "  -0.53354582226543223,\n",
       "  -0.53279206010071634,\n",
       "  -0.53205045450173716,\n",
       "  -0.5313208148356956,\n",
       "  -0.53060295353437481,\n",
       "  -0.5298966860408062,\n",
       "  -0.52920183075722149,\n",
       "  -0.5285182089942374,\n",
       "  -0.52784564492122021,\n",
       "  -0.52718396551778535,\n",
       "  -0.52653300052638308,\n",
       "  -0.52589258240592995,\n",
       "  -0.52526254628644453,\n",
       "  -0.52464272992464844,\n",
       "  -0.52403297366049839,\n",
       "  -0.52343312037461298,\n",
       "  -0.52284301544656364,\n",
       "  -0.52226250671399832,\n",
       "  -0.52169144443256865,\n",
       "  -0.52112968123663495,\n",
       "  -0.52057707210072124,\n",
       "  -0.52003347430169711,\n",
       "  -0.51949874738166335,\n",
       "  -0.51897275311151825,\n",
       "  -0.51845535545518562,\n",
       "  -0.51794642053448359,\n",
       "  -0.51744581659461442,\n",
       "  -0.51695341397026218,\n",
       "  -0.51646908505227518,\n",
       "  -0.51599270425492294,\n",
       "  -0.51552414798370816,\n",
       "  -0.51506329460372335,\n",
       "  -0.51461002440853409,\n",
       "  -0.51416421958958014,\n",
       "  -0.51372576420607874,\n",
       "  -0.51329454415541986,\n",
       "  -0.51287044714404284,\n",
       "  -0.51245336265878083,\n",
       "  -0.51204318193866638,\n",
       "  -0.51163979794718528,\n",
       "  -0.51124310534497164,\n",
       "  -0.51085300046293292,\n",
       "  -0.51046938127579833,\n",
       "  -0.51009214737608177,\n",
       "  -0.50972119994845,\n",
       "  -0.50935644174449002,\n",
       "  -0.50899777705786819,\n",
       "  -0.50864511169987259,\n",
       "  -0.5082983529753341,\n",
       "  -0.50795740965891645,\n",
       "  -0.5076221919717735,\n",
       "  -0.50729261155856142,\n",
       "  -0.50696858146480595,\n",
       "  -0.50665001611461524,\n",
       "  -0.50633683128873341,\n",
       "  -0.50602894410293031,\n",
       "  -0.5057262729867209,\n",
       "  -0.50542873766241037,\n",
       "  -0.5051362591244597,\n",
       "  -0.5048487596191652,\n",
       "  -0.50456616262465004,\n",
       "  -0.50428839283116123,\n",
       "  -0.50401537612166747,\n",
       "  -0.50374703955275479,\n",
       "  -0.50348331133581503,\n",
       "  -0.50322412081852097,\n",
       "  -0.50296939846658861,\n",
       "  -0.50271907584581688,\n",
       "  -0.50247308560440529,\n",
       "  -0.5022313614555437,\n",
       "  -0.50199383816026977,\n",
       "  -0.50176045151059145,\n",
       "  -0.50153113831287166,\n",
       "  -0.5013058363714672,\n",
       "  -0.50108448447262555,\n",
       "  -0.50086702236862801,\n",
       "  -0.50065339076218152,\n",
       "  -0.50044353129105335,\n",
       "  -0.50023738651294536,\n",
       "  -0.50003489989060546,\n",
       "  -0.49983601577717024,\n",
       "  -0.49964067940174084,\n",
       "  -0.49944883685518171,\n",
       "  -0.49926043507614587,\n",
       "  -0.49907542183731929,\n",
       "  -0.49889374573188233,\n",
       "  -0.49871535616018597,\n",
       "  -0.4985402033166389,\n",
       "  -0.4983682381768032,\n",
       "  -0.49819941248469451,\n",
       "  -0.49803367874028531,\n",
       "  -0.49787099018720754,\n",
       "  -0.49771130080065124,\n",
       "  -0.49755456527545766,\n",
       "  -0.49740073901440285,\n",
       "  -0.49724977811666971,\n",
       "  -0.49710163936650592,\n",
       "  -0.49695628022206384,\n",
       "  -0.49681365880442158,\n",
       "  -0.49667373388677999,\n",
       "  -0.49653646488383757,\n",
       "  -0.49640181184133364,\n",
       "  -0.49626973542576513,\n",
       "  -0.49614019691426825,\n",
       "  -0.49601315818466579,\n",
       "  -0.49588858170567712,\n",
       "  -0.49576643052728742,\n",
       "  -0.49564666827127474,\n",
       "  -0.49552925912189238,\n",
       "  -0.49541416781670383,\n",
       "  -0.49530135963756794,\n",
       "  -0.49519080040177327,\n",
       "  -0.49508245645331739,\n",
       "  -0.49497629465433024,\n",
       "  -0.49487228237663855,\n",
       "  -0.49477038749347063,\n",
       "  -0.4946705783712978,\n",
       "  -0.49457282386180967,\n",
       "  -0.49447709329402467,\n",
       "  -0.49438335646652926,\n",
       "  -0.49429158363984715,\n",
       "  -0.49420174552893503,\n",
       "  -0.49411381329580323,\n",
       "  -0.49402775854225894,\n",
       "  -0.49394355330276973,\n",
       "  -0.49386117003744778,\n",
       "  -0.49378058162514898,\n",
       "  -0.49370176135668919,\n",
       "  -0.49362468292817219,\n",
       "  -0.49354932043443034,\n",
       "  -0.49347564836257429,\n",
       "  -0.49340364158565092,\n",
       "  -0.49333327535640736,\n",
       "  -0.49326452530115933,\n",
       "  -0.49319736741376297,\n",
       "  -0.49313177804968711,\n",
       "  -0.49306773392018444,\n",
       "  -0.49300521208656217,\n",
       "  -0.49294418995454753,\n",
       "  -0.4928846452687482,\n",
       "  -0.4928265561072061,\n",
       "  -0.49276990087604239,\n",
       "  -0.49271465830419281,\n",
       "  -0.49266080743823137,\n",
       "  -0.49260832763728096,\n",
       "  -0.49255719856800945,\n",
       "  -0.49250740019971134,\n",
       "  -0.49245891279946957,\n",
       "  -0.49241171692740121,\n",
       "  -0.49236579343198211,\n",
       "  -0.49232112344544976,\n",
       "  -0.49227768837928465,\n",
       "  -0.4922354699197668,\n",
       "  -0.49219445002360712,\n",
       "  -0.49215461091365331,\n",
       "  -0.49211593507466572,\n",
       "  -0.49207840524916785,\n",
       "  -0.49204200443336238,\n",
       "  -0.49200671587311939,\n",
       "  -0.49197252306003064,\n",
       "  -0.49193940972752959,\n",
       "  -0.49190735984707767,\n",
       "  -0.49187635762441462,\n",
       "  -0.49184638749587029,\n",
       "  -0.49181743412474122,\n",
       "  -0.4917894823977248,\n",
       "  -0.49176251742141541,\n",
       "  -0.49173652451885891,\n",
       "  -0.49171148922616476,\n",
       "  -0.49168739728917443,\n",
       "  -0.49166423466018644,\n",
       "  -0.49164198749473587,\n",
       "  -0.49162064214842782,\n",
       "  -0.49160018517382381,\n",
       "  -0.49158060331738007,\n",
       "  -0.49156188351643737,\n",
       "  -0.49154401289626093,\n",
       "  -0.49152697876712942,\n",
       "  -0.49151076862147347,\n",
       "  -0.49149537013106076,\n",
       "  -0.49148077114422856,\n",
       "  -0.49146695968316223,\n",
       "  -0.49145392394121962,\n",
       "  -0.49144165228029851,\n",
       "  -0.49143013322824952,\n",
       "  -0.49141935547633042,\n",
       "  -0.49140930787670389,\n",
       "  -0.49139997943997621,\n",
       "  -0.49139135933277628,\n",
       "  -0.49138343687537589,\n",
       "  -0.49137620153934825,\n",
       "  -0.49136964294526553,\n",
       "  -0.49136375086043499,\n",
       "  -0.49135851519667145,\n",
       "  -0.49135392600810701,\n",
       "  -0.49134997348903731,\n",
       "  -0.49134664797180222,\n",
       "  -0.49134393992470216,\n",
       "  -0.49134183994994801,\n",
       "  -0.49134033878164562,\n",
       "  -0.4913394272838123,\n",
       "  -0.49133909644842588,\n",
       "  -0.49133933739350671,\n",
       "  -0.49134014136123016,\n",
       "  -0.49134149971606961,\n",
       "  -0.49134340394297066,\n",
       "  -0.49134584564555445,\n",
       "  -0.49134881654435059,\n",
       "  -0.49135230847505851,\n",
       "  -0.49135631338683683,\n",
       "  -0.49136082334062114,\n",
       "  -0.4913658305074689,\n",
       "  -0.4913713271669306,\n",
       "  -0.49137730570544735,\n",
       "  -0.49138375861477507,\n",
       "  -0.49139067849043361,\n",
       "  -0.4913980580301805,\n",
       "  -0.49140589003250956,\n",
       "  -0.49141416739517418,\n",
       "  -0.4914228831137335,\n",
       "  -0.49143203028012217,\n",
       "  -0.4914416020812431,\n",
       "  -0.49145159179758313,\n",
       "  -0.49146199280184955,\n",
       "  -0.49147279855762999,\n",
       "  -0.49148400261807235,\n",
       "  -0.49149559862458686,\n",
       "  -0.4915075803055674,\n",
       "  -0.49151994147513439,\n",
       "  -0.49153267603189726,\n",
       "  -0.49154577795773607,\n",
       "  -0.49155924131660289,\n",
       "  -0.49157306025334174,\n",
       "  -0.49158722899252766,\n",
       "  -0.49160174183732369,\n",
       "  -0.49161659316835543,\n",
       "  -0.49163177744260445,\n",
       "  -0.4916472891923177,\n",
       "  -0.4916631230239355,\n",
       "  -0.4916792736170344,\n",
       "  -0.49169573572328829,\n",
       "  -0.49171250416544532,\n",
       "  -0.49172957383631966,\n",
       "  -0.49174693969780042,\n",
       "  -0.4917645967798755,\n",
       "  -0.49178254017966971,\n",
       "  -0.49180076506049919,\n",
       "  -0.49181926665093939,\n",
       "  -0.4918380402439082,\n",
       "  -0.49185708119576249,\n",
       "  -0.49187638492540925,\n",
       "  -0.4918959469134303,\n",
       "  -0.49191576270121951,\n",
       "  -0.49193582789013485,\n",
       "  -0.4919561381406623,\n",
       "  -0.49197668917159287,\n",
       "  -0.4919974767592119,\n",
       "  -0.49201849673650144,\n",
       "  -0.49203974499235398,\n",
       "  -0.49206121747079884,\n",
       "  -0.49208291017023992,\n",
       "  -0.49210481914270471,\n",
       "  -0.49212694049310524,\n",
       "  -0.49214927037851008,\n",
       "  -0.4921718050074273,\n",
       "  -0.49219454063909795,\n",
       "  -0.49221747358280055,\n",
       "  -0.49224060019716576,\n",
       "  -0.49226391688950155,\n",
       "  -0.49228742011512849,\n",
       "  -0.49231110637672487,\n",
       "  -0.49233497222368161,\n",
       "  -0.4923590142514665,\n",
       "  -0.4923832291009988,\n",
       "  -0.49240761345803225,\n",
       "  -0.49243216405254753,\n",
       "  -0.49245687765815382,\n",
       "  -0.49248175109149916,\n",
       "  -0.49250678121168967,\n",
       "  -0.49253196491971685,\n",
       "  -0.49255729915789437,\n",
       "  -0.49258278090930141,\n",
       "  -0.4926084071972362,\n",
       "  -0.492634175084676,\n",
       "  -0.49266008167374586,\n",
       "  -0.49268612410519486,\n",
       "  -0.49271229955787998,\n",
       "  -0.4927386052482578,\n",
       "  -0.49276503842988245,\n",
       "  -0.49279159639291292,\n",
       "  -0.49281827646362564,\n",
       "  -0.49284507600393523,\n",
       "  -0.49287199241092128,\n",
       "  -0.49289902311636319,\n",
       "  -0.49292616558628016,\n",
       "  -0.49295341732047931,\n",
       "  -0.49298077585210953,\n",
       "  -0.49300823874722177,\n",
       "  -0.49303580360433558,\n",
       "  -0.49306346805401252,\n",
       "  -0.49309122975843428,\n",
       "  -0.49311908641098862,\n",
       "  -0.4931470357358595,\n",
       "  -0.49317507548762463,\n",
       "  -0.49320320345085694,\n",
       "  -0.49323141743973353,\n",
       "  -0.49325971529764917,\n",
       "  -0.49328809489683501,\n",
       "  -0.49331655413798342,\n",
       "  -0.49334509094987777,\n",
       "  -0.49337370328902752,\n",
       "  -0.49340238913930801,\n",
       "  -0.49343114651160602],\n",
       " [array([1, 2, 3, 4, 5, 6, 7]),\n",
       "  array([-0.13361692,  1.11377752,  2.57004459,  3.92217324,  4.9356072 ,\n",
       "          5.95279664,  6.81803972]),\n",
       "  array([-1.15583395,  0.30566229,  2.18057897,  3.84630755,  4.87236671,\n",
       "          5.90921138,  6.63614635]),\n",
       "  array([-1.83479035, -0.23435659,  1.91735663,  3.77802212,  4.81357355,\n",
       "          5.87603005,  6.45467303]),\n",
       "  array([-2.21506904, -0.54439954,  1.76902376,  3.72034359,  4.76159463,\n",
       "          5.85321882,  6.27459765]),\n",
       "  array([-2.46154075, -0.75827604,  1.6732587 ,  3.6700486 ,  4.71477207,\n",
       "          5.83612239,  6.09703252]),\n",
       "  array([-2.63702576, -0.92377408,  1.60518906,  3.62485923,  4.67165917,\n",
       "          5.82253343,  5.923229  ]),\n",
       "  array([-2.76707714, -1.05903758,  1.55449914,  3.5834587 ,  4.63136031,\n",
       "          5.81138207,  5.7546308 ]),\n",
       "  array([-2.86404903, -1.17219941,  1.51611611,  3.54501682,  4.5932932 ,\n",
       "          5.80205918,  5.5927839 ]),\n",
       "  array([-2.93472096, -1.26734438,  1.48720169,  3.50896544,  4.55705214,\n",
       "          5.7941719 ,  5.43915804]),\n",
       "  array([-2.98334272, -1.34682768,  1.46595673,  3.47488401,  4.5223328 ,\n",
       "          5.78743775,  5.29492333]),\n",
       "  array([-3.0130692 , -1.4123527 ,  1.45106577,  3.44243625,  4.48888877,\n",
       "          5.78163258,  5.16075714]),\n",
       "  array([-3.02665149, -1.46547966,  1.44142875,  3.41133536,  4.45650712,\n",
       "          5.77656471,  5.03675702]),\n",
       "  array([-3.02670618, -1.50780673,  1.43604823,  3.38132756,  4.42499656,\n",
       "          5.77206393,  4.92248839]),\n",
       "  array([-3.01574691, -1.54096518,  1.43400223,  3.35218679,  4.39418404,\n",
       "          5.76797872,  4.81713291]),\n",
       "  array([-2.99611466, -1.56653832,  1.43445479,  3.32371493,  4.36391567,\n",
       "          5.76417688,  4.71967086]),\n",
       "  array([-2.96989671, -1.58597682,  1.43667379,  3.29574303,  4.33405862,\n",
       "          5.76054657,  4.62904045]),\n",
       "  array([-2.93887648, -1.60054377,  1.44004142,  3.26813153,  4.30450214,\n",
       "          5.75699642,  4.54424715]),\n",
       "  array([-2.90452186, -1.61129451,  1.444054  ,  3.24076875,  4.27515713,\n",
       "          5.75345428,  4.46442227]),\n",
       "  array([-2.86800339, -1.61908272,  1.44831346,  3.21356799,  4.24595433,\n",
       "          5.74986515,  4.38884279]),\n",
       "  array([-2.83022952, -1.62458203,  1.45251389,  3.18646396,  4.21684175,\n",
       "          5.74618859,  4.31692716]),\n",
       "  array([-2.79188851, -1.6283139 ,  1.45642659,  3.159409  ,  4.18778178,\n",
       "          5.74239612,  4.24821856]),\n",
       "  array([-2.75349011, -1.63067625,  1.45988545,  3.13236957,  4.15874841,\n",
       "          5.73846878,  4.18236386]),\n",
       "  array([-2.71540314, -1.63196959,  1.46277379,  3.10532314,  4.12972467,\n",
       "          5.73439499,  4.11909242]),\n",
       "  array([-2.67788763, -1.63241931,  1.46501322,  3.07825556,  4.1007005 ,\n",
       "          5.73016877,  4.05819726]),\n",
       "  array([-2.64112108, -1.63219396,  1.46655454,  3.05115899,  4.07167097,\n",
       "          5.72578833,  3.99951931]),\n",
       "  array([-2.60521935, -1.63141967,  1.46737039,  3.02403015,  4.04263491,\n",
       "          5.7212549 ,  3.94293481]),\n",
       "  array([-2.57025298, -1.63019137,  1.46744956,  2.99686911,  4.01359378,\n",
       "          5.71657189,  3.88834548]),\n",
       "  array([-2.53625959, -1.62858124,  1.46679262,  2.96967825,  3.98455088,\n",
       "          5.71174417,  3.83567113]),\n",
       "  array([-2.50325328, -1.62664504,  1.46540856,  2.94246155,  3.95551071,\n",
       "          5.70677765,  3.78484423]),\n",
       "  array([-2.47123158, -1.62442676,  1.46331231,  2.91522405,  3.92647854,\n",
       "          5.70167882,  3.73580587]),\n",
       "  array([-2.44018056, -1.62196199,  1.4605229 ,  2.88797143,  3.89746005,\n",
       "          5.69645454,  3.68850297]),\n",
       "  array([-2.41007854, -1.61928034,  1.4570621 ,  2.86070975,  3.86846112,\n",
       "          5.69111185,  3.64288627]),\n",
       "  array([-2.38089877, -1.61640713,  1.45295338,  2.83344525,  3.83948764,\n",
       "          5.68565778,  3.59890898]),\n",
       "  array([-2.35261134, -1.61336457,  1.44822127,  2.80618419,  3.81054545,\n",
       "          5.68009929,  3.55652588]),\n",
       "  array([-2.32518449, -1.61017258,  1.44289077,  2.77893277,  3.78164022,\n",
       "          5.6744432 ,  3.51569276]),\n",
       "  array([-2.29858557, -1.60684936,  1.43698701,  2.75169708,  3.75277739,\n",
       "          5.66869616,  3.47636603]),\n",
       "  array([-2.27278169, -1.60341174,  1.43053499,  2.72448302,  3.72396223,\n",
       "          5.66286458,  3.43850256]),\n",
       "  array([-2.24774017, -1.59987541,  1.42355938,  2.6972963 ,  3.6951997 ,\n",
       "          5.65695464,  3.40205956]),\n",
       "  array([-2.22342883, -1.59625512,  1.41608438,  2.67014244,  3.66649456,\n",
       "          5.65097227,  3.36699456]),\n",
       "  array([-2.19981618, -1.59256476,  1.40813363,  2.64302672,  3.63785129,\n",
       "          5.64492316,  3.33326542]),\n",
       "  array([-2.17687159, -1.58881742,  1.39973018,  2.61595421,  3.60927414,\n",
       "          5.63881275,  3.30083039]),\n",
       "  array([-2.15456533, -1.58502544,  1.39089637,  2.58892977,  3.58076712,\n",
       "          5.63264623,  3.26964817]),\n",
       "  array([-2.13286865, -1.58120046,  1.38165387,  2.56195805,  3.55233402,\n",
       "          5.62642854,  3.23967794]),\n",
       "  array([-2.11175381, -1.5773534 ,  1.37202363,  2.53504347,  3.52397838,\n",
       "          5.62016438,  3.21087943]),\n",
       "  array([-2.09119406, -1.57349454,  1.36202587,  2.50819027,  3.49570357,\n",
       "          5.61385824,  3.18321302]),\n",
       "  array([-2.07116367, -1.56963347,  1.3516801 ,  2.48140249,  3.46751274,\n",
       "          5.60751436,  3.15663974]),\n",
       "  array([-2.05163791, -1.56577916,  1.34100508,  2.45468397,  3.43940886,\n",
       "          5.60113677,  3.13112137]),\n",
       "  array([-2.03259304, -1.56193996,  1.33001886,  2.42803839,  3.41139473,\n",
       "          5.59472931,  3.10662044]),\n",
       "  array([-2.0140063 , -1.55812361,  1.31873879,  2.40146922,  3.38347295,\n",
       "          5.58829558,  3.08310029]),\n",
       "  array([-1.99585585, -1.55433728,  1.30718149,  2.37497979,  3.355646  ,\n",
       "          5.58183902,  3.06052514]),\n",
       "  array([-1.97812082, -1.55058758,  1.29536293,  2.34857326,  3.32791619,\n",
       "          5.57536287,  3.03886002]),\n",
       "  array([-1.9607812 , -1.54688056,  1.28329838,  2.32225263,  3.30028568,\n",
       "          5.5688702 ,  3.01807089]),\n",
       "  array([-1.9438179 , -1.5432218 ,  1.27100246,  2.29602075,  3.27275652,\n",
       "          5.56236389,  2.99812461]),\n",
       "  array([-1.92721266, -1.53961634,  1.25848915,  2.26988032,  3.24533061,\n",
       "          5.55584668,  2.97898895]),\n",
       "  array([-1.91094805, -1.53606879,  1.24577181,  2.24383392,  3.21800975,\n",
       "          5.54932114,  2.96063262]),\n",
       "  array([-1.89500743, -1.53258331,  1.23286319,  2.21788397,  3.1907956 ,\n",
       "          5.54278969,  2.94302524]),\n",
       "  array([-1.87937496, -1.52916362,  1.21977546,  2.19203279,  3.16368975,\n",
       "          5.53625462,  2.92613738]),\n",
       "  array([-1.86403552, -1.52581306,  1.20652024,  2.16628254,  3.13669366,\n",
       "          5.52971808,  2.90994054]),\n",
       "  array([-1.84897471, -1.52253459,  1.19310857,  2.1406353 ,  3.10980871,\n",
       "          5.52318208,  2.89440711]),\n",
       "  array([-1.83417884, -1.51933083,  1.179551  ,  2.115093  ,  3.08303618,\n",
       "          5.51664853,  2.87951043]),\n",
       "  array([-1.81963487, -1.51620405,  1.16585754,  2.0896575 ,  3.05637727,\n",
       "          5.51011919,  2.86522473]),\n",
       "  array([-1.80533042, -1.51315622,  1.15203774,  2.06433052,  3.02983311,\n",
       "          5.50359574,  2.85152513]),\n",
       "  array([-1.79125368, -1.51018902,  1.13810066,  2.03911369,  3.00340474,\n",
       "          5.49707975,  2.83838762]),\n",
       "  array([-1.77739349, -1.50730387,  1.12405493,  2.01400855,  2.97709313,\n",
       "          5.49057267,  2.82578908]),\n",
       "  array([-1.7637392 , -1.50450191,  1.10990873,  1.98901653,  2.95089919,\n",
       "          5.48407589,  2.8137072 ]),\n",
       "  array([-1.75028074, -1.50178409,  1.09566984,  1.96413898,  2.92482376,\n",
       "          5.47759066,  2.80212053]),\n",
       "  array([-1.73700854, -1.4991511 ,  1.08134564,  1.93937716,  2.89886762,\n",
       "          5.4711182 ,  2.7910084 ]),\n",
       "  array([-1.72391353, -1.49660346,  1.06694313,  1.91473225,  2.87303149,\n",
       "          5.46465962,  2.78035095]),\n",
       "  array([-1.71098712, -1.4941415 ,  1.05246895,  1.89020534,  2.84731605,\n",
       "          5.45821595,  2.77012908]),\n",
       "  array([-1.69822115, -1.49176536,  1.03792939,  1.86579745,  2.8217219 ,\n",
       "          5.45178816,  2.76032444]),\n",
       "  array([-1.68560792, -1.48947506,  1.02333042,  1.84150952,  2.79624963,\n",
       "          5.44537714,  2.75091942]),\n",
       "  array([-1.67314012, -1.48727044,  1.00867768,  1.81734243,  2.77089973,\n",
       "          5.43898374,  2.74189709]),\n",
       "  array([-1.66081085, -1.48515124,  0.99397653,  1.79329696,  2.7456727 ,\n",
       "          5.43260871,  2.73324124]),\n",
       "  array([-1.64861358, -1.48311706,  0.97923204,  1.76937386,  2.72056897,\n",
       "          5.42625278,  2.7249363 ]),\n",
       "  array([-1.63654213, -1.4811674 ,  0.964449  ,  1.74557378,  2.69558893,\n",
       "          5.41991661,  2.71696735]),\n",
       "  array([-1.62459066, -1.47930166,  0.94963194,  1.72189735,  2.67073293,\n",
       "          5.4136008 ,  2.70932009]),\n",
       "  array([-1.61275366, -1.47751915,  0.93478516,  1.69834509,  2.6460013 ,\n",
       "          5.40730591,  2.70198083]),\n",
       "  array([-1.60102592, -1.47581911,  0.91991272,  1.67491749,  2.62139431,\n",
       "          5.40103246,  2.69493646]),\n",
       "  array([-1.58940254, -1.4742007 ,  0.90501844,  1.651615  ,  2.59691223,\n",
       "          5.39478092,  2.68817441]),\n",
       "  array([-1.57787886, -1.47266302,  0.89010597,  1.62843798,  2.57255527,\n",
       "          5.38855172,  2.68168268]),\n",
       "  array([-1.56645053, -1.47120511,  0.87517871,  1.60538676,  2.54832361,\n",
       "          5.38234525,  2.67544976]),\n",
       "  array([-1.55511342, -1.46982596,  0.86023992,  1.58246161,  2.52421743,\n",
       "          5.37616186,  2.66946467]),\n",
       "  array([-1.54386364, -1.46852452,  0.84529265,  1.55966276,  2.50023686,\n",
       "          5.37000189,  2.6637169 ]),\n",
       "  array([-1.53269753, -1.46729971,  0.83033979,  1.53699039,  2.47638199,\n",
       "          5.36386561,  2.65819639]),\n",
       "  array([-1.52161165, -1.4661504 ,  0.81538407,  1.51444464,  2.45265292,\n",
       "          5.35775329,  2.65289354]),\n",
       "  array([-1.51060275, -1.46507545,  0.80042806,  1.4920256 ,  2.4290497 ,\n",
       "          5.35166516,  2.64779917]),\n",
       "  array([-1.49966778, -1.46407369,  0.78547419,  1.46973332,  2.40557238,\n",
       "          5.34560143,  2.64290452]),\n",
       "  array([-1.48880386, -1.46314392,  0.77052475,  1.44756781,  2.38222095,\n",
       "          5.33956227,  2.63820122]),\n",
       "  array([-1.4780083 , -1.46228495,  0.75558192,  1.42552905,  2.35899542,\n",
       "          5.33354784,  2.63368126]),\n",
       "  array([-1.46727856, -1.46149556,  0.74064774,  1.40361697,  2.33589576,\n",
       "          5.32755828,  2.62933701]),\n",
       "  array([-1.45661226, -1.46077452,  0.72572413,  1.38183148,  2.31292192,\n",
       "          5.3215937 ,  2.62516119]),\n",
       "  array([-1.44600716, -1.46012061,  0.71081291,  1.36017244,  2.29007384,\n",
       "          5.31565419,  2.62114684]),\n",
       "  array([-1.43546116, -1.4595326 ,  0.6959158 ,  1.33863969,  2.26735143,\n",
       "          5.30973984,  2.61728732]),\n",
       "  array([-1.42497228, -1.45900925,  0.68103442,  1.31723304,  2.2447546 ,\n",
       "          5.3038507 ,  2.61357629]),\n",
       "  array([-1.41453867, -1.45854934,  0.66617029,  1.29595225,  2.22228323,\n",
       "          5.29798681,  2.61000771]),\n",
       "  array([-1.40415861, -1.45815165,  0.65132486,  1.27479709,  2.19993719,\n",
       "          5.2921482 ,  2.60657581]),\n",
       "  array([-1.39383048, -1.45781495,  0.63649948,  1.25376725,  2.17771633,\n",
       "          5.28633489,  2.60327508]),\n",
       "  array([-1.38355273, -1.45753804,  0.62169544,  1.23286245,  2.1556205 ,\n",
       "          5.28054689,  2.60010028]),\n",
       "  array([-1.37332396, -1.45731971,  0.60691394,  1.21208234,  2.13364952,\n",
       "          5.27478417,  2.5970464 ]),\n",
       "  array([-1.36314283, -1.45715877,  0.59215612,  1.19142658,  2.1118032 ,\n",
       "          5.26904672,  2.59410866]),\n",
       "  array([-1.3530081 , -1.45705405,  0.57742306,  1.17089477,  2.09008135,\n",
       "          5.2633345 ,  2.5912825 ]),\n",
       "  array([-1.34291858, -1.45700437,  0.56271577,  1.15048654,  2.06848376,\n",
       "          5.25764748,  2.58856357]),\n",
       "  array([-1.33287321, -1.45700858,  0.54803521,  1.13020144,  2.04701019,\n",
       "          5.2519856 ,  2.58594773]),\n",
       "  array([-1.32287095, -1.45706555,  0.53338228,  1.11003906,  2.02566043,\n",
       "          5.2463488 ,  2.58343102]),\n",
       "  array([-1.31291086, -1.45717415,  0.51875783,  1.08999891,  2.00443422,\n",
       "          5.24073702,  2.58100967]),\n",
       "  array([-1.30299205, -1.45733326,  0.50416267,  1.07008054,  1.98333132,\n",
       "          5.23515018,  2.57868008]),\n",
       "  array([-1.2931137 , -1.4575418 ,  0.48959754,  1.05028345,  1.96235145,\n",
       "          5.2295882 ,  2.5764388 ]),\n",
       "  array([-1.28327502, -1.45779869,  0.47506317,  1.03060712,  1.94149435,\n",
       "          5.22405098,  2.57428257]),\n",
       "  array([-1.2734753 , -1.45810286,  0.46056023,  1.01105105,  1.92075973,\n",
       "          5.21853845,  2.57220825]),\n",
       "  array([-1.26371388, -1.45845329,  0.44608935,  0.99161468,  1.9001473 ,\n",
       "          5.21305049,  2.57021286]),\n",
       "  array([-1.25399013, -1.45884893,  0.43165113,  0.97229747,  1.87965676,\n",
       "          5.20758701,  2.56829355]),\n",
       "  array([-1.24430346, -1.45928878,  0.41724615,  0.95309886,  1.85928782,\n",
       "          5.20214789,  2.56644759]),\n",
       "  array([-1.23465334, -1.45977185,  0.40287493,  0.93401826,  1.83904014,\n",
       "          5.19673303,  2.56467239]),\n",
       "  array([-1.22503926, -1.46029716,  0.38853798,  0.91505511,  1.81891341,\n",
       "          5.19134231,  2.56296547]),\n",
       "  array([-1.21546077, -1.46086377,  0.37423577,  0.89620879,  1.7989073 ,\n",
       "          5.1859756 ,  2.56132446]),\n",
       "  array([-1.20591742, -1.46147072,  0.35996876,  0.8774787 ,  1.77902148,\n",
       "          5.18063279,  2.55974708]),\n",
       "  array([-1.19640881, -1.4621171 ,  0.34573736,  0.85886423,  1.75925561,\n",
       "          5.17531375,  2.55823119]),\n",
       "  array([-1.18693458, -1.46280201,  0.33154199,  0.84036476,  1.73960933,\n",
       "          5.17001835,  2.55677471]),\n",
       "  array([-1.17749438, -1.46352455,  0.31738301,  0.82197965,  1.72008229,\n",
       "          5.16474646,  2.55537566]),\n",
       "  array([-1.16808788, -1.46428386,  0.30326078,  0.80370827,  1.70067414,\n",
       "          5.15949794,  2.55403215]),\n",
       "  array([-1.15871479, -1.46507908,  0.28917565,  0.78554996,  1.6813845 ,\n",
       "          5.15427268,  2.55274238]),\n",
       "  array([-1.14937483, -1.46590939,  0.27512792,  0.76750409,  1.66221301,\n",
       "          5.14907051,  2.55150461]),\n",
       "  array([-1.14006775, -1.46677395,  0.26111791,  0.74957   ,  1.64315929,\n",
       "          5.14389132,  2.55031718]),\n",
       "  array([-1.13079332, -1.46767196,  0.24714588,  0.73174701,  1.62422297,\n",
       "          5.13873497,  2.54917851]),\n",
       "  array([-1.12155132, -1.46860265,  0.23321212,  0.71403448,  1.60540365,\n",
       "          5.1336013 ,  2.54808708]),\n",
       "  array([-1.11234154, -1.46956523,  0.21931687,  0.69643172,  1.58670095,\n",
       "          5.12849018,  2.54704144]),\n",
       "  array([-1.1031638 , -1.47055895,  0.20546037,  0.67893806,  1.56811447,\n",
       "          5.12340147,  2.54604018]),\n",
       "  array([-1.09401793, -1.47158307,  0.19164284,  0.66155284,  1.54964382,\n",
       "          5.11833503,  2.54508197]),\n",
       "  array([-1.08490376, -1.47263687,  0.17786451,  0.64427536,  1.53128859,\n",
       "          5.11329072,  2.54416552]),\n",
       "  array([-1.07582116, -1.47371963,  0.16412557,  0.62710495,  1.51304838,\n",
       "          5.10826839,  2.54328961]),\n",
       "  array([-1.06676998, -1.47483066,  0.1504262 ,  0.61004092,  1.49492277,\n",
       "          5.10326789,  2.54245305]),\n",
       "  array([-1.0577501 , -1.47596928,  0.13676659,  0.59308259,  1.47691137,\n",
       "          5.09828909,  2.54165469]),\n",
       "  array([-1.04876141, -1.47713483,  0.12314691,  0.57622926,  1.45901374,\n",
       "          5.09333185,  2.54089346]),\n",
       "  array([-1.0398038 , -1.47832664,  0.10956731,  0.55948026,  1.44122947,\n",
       "          5.08839601,  2.5401683 ]),\n",
       "  array([-1.03087716, -1.47954408,  0.09602794,  0.5428349 ,  1.42355814,\n",
       "          5.08348144,  2.5394782 ]),\n",
       "  array([-1.02198141, -1.48078653,  0.08252894,  0.52629247,  1.40599932,\n",
       "          5.07858799,  2.53882219]),\n",
       "  array([-1.01311645, -1.48205336,  0.06907045,  0.50985231,  1.38855258,\n",
       "          5.07371552,  2.53819934]),\n",
       "  array([-1.00428222, -1.48334399,  0.05565258,  0.49351371,  1.37121749,\n",
       "          5.06886388,  2.53760873]),\n",
       "  array([-0.99547864, -1.48465781,  0.04227546,  0.47727598,  1.35399361,\n",
       "          5.06403295,  2.53704951]),\n",
       "  array([-0.98670563, -1.48599427,  0.02893918,  0.46113845,  1.33688052,\n",
       "          5.05922256,  2.53652084]),\n",
       "  array([-0.97796313, -1.48735278,  0.01564386,  0.44510042,  1.31987776,\n",
       "          5.05443259,  2.5360219 ]),\n",
       "  array([ -9.69251095e-01,  -1.48873281e+00,   2.38959382e-03,\n",
       "           4.29161205e-01,   1.30298489e+00,   5.04966290e+00,\n",
       "           2.53555193e+00]),\n",
       "  array([-0.96056945, -1.4901338 , -0.01082354,  0.41332012,  1.28620148,\n",
       "          5.04491333,  2.53511016]),\n",
       "  array([-0.95191815, -1.49155524, -0.02399545,  0.39757649,  1.26952708,\n",
       "          5.04018376,  2.53469586]),\n",
       "  array([-0.94329715, -1.4929966 , -0.03712606,  0.38192962,  1.25296122,\n",
       "          5.03547404,  2.53430835]),\n",
       "  array([-0.93470639, -1.49445738, -0.05021531,  0.36637884,  1.23650348,\n",
       "          5.03078404,  2.53394692]),\n",
       "  array([-0.92614583, -1.49593708, -0.06326312,  0.35092346,  1.22015338,\n",
       "          5.02611362,  2.53361094]),\n",
       "  array([-0.91761543, -1.49743521, -0.07626943,  0.33556283,  1.20391048,\n",
       "          5.02146265,  2.53329975]),\n",
       "  array([-0.90911515, -1.4989513 , -0.08923419,  0.32029624,  1.18777432,\n",
       "          5.01683098,  2.53301275]),\n",
       "  array([-0.90064494, -1.50048488, -0.10215735,  0.30512305,  1.17174443,\n",
       "          5.01221849,  2.53274933]),\n",
       "  array([-0.89220477, -1.50203549, -0.11503886,  0.29004258,  1.15582037,\n",
       "          5.00762503,  2.53250891]),\n",
       "  array([-0.8837946 , -1.50360269, -0.12787868,  0.27505416,  1.14000166,\n",
       "          5.00305049,  2.53229093]),\n",
       "  array([-0.87541439, -1.50518604, -0.14067676,  0.26015714,  1.12428784,\n",
       "          4.99849472,  2.53209485]),\n",
       "  array([-0.8670641 , -1.50678511, -0.15343309,  0.24535084,  1.10867846,\n",
       "          4.99395759,  2.53192013]),\n",
       "  array([-0.8587437 , -1.50839947, -0.16614761,  0.23063462,  1.09317303,\n",
       "          4.98943897,  2.53176626]),\n",
       "  array([-0.85045316, -1.51002873, -0.17882032,  0.21600781,  1.07777109,\n",
       "          4.98493874,  2.53163274]),\n",
       "  array([-0.84219243, -1.51167247, -0.19145119,  0.20146978,  1.06247217,\n",
       "          4.98045677,  2.53151908]),\n",
       "  array([-0.83396148, -1.51333031, -0.2040402 ,  0.18701987,  1.0472758 ,\n",
       "          4.97599292,  2.5314248 ]),\n",
       "  array([-0.82576028, -1.51500184, -0.21658733,  0.17265743,  1.0321815 ,\n",
       "          4.97154707,  2.53134945]),\n",
       "  array([-0.81758879, -1.5166867 , -0.22909258,  0.15838183,  1.01718881,\n",
       "          4.9671191 ,  2.53129258]),\n",
       "  array([-0.80944698, -1.51838452, -0.24155593,  0.14419243,  1.00229725,\n",
       "          4.96270888,  2.53125374]),\n",
       "  array([-0.8013348 , -1.52009492, -0.25397738,  0.13008859,  0.98750633,\n",
       "          4.95831628,  2.53123251]),\n",
       "  array([-0.79325222, -1.52181756, -0.26635693,  0.11606968,  0.9728156 ,\n",
       "          4.95394119,  2.53122848]),\n",
       "  array([-0.7851992 , -1.52355208, -0.27869457,  0.10213508,  0.95822455,\n",
       "          4.94958347,  2.53124124]),\n",
       "  array([-0.7771757 , -1.52529815, -0.29099033,  0.08828417,  0.94373272,\n",
       "          4.94524302,  2.53127039]),\n",
       "  array([-0.76918169, -1.52705542, -0.30324419,  0.07451632,  0.92933963,\n",
       "          4.94091971,  2.53131555]),\n",
       "  array([-0.76121713, -1.52882357, -0.31545617,  0.06083092,  0.91504479,\n",
       "          4.93661342,  2.53137634]),\n",
       "  array([-0.75328196, -1.53060228, -0.32762628,  0.04722735,  0.90084772,\n",
       "          4.93232403,  2.53145239]),\n",
       "  array([-0.74537616, -1.53239123, -0.33975455,  0.03370501,  0.88674794,\n",
       "          4.92805142,  2.53154334]),\n",
       "  array([-0.73749968, -1.53419012, -0.35184098,  0.0202633 ,  0.87274497,\n",
       "          4.92379548,  2.53164884]),\n",
       "  array([-0.72965248, -1.53599863, -0.3638856 ,  0.00690161,  0.85883832,\n",
       "          4.91955609,  2.53176855]),\n",
       "  array([-0.72183451, -1.53781648, -0.37588842, -0.00638065,  0.84502751,\n",
       "          4.91533315,  2.53190212]),\n",
       "  array([-0.71404572, -1.53964338, -0.38784949, -0.01958408,  0.83131205,\n",
       "          4.91112652,  2.53204924]),\n",
       "  array([-0.70628607, -1.54147903, -0.39976882, -0.03270926,  0.81769145,\n",
       "          4.9069361 ,  2.53220957]),\n",
       "  array([-0.69855552, -1.54332316, -0.41164644, -0.04575679,  0.80416523,\n",
       "          4.90276178,  2.53238281]),\n",
       "  array([-0.69085401, -1.5451755 , -0.42348239, -0.05872723,  0.79073291,\n",
       "          4.89860345,  2.53256864]),\n",
       "  array([-0.6831815 , -1.54703577, -0.43527671, -0.07162117,  0.77739399,\n",
       "          4.894461  ,  2.53276677]),\n",
       "  array([-0.67553793, -1.54890372, -0.44702942, -0.08443918,  0.76414798,\n",
       "          4.89033431,  2.53297689]),\n",
       "  array([-0.66792325, -1.55077908, -0.45874057, -0.09718184,  0.75099441,\n",
       "          4.88622328,  2.53319871]),\n",
       "  array([-0.66033741, -1.5526616 , -0.47041021, -0.10984969,  0.73793277,\n",
       "          4.8821278 ,  2.53343196]),\n",
       "  array([-0.65278036, -1.55455105, -0.48203836, -0.12244332,  0.72496259,\n",
       "          4.87804776,  2.53367635]),\n",
       "  array([-0.64525204, -1.55644716, -0.49362509, -0.13496326,  0.71208336,\n",
       "          4.87398306,  2.53393162]),\n",
       "  array([-0.63775239, -1.55834971, -0.50517044, -0.14741008,  0.69929462,\n",
       "          4.86993359,  2.53419748]),\n",
       "  array([-0.63028136, -1.56025846, -0.51667446, -0.15978433,  0.68659586,\n",
       "          4.86589924,  2.53447369]),\n",
       "  array([-0.62283889, -1.56217318, -0.52813719, -0.17208655,  0.67398659,\n",
       "          4.86187992,  2.53475999]),\n",
       "  array([-0.61542493, -1.56409365, -0.5395587 , -0.18431728,  0.66146633,\n",
       "          4.85787552,  2.53505611]),\n",
       "  array([-0.6080394 , -1.56601965, -0.55093904, -0.19647707,  0.64903459,\n",
       "          4.85388594,  2.53536182]),\n",
       "  array([-0.60068226, -1.56795096, -0.56227827, -0.20856643,  0.63669088,\n",
       "          4.84991107,  2.53567688]),\n",
       "  array([-0.59335343, -1.56988737, -0.57357644, -0.22058591,  0.62443471,\n",
       "          4.84595082,  2.53600104]),\n",
       "  array([-0.58605286, -1.57182867, -0.58483362, -0.23253603,  0.61226559,\n",
       "          4.84200509,  2.53633407]),\n",
       "  array([-0.57878047, -1.57377466, -0.59604987, -0.24441731,  0.60018304,\n",
       "          4.83807377,  2.53667575]),\n",
       "  array([-0.57153622, -1.57572515, -0.60722525, -0.25623027,  0.58818656,\n",
       "          4.83415677,  2.53702584]),\n",
       "  array([-0.56432002, -1.57767993, -0.61835983, -0.26797543,  0.57627567,\n",
       "          4.83025399,  2.53738413]),\n",
       "  array([-0.55713182, -1.57963881, -0.62945368, -0.27965328,  0.56444988,\n",
       "          4.82636533,  2.5377504 ]),\n",
       "  array([-0.54997154, -1.58160161, -0.64050686, -0.29126435,  0.5527087 ,\n",
       "          4.8224907 ,  2.53812444]),\n",
       "  array([-0.54283911, -1.58356814, -0.65151946, -0.30280913,  0.54105165,\n",
       "          4.81863001,  2.53850605]),\n",
       "  array([-0.53573447, -1.58553823, -0.66249153, -0.31428812,  0.52947824,\n",
       "          4.81478315,  2.53889501]),\n",
       "  array([-0.52865755, -1.58751168, -0.67342315, -0.32570181,  0.51798798,\n",
       "          4.81095003,  2.53929112]),\n",
       "  array([-0.52160827, -1.58948834, -0.68431441, -0.3370507 ,  0.5065804 ,\n",
       "          4.80713057,  2.5396942 ]),\n",
       "  array([-0.51458657, -1.59146803, -0.69516537, -0.34833528,  0.495255  ,\n",
       "          4.80332466,  2.54010404]),\n",
       "  array([-0.50759236, -1.59345058, -0.70597611, -0.35955602,  0.48401129,\n",
       "          4.79953222,  2.54052045]),\n",
       "  array([-0.50062558, -1.59543582, -0.71674672, -0.37071342,  0.47284881,\n",
       "          4.79575315,  2.54094326]),\n",
       "  array([-0.49368615, -1.59742361, -0.72747727, -0.38180793,  0.46176707,\n",
       "          4.79198736,  2.54137227]),\n",
       "  array([-0.48677399, -1.59941378, -0.73816785, -0.39284005,  0.45076557,\n",
       "          4.78823477,  2.54180732]),\n",
       "  array([-0.47988904, -1.60140617, -0.74881854, -0.40381023,  0.43984385,\n",
       "          4.78449528,  2.54224821]),\n",
       "  array([-0.47303121, -1.60340064, -0.75942942, -0.41471894,  0.42900143,\n",
       "          4.78076881,  2.54269478]),\n",
       "  array([-0.46620042, -1.60539704, -0.77000059, -0.42556664,  0.41823781,\n",
       "          4.77705526,  2.54314687]),\n",
       "  array([-0.4593966 , -1.60739522, -0.78053212, -0.43635379,  0.40755253,\n",
       "          4.77335456,  2.5436043 ]),\n",
       "  array([-0.45261966, -1.60939503, -0.79102411, -0.44708085,  0.39694511,\n",
       "          4.76966661,  2.5440669 ]),\n",
       "  array([-0.44586954, -1.61139635, -0.80147665, -0.45774826,  0.38641507,\n",
       "          4.76599132,  2.54453453]),\n",
       "  array([-0.43914615, -1.61339902, -0.81188982, -0.46835647,  0.37596194,\n",
       "          4.76232862,  2.54500702]),\n",
       "  array([-0.4324494 , -1.61540292, -0.82226373, -0.47890593,  0.36558524,\n",
       "          4.75867842,  2.54548422]),\n",
       "  array([-0.42577922, -1.61740792, -0.83259845, -0.48939708,  0.35528449,\n",
       "          4.75504062,  2.54596598]),\n",
       "  array([-0.41913553, -1.61941388, -0.84289409, -0.49983035,  0.34505924,\n",
       "          4.75141516,  2.54645215]),\n",
       "  array([-0.41251824, -1.62142068, -0.85315074, -0.51020617,  0.33490899,\n",
       "          4.74780194,  2.54694258]),\n",
       "  array([-0.40592727, -1.62342819, -0.8633685 , -0.52052498,  0.3248333 ,\n",
       "          4.74420089,  2.54743713]),\n",
       "  array([-0.39936254, -1.6254363 , -0.87354746, -0.5307872 ,  0.31483168,\n",
       "          4.74061192,  2.54793566]),\n",
       "  array([-0.39282397, -1.62744488, -0.88368773, -0.54099325,  0.30490367,\n",
       "          4.73703495,  2.54843804]),\n",
       "  array([-0.38631146, -1.62945381, -0.89378939, -0.55114356,  0.2950488 ,\n",
       "          4.7334699 ,  2.54894412]),\n",
       "  array([-0.37982494, -1.63146298, -0.90385255, -0.56123854,  0.28526661,\n",
       "          4.72991669,  2.54945379]),\n",
       "  array([-0.37336432, -1.63347229, -0.91387732, -0.5712786 ,  0.27555664,\n",
       "          4.72637524,  2.5499669 ]),\n",
       "  array([-0.36692951, -1.63548161, -0.92386379, -0.58126415,  0.26591842,\n",
       "          4.72284547,  2.55048332]),\n",
       "  array([-0.36052044, -1.63749083, -0.93381206, -0.5911956 ,  0.2563515 ,\n",
       "          4.7193273 ,  2.55100295]),\n",
       "  array([-0.35413701, -1.63949986, -0.94372224, -0.60107335,  0.24685541,\n",
       "          4.71582066,  2.55152565]),\n",
       "  array([-0.34777913, -1.64150859, -0.95359443, -0.6108978 ,  0.2374297 ,\n",
       "          4.71232546,  2.5520513 ]),\n",
       "  array([-0.34144673, -1.64351692, -0.96342874, -0.62066935,  0.2280739 ,\n",
       "          4.70884164,  2.55257978]),\n",
       "  array([-0.33513971, -1.64552474, -0.97322527, -0.63038838,  0.21878758,\n",
       "          4.70536911,  2.55311099]),\n",
       "  array([-0.32885798, -1.64753197, -0.98298413, -0.6400553 ,  0.20957026,\n",
       "          4.7019078 ,  2.55364481]),\n",
       "  array([-0.32260146, -1.64953849, -0.99270542, -0.64967048,  0.20042151,\n",
       "          4.69845764,  2.55418112]),\n",
       "  array([-0.31637007, -1.65154423, -1.00238926, -0.65923431,  0.19134087,\n",
       "          4.69501854,  2.55471983]),\n",
       "  array([-0.3101637 , -1.65354908, -1.01203574, -0.66874717,  0.18232789,\n",
       "          4.69159044,  2.55526082]),\n",
       "  array([-0.30398229, -1.65555296, -1.02164499, -0.67820943,  0.17338213,\n",
       "          4.68817326,  2.55580398]),\n",
       "  array([-0.29782572, -1.65755577, -1.0312171 , -0.68762148,  0.16450314,\n",
       "          4.68476692,  2.55634923]),\n",
       "  array([-0.29169392, -1.65955744, -1.04075219, -0.69698368,  0.15569048,\n",
       "          4.68137137,  2.55689645]),\n",
       "  array([-0.2855868 , -1.66155787, -1.05025037, -0.7062964 ,  0.14694371,\n",
       "          4.67798651,  2.55744556]),\n",
       "  array([-0.27950427, -1.66355699, -1.05971175, -0.71556001,  0.13826239,\n",
       "          4.67461229,  2.55799645]),\n",
       "  array([-0.27344624, -1.66555471, -1.06913643, -0.72477486,  0.12964607,\n",
       "          4.67124863,  2.55854903]),\n",
       "  array([-0.26741262, -1.66755095, -1.07852455, -0.73394132,  0.12109433,\n",
       "          4.66789547,  2.55910321]),\n",
       "  array([-0.26140332, -1.66954563, -1.08787619, -0.74305973,  0.11260673,\n",
       "          4.66455272,  2.5596589 ]),\n",
       "  array([-0.25541825, -1.67153868, -1.09719149, -0.75213047,  0.10418284,\n",
       "          4.66122032,  2.56021602]),\n",
       "  array([-0.24945732, -1.67353002, -1.10647055, -0.76115387,  0.09582222,\n",
       "          4.65789821,  2.56077447]),\n",
       "  array([-0.24352045, -1.67551957, -1.11571348, -0.77013028,  0.08752446,\n",
       "          4.6545863 ,  2.56133418]),\n",
       "  array([-0.23760753, -1.67750728, -1.1249204 , -0.77906005,  0.07928911,\n",
       "          4.65128455,  2.56189505]),\n",
       "  array([-0.23171849, -1.67949306, -1.13409143, -0.78794352,  0.07111576,\n",
       "          4.64799287,  2.56245701]),\n",
       "  array([-0.22585322, -1.68147684, -1.14322668, -0.79678102,  0.06300398,\n",
       "          4.64471121,  2.56301999]),\n",
       "  array([-0.22001165, -1.68345856, -1.15232626, -0.8055729 ,  0.05495335,\n",
       "          4.64143948,  2.5635839 ]),\n",
       "  array([-0.21419368, -1.68543816, -1.16139029, -0.81431948,  0.04696346,\n",
       "          4.63817764,  2.56414867]),\n",
       "  array([-0.20839922, -1.68741556, -1.17041889, -0.8230211 ,  0.03903388,\n",
       "          4.63492561,  2.56471422]),\n",
       "  array([-0.20262818, -1.6893907 , -1.17941217, -0.83167808,  0.03116421,\n",
       "          4.63168332,  2.56528048]),\n",
       "  array([-0.19688047, -1.69136353, -1.18837025, -0.84029075,  0.02335402,\n",
       "          4.62845072,  2.56584739]),\n",
       "  array([-0.191156  , -1.69333398, -1.19729324, -0.84885943,  0.0156029 ,\n",
       "          4.62522774,  2.56641488]),\n",
       "  array([-0.18545468, -1.69530199, -1.20618127, -0.85738444,  0.00791046,\n",
       "          4.62201431,  2.56698287]),\n",
       "  array([ -1.79776426e-01,  -1.69726751e+00,  -1.21503445e+00,\n",
       "          -8.65866101e-01,   2.76269527e-04,   4.61881037e+00,\n",
       "           2.56755130e+00]),\n",
       "  array([-0.17412114, -1.69923047, -1.2238529 , -0.87430472, -0.00730006,\n",
       "          4.61561585,  2.5681201 ]),\n",
       "  array([-0.16848873, -1.70119082, -1.23263673, -0.88270061, -0.01481894,\n",
       "          4.61243071,  2.56868922]),\n",
       "  array([-0.16287911, -1.70314851, -1.24138607, -0.89105408, -0.02228077,\n",
       "          4.60925487,  2.5692586 ]),\n",
       "  array([-0.15729219, -1.70510348, -1.25010102, -0.89936543, -0.02968595,\n",
       "          4.60608827,  2.56982816]),\n",
       "  array([-0.15172788, -1.70705568, -1.25878172, -0.90763498, -0.03703487,\n",
       "          4.60293085,  2.57039786]),\n",
       "  array([-0.14618609, -1.70900506, -1.26742828, -0.91586302, -0.04432794,\n",
       "          4.59978255,  2.57096764]),\n",
       "  array([-0.14066674, -1.71095157, -1.27604081, -0.92404984, -0.05156553,\n",
       "          4.59664331,  2.57153744]),\n",
       "  array([-0.13516972, -1.71289516, -1.28461944, -0.93219576, -0.05874805,\n",
       "          4.59351306,  2.57210721]),\n",
       "  array([-0.12969495, -1.71483579, -1.29316428, -0.94030105, -0.06587588,\n",
       "          4.59039176,  2.57267689]),\n",
       "  array([-0.12424235, -1.7167734 , -1.30167546, -0.94836601, -0.0729494 ,\n",
       "          4.58727935,  2.57324643]),\n",
       "  array([-0.11881182, -1.71870796, -1.31015308, -0.95639093, -0.07996901,\n",
       "          4.58417575,  2.57381579]),\n",
       "  array([-0.11340327, -1.72063941, -1.31859728, -0.9643761 , -0.08693508,\n",
       "          4.58108092,  2.57438491]),\n",
       "  array([-0.10801662, -1.72256772, -1.32700817, -0.9723218 , -0.093848  ,\n",
       "          4.5779948 ,  2.57495374]),\n",
       "  array([-0.10265177, -1.72449284, -1.33538586, -0.9802283 , -0.10070814,\n",
       "          4.57491732,  2.57552224]),\n",
       "  array([-0.09730864, -1.72641472, -1.34373049, -0.9880959 , -0.10751587,\n",
       "          4.57184844,  2.57609036]),\n",
       "  array([-0.09198714, -1.72833334, -1.35204216, -0.99592486, -0.11427157,\n",
       "          4.5687881 ,  2.57665806]),\n",
       "  array([-0.08668718, -1.73024865, -1.360321  , -1.00371545, -0.12097562,\n",
       "          4.56573623,  2.57722529]),\n",
       "  array([-0.08140867, -1.73216061, -1.36856712, -1.01146797, -0.12762838,\n",
       "          4.56269279,  2.57779202]),\n",
       "  array([-0.07615152, -1.73406918, -1.37678065, -1.01918266, -0.13423021,\n",
       "          4.55965772,  2.57835819]),\n",
       "  array([-0.07091565, -1.73597433, -1.3849617 , -1.0268598 , -0.14078149,\n",
       "          4.55663096,  2.57892378]),\n",
       "  array([-0.06570097, -1.73787603, -1.3931104 , -1.03449965, -0.14728257,\n",
       "          4.55361247,  2.57948873]),\n",
       "  array([-0.06050738, -1.73977422, -1.40122685, -1.04210248, -0.15373382,\n",
       "          4.55060218,  2.58005302]),\n",
       "  array([-0.05533481, -1.74166889, -1.40931119, -1.04966855, -0.16013559,\n",
       "          4.54760004,  2.58061661]),\n",
       "  array([-0.05018317, -1.74356   , -1.41736353, -1.05719811, -0.16648824,\n",
       "          4.54460601,  2.58117945]),\n",
       "  array([-0.04505236, -1.74544752, -1.42538398, -1.06469143, -0.17279213,\n",
       "          4.54162001,  2.58174153]),\n",
       "  array([-0.0399423 , -1.74733141, -1.43337267, -1.07214875, -0.1790476 ,\n",
       "          4.53864202,  2.58230279]),\n",
       "  array([-0.03485291, -1.74921165, -1.44132972, -1.07957032, -0.18525501,\n",
       "          4.53567196,  2.58286321]),\n",
       "  array([-0.0297841 , -1.7510882 , -1.44925524, -1.08695641, -0.1914147 ,\n",
       "          4.5327098 ,  2.58342275]),\n",
       "  array([-0.02473578, -1.75296104, -1.45714935, -1.09430725, -0.19752702,\n",
       "          4.52975547,  2.58398139]),\n",
       "  array([-0.01970786, -1.75483013, -1.46501218, -1.10162309, -0.20359231,\n",
       "          4.52680893,  2.58453909]),\n",
       "  array([-0.01470027, -1.75669546, -1.47284383, -1.10890417, -0.20961091,\n",
       "          4.52387013,  2.58509582]),\n",
       "  array([-0.00971291, -1.75855698, -1.48064443, -1.11615073, -0.21558317,\n",
       "          4.52093902,  2.58565156]),\n",
       "  array([-0.0047457 , -1.76041468, -1.48841409, -1.12336302, -0.22150941,\n",
       "          4.51801554,  2.58620628]),\n",
       "  array([  2.01442455e-04,  -1.76226854e+00,  -1.49615294e+00,\n",
       "          -1.13054128e+00,  -2.27389979e-01,   4.51509966e+00,\n",
       "           2.58675994e+00]),\n",
       "  array([ 0.00512861, -1.76411851, -1.50386109, -1.13768572, -0.2332252 ,\n",
       "          4.51219131,  2.58731253]),\n",
       "  array([ 0.01003588, -1.7659646 , -1.51153865, -1.1447966 , -0.23901541,\n",
       "          4.50929045,  2.58786401]),\n",
       "  array([ 0.01492334, -1.76780675, -1.51918575, -1.15187414, -0.24476093,\n",
       "          4.50639703,  2.58841437]),\n",
       "  array([ 0.01979107, -1.76964497, -1.5268025 , -1.15891857, -0.25046209,\n",
       "          4.50351101,  2.58896358]),\n",
       "  array([ 0.02463916, -1.77147922, -1.53438902, -1.16593012, -0.25611922,\n",
       "          4.50063234,  2.58951161]),\n",
       "  array([ 0.02946769, -1.77330948, -1.54194543, -1.172909  , -0.26173263,\n",
       "          4.49776096,  2.59005844]),\n",
       "  array([ 0.03427675, -1.77513573, -1.54947183, -1.17985546, -0.26730264,\n",
       "          4.49489684,  2.59060406]),\n",
       "  array([ 0.03906642, -1.77695795, -1.55696836, -1.1867697 , -0.27282958,\n",
       "          4.49203992,  2.59114843]),\n",
       "  array([ 0.04383677, -1.77877613, -1.56443512, -1.19365195, -0.27831376,\n",
       "          4.48919016,  2.59169154]),\n",
       "  array([ 0.0485879 , -1.78059024, -1.57187222, -1.20050243, -0.28375548,\n",
       "          4.48634752,  2.59223338]),\n",
       "  array([ 0.05331988, -1.78240026, -1.57927979, -1.20732135, -0.28915507,\n",
       "          4.48351194,  2.59277391]),\n",
       "  array([ 0.0580328 , -1.78420618, -1.58665795, -1.21410892, -0.29451283,\n",
       "          4.48068339,  2.59331312]),\n",
       "  array([ 0.06272675, -1.78600798, -1.5940068 , -1.22086536, -0.29982907,\n",
       "          4.47786181,  2.59385099]),\n",
       "  array([ 0.06740179, -1.78780564, -1.60132645, -1.22759088, -0.3051041 ,\n",
       "          4.47504717,  2.59438751]),\n",
       "  array([ 0.07205801, -1.78959915, -1.60861704, -1.23428569, -0.3103382 ,\n",
       "          4.47223942,  2.59492266]),\n",
       "  array([ 0.0766955 , -1.79138849, -1.61587866, -1.24094999, -0.3155317 ,\n",
       "          4.46943852,  2.59545641]),\n",
       "  array([ 0.08131434, -1.79317365, -1.62311144, -1.24758399, -0.32068488,\n",
       "          4.46664442,  2.59598877]),\n",
       "  array([ 0.08591459, -1.79495461, -1.63031548, -1.25418789, -0.32579805,\n",
       "          4.46385708,  2.59651971]),\n",
       "  array([ 0.09049636, -1.79673136, -1.63749091, -1.2607619 , -0.33087149,\n",
       "          4.46107645,  2.59704921]),\n",
       "  array([ 0.09505971, -1.79850388, -1.64463782, -1.26730621, -0.3359055 ,\n",
       "          4.4583025 ,  2.59757726]),\n",
       "  array([ 0.09960472, -1.80027216, -1.65175635, -1.27382102, -0.34090037,\n",
       "          4.45553518,  2.59810386]),\n",
       "  array([ 0.10413148, -1.8020362 , -1.6588466 , -1.28030653, -0.3458564 ,\n",
       "          4.45277446,  2.59862898]),\n",
       "  array([ 0.10864006, -1.80379597, -1.66590867, -1.28676294, -0.35077385,\n",
       "          4.45002028,  2.59915261]),\n",
       "  array([ 0.11313054, -1.80555146, -1.6729427 , -1.29319044, -0.35565303,\n",
       "          4.44727261,  2.59967475]),\n",
       "  array([ 0.117603  , -1.80730268, -1.67994878, -1.29958921, -0.36049421,\n",
       "          4.44453141,  2.60019537]),\n",
       "  array([ 0.12205752, -1.80904959, -1.68692702, -1.30595946, -0.36529767,\n",
       "          4.44179663,  2.60071448]),\n",
       "  array([ 0.12649418, -1.8107922 , -1.69387755, -1.31230136, -0.3700637 ,\n",
       "          4.43906824,  2.60123205]),\n",
       "  array([ 0.13091306, -1.8125305 , -1.70080047, -1.31861511, -0.37479256,\n",
       "          4.4363462 ,  2.60174808]),\n",
       "  array([ 0.13531422, -1.81426447, -1.70769589, -1.32490088, -0.37948454,\n",
       "          4.43363046,  2.60226255]),\n",
       "  array([ 0.13969776, -1.8159941 , -1.71456392, -1.33115888, -0.3841399 ,\n",
       "          4.43092099,  2.60277547]),\n",
       "  array([ 0.14406374, -1.8177194 , -1.72140467, -1.33738926, -0.38875892,\n",
       "          4.42821775,  2.60328681]),\n",
       "  array([ 0.14841225, -1.81944034, -1.72821825, -1.34359223, -0.39334186,\n",
       "          4.4255207 ,  2.60379658]),\n",
       "  array([ 0.15274335, -1.82115693, -1.73500477, -1.34976795, -0.397889  ,\n",
       "          4.4228298 ,  2.60430475]),\n",
       "  array([ 0.15705713, -1.82286915, -1.74176435, -1.3559166 , -0.40240059,\n",
       "          4.42014502,  2.60481134]),\n",
       "  array([ 0.16135366, -1.824577  , -1.74849708, -1.36203837, -0.4068769 ,\n",
       "          4.41746631,  2.60531632]),\n",
       "  array([ 0.16563301, -1.82628047, -1.75520307, -1.36813342, -0.4113182 ,\n",
       "          4.41479364,  2.60581969]),\n",
       "  array([ 0.16989527, -1.82797956, -1.76188245, -1.37420192, -0.41572473,\n",
       "          4.41212697,  2.60632144]),\n",
       "  array([ 0.1741405 , -1.82967426, -1.7685353 , -1.38024406, -0.42009677,\n",
       "          4.40946627,  2.60682157]),\n",
       "  array([ 0.17836879, -1.83136456, -1.77516175, -1.38625999, -0.42443456,\n",
       "          4.40681149,  2.60732008]),\n",
       "  array([ 0.18258019, -1.83305047, -1.7817619 , -1.3922499 , -0.42873835,\n",
       "          4.4041626 ,  2.60781695]),\n",
       "  array([ 0.1867748 , -1.83473197, -1.78833585, -1.39821394, -0.43300841,\n",
       "          4.40151957,  2.60831218]),\n",
       "  array([ 0.19095268, -1.83640906, -1.79488371, -1.40415228, -0.43724497,\n",
       "          4.39888236,  2.60880576]),\n",
       "  array([ 0.19511391, -1.83808174, -1.80140558, -1.41006508, -0.44144829,\n",
       "          4.39625094,  2.6092977 ]),\n",
       "  array([ 0.19925855, -1.83975   , -1.80790158, -1.41595252, -0.44561862,\n",
       "          4.39362526,  2.60978798]),\n",
       "  array([ 0.20338669, -1.84141385, -1.81437181, -1.42181475, -0.44975619,\n",
       "          4.3910053 ,  2.6102766 ]),\n",
       "  array([ 0.20749839, -1.84307327, -1.82081637, -1.42765193, -0.45386126,\n",
       "          4.38839101,  2.61076357]),\n",
       "  array([ 0.21159372, -1.84472826, -1.82723537, -1.43346423, -0.45793406,\n",
       "          4.38578237,  2.61124886]),\n",
       "  array([ 0.21567277, -1.84637883, -1.83362892, -1.43925179, -0.46197483,\n",
       "          4.38317935,  2.61173249]),\n",
       "  array([ 0.21973559, -1.84802497, -1.83999711, -1.44501478, -0.46598381,\n",
       "          4.38058189,  2.61221445]),\n",
       "  array([ 0.22378227, -1.84966668, -1.84634005, -1.45075335, -0.46996123,\n",
       "          4.37798999,  2.61269474]),\n",
       "  array([ 0.22781286, -1.85130396, -1.85265784, -1.45646765, -0.47390733,\n",
       "          4.37540359,  2.61317334]),\n",
       "  array([ 0.23182746, -1.8529368 , -1.85895059, -1.46215784, -0.47782235,\n",
       "          4.37282267,  2.61365027]),\n",
       "  array([ 0.23582611, -1.85456521, -1.8652184 , -1.46782407, -0.4817065 ,\n",
       "          4.3702472 ,  2.61412552]),\n",
       "  array([ 0.2398089 , -1.85618918, -1.87146137, -1.4734665 , -0.48556002,\n",
       "          4.36767714,  2.61459908]),\n",
       "  array([ 0.24377589, -1.85780872, -1.87767961, -1.47908526, -0.48938315,\n",
       "          4.36511245,  2.61507096]),\n",
       "  array([ 0.24772716, -1.85942382, -1.88387321, -1.4846805 , -0.49317609,\n",
       "          4.36255312,  2.61554116]),\n",
       "  array([ 0.25166276, -1.86103449, -1.89004228, -1.49025238, -0.49693908,\n",
       "          4.3599991 ,  2.61600967]),\n",
       "  array([ 0.25558278, -1.86264073, -1.89618691, -1.49580104, -0.50067234,\n",
       "          4.35745037,  2.61647649]),\n",
       "  array([ 0.25948728, -1.86424252, -1.90230722, -1.50132661, -0.50437609,\n",
       "          4.35490689,  2.61694162]),\n",
       "  array([ 0.26337633, -1.86583989, -1.90840329, -1.50682926, -0.50805054,\n",
       "          4.35236863,  2.61740507]),\n",
       "  array([ 0.26724999, -1.86743282, -1.91447523, -1.51230911, -0.51169592,\n",
       "          4.34983556,  2.61786683]),\n",
       "  array([ 0.27110834, -1.86902133, -1.92052313, -1.5177663 , -0.51531244,\n",
       "          4.34730766,  2.6183269 ]),\n",
       "  array([ 0.27495144, -1.8706054 , -1.92654711, -1.52320098, -0.51890032,\n",
       "          4.34478489,  2.61878527]),\n",
       "  array([ 0.27877936, -1.87218505, -1.93254725, -1.52861329, -0.52245976,\n",
       "          4.34226721,  2.61924197]),\n",
       "  array([ 0.28259216, -1.87376027, -1.93852365, -1.53400336, -0.52599098,\n",
       "          4.33975461,  2.61969697]),\n",
       "  array([ 0.28638992, -1.87533107, -1.94447641, -1.53937132, -0.52949418,\n",
       "          4.33724705,  2.62015029]),\n",
       "  array([ 0.2901727 , -1.87689745, -1.95040564, -1.54471732, -0.53296957,\n",
       "          4.33474451,  2.62060192]),\n",
       "  array([ 0.29394056, -1.87845942, -1.95631142, -1.55004149, -0.53641737,\n",
       "          4.33224694,  2.62105186]),\n",
       "  array([ 0.29769358, -1.88001697, -1.96219385, -1.55534395, -0.53983777,\n",
       "          4.32975433,  2.62150012]),\n",
       "  array([ 0.30143181, -1.88157011, -1.96805303, -1.56062484, -0.54323097,\n",
       "          4.32726665,  2.6219467 ]),\n",
       "  array([ 0.30515532, -1.88311884, -1.97388906, -1.5658843 , -0.54659719,\n",
       "          4.32478386,  2.62239159]),\n",
       "  array([ 0.30886418, -1.88466316, -1.97970204, -1.57112244, -0.54993661,\n",
       "          4.32230595,  2.62283481]),\n",
       "  array([ 0.31255845, -1.88620309, -1.98549205, -1.5763394 , -0.55324943,\n",
       "          4.31983287,  2.62327634]),\n",
       "  array([ 0.3162382 , -1.88773862, -1.99125919, -1.58153531, -0.55653586,\n",
       "          4.31736461,  2.62371621]),\n",
       "  array([ 0.31990349, -1.88926975, -1.99700356, -1.58671029, -0.55979609,\n",
       "          4.31490113,  2.62415439]),\n",
       "  array([ 0.32355438, -1.8907965 , -2.00272525, -1.59186447, -0.56303031,\n",
       "          4.31244242,  2.62459091]),\n",
       "  array([ 0.32719094, -1.89231887, -2.00842436, -1.59699797, -0.56623871,\n",
       "          4.30998843,  2.62502575]),\n",
       "  array([ 0.33081323, -1.89383685, -2.01410097, -1.60211092, -0.56942148,\n",
       "          4.30753916,  2.62545893]),\n",
       "  array([ 0.33442131, -1.89535046, -2.01975519, -1.60720343, -0.57257882,\n",
       "          4.30509456,  2.62589044]),\n",
       "  array([ 0.33801525, -1.8968597 , -2.02538711, -1.61227563, -0.57571092,\n",
       "          4.30265461,  2.62632029]),\n",
       "  array([ 0.34159511, -1.89836458, -2.03099681, -1.61732764, -0.57881795,\n",
       "          4.30021929,  2.62674847]),\n",
       "  array([ 0.34516095, -1.8998651 , -2.0365844 , -1.62235957, -0.5819001 ,\n",
       "          4.29778856,  2.62717501]),\n",
       "  array([ 0.34871284, -1.90136126, -2.04214995, -1.62737156, -0.58495756,\n",
       "          4.29536242,  2.62759988]),\n",
       "  array([ 0.35225082, -1.90285308, -2.04769358, -1.6323637 , -0.58799051,\n",
       "          4.29294082,  2.62802311]),\n",
       "  array([ 0.35577498, -1.90434055, -2.05321535, -1.63733613, -0.59099913,\n",
       "          4.29052374,  2.62844469]),\n",
       "  array([ 0.35928536, -1.90582369, -2.05871537, -1.64228895, -0.59398361,\n",
       "          4.28811116,  2.62886462]),\n",
       "  array([ 0.36278203, -1.9073025 , -2.06419373, -1.64722228, -0.5969441 ,\n",
       "          4.28570306,  2.62928291]),\n",
       "  array([ 0.36626505, -1.90877698, -2.06965051, -1.65213624, -0.59988081,\n",
       "          4.2832994 ,  2.62969957]),\n",
       "  array([ 0.36973447, -1.91024714, -2.07508581, -1.65703093, -0.60279389,\n",
       "          4.28090017,  2.63011459]),\n",
       "  array([ 0.37319037, -1.911713  , -2.08049972, -1.66190648, -0.60568353,\n",
       "          4.27850534,  2.63052798]),\n",
       "  array([ 0.37663279, -1.91317454, -2.08589232, -1.66676298, -0.6085499 ,\n",
       "          4.27611488,  2.63093974]),\n",
       "  array([ 0.3800618 , -1.91463179, -2.0912637 , -1.67160055, -0.61139317,\n",
       "          4.27372878,  2.63134988]),\n",
       "  array([ 0.38347746, -1.91608475, -2.09661395, -1.6764193 , -0.6142135 ,\n",
       "          4.271347  ,  2.6317584 ]),\n",
       "  array([ 0.38687983, -1.91753342, -2.10194317, -1.68121933, -0.61701107,\n",
       "          4.26896952,  2.6321653 ]),\n",
       "  array([ 0.39026895, -1.91897782, -2.10725143, -1.68600077, -0.61978605,\n",
       "          4.26659633,  2.63257059]),\n",
       "  array([ 0.3936449 , -1.92041794, -2.11253882, -1.6907637 , -0.6225386 ,\n",
       "          4.2642274 ,  2.63297427]),\n",
       "  array([ 0.39700774, -1.9218538 , -2.11780543, -1.69550824, -0.62526888,\n",
       "          4.26186269,  2.63337635]),\n",
       "  array([ 0.40035751, -1.9232854 , -2.12305136, -1.70023449, -0.62797707,\n",
       "          4.2595022 ,  2.63377683]),\n",
       "  array([ 0.40369427, -1.92471276, -2.12827667, -1.70494256, -0.63066331,\n",
       "          4.2571459 ,  2.63417571]),\n",
       "  array([ 0.40701809, -1.92613587, -2.13348146, -1.70963254, -0.63332779,\n",
       "          4.25479377,  2.634573  ]),\n",
       "  array([ 0.41032903, -1.92755475, -2.13866582, -1.71430455, -0.63597064,\n",
       "          4.25244578,  2.63496871]),\n",
       "  array([ 0.41362713, -1.92896941, -2.14382983, -1.71895868, -0.63859204,\n",
       "          4.25010191,  2.63536283]),\n",
       "  array([ 0.41691245, -1.93037985, -2.14897357, -1.72359504, -0.64119214,\n",
       "          4.24776214,  2.63575538]),\n",
       "  array([ 0.42018505, -1.93178607, -2.15409713, -1.72821372, -0.64377109,\n",
       "          4.24542645,  2.63614635]),\n",
       "  array([ 0.42344499, -1.9331881 , -2.1592006 , -1.73281483, -0.64632906,\n",
       "          4.24309482,  2.63653575]),\n",
       "  array([ 0.42669232, -1.93458593, -2.16428405, -1.73739845, -0.64886619,\n",
       "          4.24076722,  2.63692359]),\n",
       "  array([ 0.4299271 , -1.93597958, -2.16934757, -1.7419647 , -0.65138265,\n",
       "          4.23844364,  2.63730987]),\n",
       "  array([ 0.43314938, -1.93736905, -2.17439125, -1.74651367, -0.65387857,\n",
       "          4.23612405,  2.6376946 ]),\n",
       "  array([ 0.43635922, -1.93875435, -2.17941516, -1.75104544, -0.65635411,\n",
       "          4.23380843,  2.63807777]),\n",
       "  array([ 0.43955668, -1.94013549, -2.18441938, -1.75556013, -0.65880942,\n",
       "          4.23149677,  2.6384594 ]),\n",
       "  array([ 0.4427418 , -1.94151247, -2.18940401, -1.76005782, -0.66124465,\n",
       "          4.22918903,  2.63883949]),\n",
       "  array([ 0.44591464, -1.94288532, -2.19436912, -1.76453861, -0.66365995,\n",
       "          4.2268852 ,  2.63921804]),\n",
       "  array([ 0.44907525, -1.94425403, -2.1993148 , -1.76900259, -0.66605545,\n",
       "          4.22458527,  2.63959506]),\n",
       "  array([ 0.4522237 , -1.94561861, -2.20424111, -1.77344985, -0.66843132,\n",
       "          4.2222892 ,  2.63997055]),\n",
       "  array([ 0.45536003, -1.94697908, -2.20914815, -1.77788049, -0.67078768,\n",
       "          4.21999699,  2.64034453]),\n",
       "  array([ 0.45848429, -1.94833544, -2.214036  , -1.78229459, -0.67312468,\n",
       "          4.2177086 ,  2.64071698]),\n",
       "  array([ 0.46159654, -1.9496877 , -2.21890473, -1.78669226, -0.67544247,\n",
       "          4.21542403,  2.64108793]),\n",
       "  array([ 0.46469684, -1.95103587, -2.22375443, -1.79107356, -0.67774118,\n",
       "          4.21314324,  2.64145737]),\n",
       "  array([ 0.46778522, -1.95237997, -2.22858517, -1.79543861, -0.68002096,\n",
       "          4.21086623,  2.64182531]),\n",
       "  array([ 0.47086176, -1.95371998, -2.23339703, -1.79978748, -0.68228193,\n",
       "          4.20859297,  2.64219175]),\n",
       "  array([ 0.47392649, -1.95505594, -2.2381901 , -1.80412026, -0.68452425,\n",
       "          4.20632345,  2.6425567 ]),\n",
       "  array([ 0.47697947, -1.95638785, -2.24296444, -1.80843704, -0.68674804,\n",
       "          4.20405764,  2.64292017]),\n",
       "  array([ 0.48002076, -1.95771571, -2.24772015, -1.8127379 , -0.68895344,\n",
       "          4.20179553,  2.64328216]),\n",
       "  array([ 0.48305039, -1.95903953, -2.25245728, -1.81702294, -0.69114058,\n",
       "          4.19953709,  2.64364267]),\n",
       "  array([ 0.48606843, -1.96035933, -2.25717594, -1.82129223, -0.6933096 ,\n",
       "          4.19728231,  2.64400171]),\n",
       "  array([ 0.48907493, -1.96167512, -2.26187618, -1.82554586, -0.69546064,\n",
       "          4.19503118,  2.64435928]),\n",
       "  array([ 0.49206993, -1.9629869 , -2.26655808, -1.82978392, -0.69759381,\n",
       "          4.19278367,  2.6447154 ]),\n",
       "  array([ 0.49505349, -1.96429469, -2.27122173, -1.83400648, -0.69970925,\n",
       "          4.19053976,  2.64507006]),\n",
       "  array([ 0.49802565, -1.96559848, -2.2758672 , -1.83821363, -0.70180709,\n",
       "          4.18829944,  2.64542327]),\n",
       "  array([ 0.50098647, -1.9668983 , -2.28049457, -1.84240546, -0.70388746,\n",
       "          4.18606269,  2.64577503]),\n",
       "  array([ 0.50393599, -1.96819416, -2.2851039 , -1.84658204, -0.70595048,\n",
       "          4.18382949,  2.64612536]),\n",
       "  array([ 0.50687427, -1.96948606, -2.28969528, -1.85074345, -0.70799628,\n",
       "          4.18159982,  2.64647426]),\n",
       "  array([ 0.50980136, -1.97077401, -2.29426877, -1.85488978, -0.71002499,\n",
       "          4.17937367,  2.64682172]),\n",
       "  array([ 0.51271729, -1.97205802, -2.29882447, -1.8590211 , -0.71203673,\n",
       "          4.17715103,  2.64716777]),\n",
       "  array([ 0.51562213, -1.97333811, -2.30336243, -1.86313749, -0.71403162,\n",
       "          4.17493186,  2.64751239]),\n",
       "  array([ 0.51851592, -1.97461427, -2.30788273, -1.86723904, -0.71600979,\n",
       "          4.17271617,  2.64785561]),\n",
       "  array([ 0.52139871, -1.97588653, -2.31238545, -1.87132581, -0.71797135,\n",
       "          4.17050392,  2.64819742]),\n",
       "  array([ 0.52427054, -1.9771549 , -2.31687065, -1.87539788, -0.71991644,\n",
       "          4.1682951 ,  2.64853782]),\n",
       "  array([ 0.52713147, -1.97841937, -2.32133842, -1.87945534, -0.72184516,\n",
       "          4.1660897 ,  2.64887683]),\n",
       "  array([ 0.52998154, -1.97967997, -2.32578882, -1.88349826, -0.72375763,\n",
       "          4.1638877 ,  2.64921445]),\n",
       "  array([ 0.53282079, -1.9809367 , -2.33022193, -1.88752671, -0.72565398,\n",
       "          4.16168909,  2.64955068]),\n",
       "  array([ 0.53564929, -1.98218958, -2.33463782, -1.89154077, -0.72753431,\n",
       "          4.15949384,  2.64988553]),\n",
       "  array([ 0.53846707, -1.9834386 , -2.33903656, -1.89554051, -0.72939876,\n",
       "          4.15730195,  2.65021901]),\n",
       "  array([ 0.54127418, -1.98468379, -2.34341822, -1.89952601, -0.73124742,\n",
       "          4.15511339,  2.65055112]),\n",
       "  array([ 0.54407066, -1.98592516, -2.34778287, -1.90349733, -0.73308042,\n",
       "          4.15292815,  2.65088187]),\n",
       "  array([ 0.54685657, -1.9871627 , -2.35213058, -1.90745456, -0.73489787,\n",
       "          4.15074622,  2.65121125]),\n",
       "  array([ 0.54963195, -1.98839645, -2.35646142, -1.91139776, -0.73669988,\n",
       "          4.14856757,  2.65153928]),\n",
       "  array([ 0.55239684, -1.98962639, -2.36077547, -1.91532701, -0.73848656,\n",
       "          4.1463922 ,  2.65186597]),\n",
       "  array([ 0.5551513 , -1.99085255, -2.3650728 , -1.91924238, -0.74025802,\n",
       "          4.14422009,  2.65219131]),\n",
       "  array([ 0.55789536, -1.99207494, -2.36935346, -1.92314393, -0.74201438,\n",
       "          4.14205122,  2.65251531]),\n",
       "  array([ 0.56062907, -1.99329356, -2.37361754, -1.92703174, -0.74375574,\n",
       "          4.13988558,  2.65283799]),\n",
       "  array([ 0.56335247, -1.99450843, -2.3778651 , -1.93090588, -0.74548221,\n",
       "          4.13772316,  2.65315933]),\n",
       "  array([ 0.56606562, -1.99571955, -2.38209621, -1.93476642, -0.7471939 ,\n",
       "          4.13556393,  2.65347936]),\n",
       "  array([ 0.56876855, -1.99692695, -2.38631093, -1.93861342, -0.74889091,\n",
       "          4.13340789,  2.65379807]),\n",
       "  array([ 0.57146132, -1.99813061, -2.39050934, -1.94244695, -0.75057336,\n",
       "          4.13125502,  2.65411547]),\n",
       "  array([ 0.57414395, -1.99933057, -2.39469151, -1.94626708, -0.75224134,\n",
       "          4.1291053 ,  2.65443156]),\n",
       "  array([ 0.57681651, -2.00052682, -2.39885749, -1.95007388, -0.75389496,\n",
       "          4.12695873,  2.65474635]),\n",
       "  array([ 0.57947902, -2.00171938, -2.40300737, -1.95386741, -0.75553432,\n",
       "          4.12481528,  2.65505985]),\n",
       "  array([ 0.58213155, -2.00290827, -2.4071412 , -1.95764775, -0.75715953,\n",
       "          4.12267494,  2.65537206]),\n",
       "  array([ 0.58477412, -2.00409348, -2.41125904, -1.96141495, -0.75877068,\n",
       "          4.12053771,  2.65568299]),\n",
       "  array([ 0.58740678, -2.00527503, -2.41536098, -1.96516908, -0.76036788,\n",
       "          4.11840356,  2.65599264]),\n",
       "  array([ 0.59002957, -2.00645293, -2.41944707, -1.96891021, -0.76195124,\n",
       "          4.11627248,  2.65630101]),\n",
       "  array([ 0.59264255, -2.00762719, -2.42351738, -1.97263839, -0.76352084,\n",
       "          4.11414445,  2.65660812]),\n",
       "  array([ 0.59524574, -2.00879783, -2.42757198, -1.9763537 , -0.76507679,\n",
       "          4.11201948,  2.65691396]),\n",
       "  array([ 0.5978392 , -2.00996484, -2.43161093, -1.9800562 , -0.76661918,\n",
       "          4.10989753,  2.65721855]),\n",
       "  array([ 0.60042296, -2.01112825, -2.43563429, -1.98374594, -0.76814812,\n",
       "          4.1077786 ,  2.65752188]),\n",
       "  array([ 0.60299706, -2.01228807, -2.43964212, -1.987423  , -0.7696637 ,\n",
       "          4.10566268,  2.65782396]),\n",
       "  array([ 0.60556156, -2.01344429, -2.44363451, -1.99108744, -0.77116601,\n",
       "          4.10354975,  2.65812481]),\n",
       "  array([ 0.60811648, -2.01459694, -2.4476115 , -1.99473931, -0.77265516,\n",
       "          4.10143979,  2.65842442]),\n",
       "  array([ 0.61066188, -2.01574603, -2.45157316, -1.99837867, -0.77413123,\n",
       "          4.0993328 ,  2.65872279]),\n",
       "  array([ 0.61319778, -2.01689156, -2.45551956, -2.0020056 , -0.77559432,\n",
       "          4.09722876,  2.65901994]),\n",
       "  array([ 0.61572424, -2.01803355, -2.45945076, -2.00562014, -0.77704452,\n",
       "          4.09512767,  2.65931587]),\n",
       "  array([ 0.6182413 , -2.01917201, -2.46336681, -2.00922236, -0.77848192,\n",
       "          4.0930295 ,  2.65961059]),\n",
       "  array([ 0.62074898, -2.02030694, -2.46726779, -2.01281231, -0.77990662,\n",
       "          4.09093424,  2.65990409]),\n",
       "  array([ 0.62324735, -2.02143836, -2.47115376, -2.01639007, -0.78131871,\n",
       "          4.08884189,  2.66019639]),\n",
       "  array([ 0.62573642, -2.02256628, -2.47502477, -2.01995567, -0.78271827,\n",
       "          4.08675242,  2.66048749]),\n",
       "  array([ 0.62821625, -2.02369071, -2.4788809 , -2.02350919, -0.78410541,\n",
       "          4.08466584,  2.66077739]),\n",
       "  array([ 0.63068688, -2.02481166, -2.4827222 , -2.02705068, -0.78548019,\n",
       "          4.08258212,  2.6610661 ]),\n",
       "  array([ 0.63314834, -2.02592913, -2.48654873, -2.0305802 , -0.78684273,\n",
       "          4.08050125,  2.66135363]),\n",
       "  array([ 0.63560068, -2.02704315, -2.49036055, -2.03409781, -0.78819309,\n",
       "          4.07842322,  2.66163997]),\n",
       "  array([ 0.63804392, -2.02815372, -2.49415773, -2.03760355, -0.78953137,\n",
       "          4.07634803,  2.66192515]),\n",
       "  array([ 0.64047812, -2.02926086, -2.49794032, -2.04109749, -0.79085766,\n",
       "          4.07427565,  2.66220915]),\n",
       "  array([ 0.64290331, -2.03036456, -2.50170839, -2.04457969, -0.79217204,\n",
       "          4.07220608,  2.66249198]),\n",
       "  array([ 0.64531953, -2.03146485, -2.50546199, -2.0480502 , -0.79347459,\n",
       "          4.0701393 ,  2.66277366]),\n",
       "  array([ 0.64772682, -2.03256173, -2.50920119, -2.05150907, -0.79476541,\n",
       "          4.0680753 ,  2.66305419]),\n",
       "  array([ 0.65012521, -2.03365522, -2.51292605, -2.05495636, -0.79604456,\n",
       "          4.06601408,  2.66333356]),\n",
       "  array([ 0.65251475, -2.03474532, -2.51663662, -2.05839212, -0.79731215,\n",
       "          4.06395562,  2.66361179]),\n",
       "  array([ 0.65489547, -2.03583205, -2.52033296, -2.06181641, -0.79856825,\n",
       "          4.0618999 ,  2.66388888]),\n",
       "  array([ 0.65726741, -2.03691541, -2.52401513, -2.06522928, -0.79981293,\n",
       "          4.05984693,  2.66416483]),\n",
       "  array([ 0.65963061, -2.03799542, -2.52768319, -2.06863078, -0.80104629,\n",
       "          4.05779668,  2.66443965]),\n",
       "  array([ 0.66198511, -2.03907209, -2.53133721, -2.07202097, -0.80226841,\n",
       "          4.05574914,  2.66471335]),\n",
       "  array([ 0.66433093, -2.04014542, -2.53497722, -2.0753999 , -0.80347935,\n",
       "          4.05370431,  2.66498593]),\n",
       "  array([ 0.66666813, -2.04121543, -2.53860331, -2.07876762, -0.80467922,\n",
       "          4.05166218,  2.66525739]),\n",
       "  array([ 0.66899673, -2.04228213, -2.54221551, -2.08212418, -0.80586807,\n",
       "          4.04962273,  2.66552775]),\n",
       "  array([ 0.67131678, -2.04334553, -2.54581389, -2.08546964, -0.80704599,\n",
       "          4.04758595,  2.66579699]),\n",
       "  array([ 0.67362831, -2.04440563, -2.54939851, -2.08880404, -0.80821307,\n",
       "          4.04555183,  2.66606514]),\n",
       "  array([ 0.67593135, -2.04546246, -2.55296941, -2.09212744, -0.80936936,\n",
       "          4.04352037,  2.66633219]),\n",
       "  array([ 0.67822595, -2.04651602, -2.55652667, -2.09543988, -0.81051496,\n",
       "          4.04149154,  2.66659815]),\n",
       "  array([ 0.68051213, -2.04756632, -2.56007033, -2.09874142, -0.81164994,\n",
       "          4.03946535,  2.66686302]),\n",
       "  array([ 0.68278994, -2.04861337, -2.56360046, -2.10203211, -0.81277438,\n",
       "          4.03744178,  2.66712681]),\n",
       "  array([ 0.68505941, -2.04965718, -2.5671171 , -2.105312  , -0.81388834,\n",
       "          4.03542081,  2.66738953]),\n",
       "  array([ 0.68732058, -2.05069776, -2.57062031, -2.10858112, -0.8149919 ,\n",
       "          4.03340245,  2.66765117]),\n",
       "  array([ 0.68957347, -2.05173512, -2.57411015, -2.11183955, -0.81608514,\n",
       "          4.03138668,  2.66791175]),\n",
       "  array([ 0.69181814, -2.05276928, -2.57758667, -2.11508731, -0.81716814,\n",
       "          4.02937349,  2.66817126]),\n",
       "  array([ 0.6940546 , -2.05380024, -2.58104993, -2.11832446, -0.81824095,\n",
       "          4.02736286,  2.66842971]),\n",
       "  array([ 0.6962829 , -2.05482801, -2.58449998, -2.12155106, -0.81930366,\n",
       "          4.0253548 ,  2.66868712]),\n",
       "  array([ 0.69850307, -2.0558526 , -2.58793687, -2.12476713, -0.82035634,\n",
       "          4.02334929,  2.66894347]),\n",
       "  array([ 0.70071515, -2.05687403, -2.59136067, -2.12797274, -0.82139905,\n",
       "          4.02134632,  2.66919878]),\n",
       "  array([ 0.70291917, -2.05789231, -2.59477142, -2.13116793, -0.82243188,\n",
       "          4.01934588,  2.66945305]),\n",
       "  array([ 0.70511516, -2.05890743, -2.59816917, -2.13435274, -0.82345488,\n",
       "          4.01734797,  2.66970628]),\n",
       "  array([ 0.70730316, -2.05991943, -2.60155399, -2.13752723, -0.82446813,\n",
       "          4.01535256,  2.66995849]),\n",
       "  array([ 0.70948321, -2.06092829, -2.60492592, -2.14069143, -0.8254717 ,\n",
       "          4.01335966,  2.67020966]),\n",
       "  array([ 0.71165533, -2.06193404, -2.60828502, -2.1438454 , -0.82646566,\n",
       "          4.01136925,  2.67045982])])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(y_train, x_train, w, 500, 1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25.54935547662346\n",
      "-13.859355322734316\n",
      "-7.551189948344418\n",
      "-4.984044521393974\n",
      "-3.8811204165886637\n",
      "-3.2561654133744073\n",
      "-2.8479329011473378\n",
      "-2.5626950186040687\n",
      "-2.3563816087321845\n",
      "-2.2039159407770725\n",
      "-2.0889455946514683\n",
      "-1.9999205813609127\n",
      "-1.928486821535468\n",
      "-1.8687149646681127\n",
      "-1.8165751356667488\n",
      "-1.7694704281148421\n",
      "-1.7258155960015233\n",
      "-1.6846900840436285\n",
      "-1.6455808742675364\n",
      "-1.6082088382920001\n",
      "-1.572420379021376\n",
      "-1.538124344308646\n",
      "-1.5052576621313543\n",
      "-1.4737679450963517\n",
      "-1.4436055071251483\n",
      "-1.4147202757771828\n",
      "-1.387061059841614\n",
      "-1.3605758231321217\n",
      "-1.3352122923713492\n",
      "-1.3109185919151156\n",
      "-1.287643784240082\n",
      "-1.2653382839432759\n",
      "-1.2439541513170365\n",
      "-1.223445285089486\n",
      "-1.2037675361658713\n",
      "-1.1848787619298415\n",
      "-1.1667388370509002\n",
      "-1.1493096331657897\n",
      "-1.1325549767526837\n",
      "-1.1164405920994103\n",
      "-1.1009340344238845\n",
      "-1.0860046168319553\n",
      "-1.0716233337883496\n",
      "-1.057762783039367\n",
      "-1.0443970873890702\n",
      "-1.0315018173393409\n",
      "-1.0190539153177405\n",
      "-1.0070316220063835\n",
      "-0.9954144051287864\n",
      "-0.9841828909348859\n",
      "-0.9733187985363794\n",
      "-0.9628048771776679\n",
      "-0.9526248464765237\n",
      "-0.9427633396293196\n",
      "-0.9332058495454811\n",
      "-0.9239386778526975\n",
      "-0.9149488866968645\n",
      "-0.9062242532476491\n",
      "-0.8977532268110155\n",
      "-0.8895248884434677\n",
      "-0.8815289129584862\n",
      "-0.8737555332133682\n",
      "-0.8661955065639148\n",
      "-0.8588400833749751\n",
      "-0.8516809774764272\n",
      "-0.8447103384565573\n",
      "-0.8379207256878355\n",
      "-0.8313050839835804\n",
      "-0.8248567207878833\n",
      "-0.8185692848052752\n",
      "-0.812436745980888\n",
      "-0.806453376746226\n",
      "-0.8006137344500466\n",
      "-0.7949126448981931\n",
      "-0.7893451869305146\n",
      "-0.7839066779671924\n",
      "-0.7785926604608397\n",
      "-0.7733988891946698\n",
      "-0.7683213193707666\n",
      "-0.7633560954360896\n",
      "-0.7584995405972552\n",
      "-0.7537481469783684\n",
      "-0.7490985663792494\n",
      "-0.7445476015942745\n",
      "-0.7400921982547777\n",
      "-0.7357294371604945\n",
      "-0.7314565270679303\n",
      "-0.727270797905756\n",
      "-0.7231696943894262\n",
      "-0.7191507700091575\n",
      "-0.7152116813672104\n",
      "-0.7113501828421077\n",
      "-0.707564121558985\n",
      "-0.7038514326467189\n",
      "-0.7002101347638331\n",
      "-0.6966383258764297\n",
      "-0.693134179272547\n",
      "-0.6896959397984314\n",
      "-0.6863219203031917\n",
      "-0.6830104982792351\n",
      "-0.6797601126867298\n",
      "-0.6765692609511345\n",
      "-0.6734364961235619\n",
      "-0.6703604241944208\n",
      "-0.6673397015514099\n",
      "-0.664373032573514\n",
      "-0.661459167353195\n",
      "-0.658596899539465\n",
      "-0.6557850642949942\n",
      "-0.6530225363608338\n",
      "-0.6503082282227346\n",
      "-0.6476410883734071\n",
      "-0.6450200996654221\n",
      "-0.6424442777497593\n",
      "-0.6399126695953187\n",
      "-0.6374243520849832\n",
      "-0.6349784306840786\n",
      "-0.6325740381773208\n",
      "-0.6302103334705642\n",
      "-0.6278865004538748\n",
      "-0.6256017469226511\n",
      "-0.6233553035536996\n",
      "-0.621146422933339\n",
      "-0.6189743786347806\n",
      "-0.6168384643421703\n",
      "-0.614737993018834\n",
      "-0.612672296117389\n",
      "-0.6106407228295233\n",
      "-0.6086426393733505\n",
      "-0.606677428316372\n",
      "-0.6047444879321714\n",
      "-0.6028432315890784\n",
      "-0.6009730871691187\n",
      "-0.5991334965156686\n",
      "-0.5973239149083084\n",
      "-0.5955438105634479\n",
      "-0.5937926641593765\n",
      "-0.5920699683844572\n",
      "-0.5903752275072528\n",
      "-0.588707956967433\n",
      "-0.5870676829863759\n",
      "-0.5854539421964283\n",
      "-0.5838662812878508\n",
      "-0.5823042566725133\n",
      "-0.580767434163469\n",
      "-0.579255388669568\n",
      "-0.5777677039043236\n",
      "-0.5763039721082818\n",
      "-0.5748637937841842\n",
      "-0.5734467774442535\n",
      "-0.5720525393689634\n",
      "-0.5706807033766879\n",
      "-0.5693309006036629\n",
      "-0.5680027692937131\n",
      "-0.5666959545972338\n",
      "-0.5654101083789417\n",
      "-0.5641448890339334\n",
      "-0.5628999613116168\n",
      "-0.5616749961471008\n",
      "-0.5604696704996561\n",
      "-0.5592836671978734\n",
      "-0.5581166747911712\n",
      "-0.5569683874073217\n",
      "-0.5558385046156802\n",
      "-0.5547267312958234\n",
      "-0.553632777511313\n",
      "-0.5525563583883224\n",
      "-0.5514971939988728\n",
      "-0.5504550092484426\n",
      "-0.5494295337677257\n",
      "-0.5484205018083249\n",
      "-0.5474276521421818\n",
      "-0.5464507279645513\n",
      "-0.5454894768003438\n",
      "-0.5445436504136625\n",
      "-0.5436130047203797\n",
      "-0.5426972997035953\n",
      "-0.5417962993318415\n",
      "-0.5409097714798909\n",
      "-0.5400374878520486\n",
      "-0.5391792239077984\n",
      "-0.5383347587896992\n",
      "-0.5375038752534163\n",
      "-0.5366863595997902\n",
      "-0.5358820016088461\n",
      "-0.5350905944756523\n",
      "-0.5343119347479444\n",
      "-0.5335458222654322\n",
      "-0.5327920601007163\n",
      "-0.5320504545017372\n",
      "-0.5313208148356956\n",
      "-0.5306029535343748\n",
      "-0.5298966860408062\n",
      "-0.5292018307572215\n",
      "-0.5285182089942374\n",
      "-0.5278456449212202\n",
      "-0.5271839655177853\n",
      "-0.5265330005263831\n",
      "-0.52589258240593\n",
      "-0.5252625462864445\n",
      "-0.5246427299246484\n",
      "-0.5240329736604984\n",
      "-0.523433120374613\n",
      "-0.5228430154465636\n",
      "-0.5222625067139983\n",
      "-0.5216914444325687\n",
      "-0.521129681236635\n",
      "-0.5205770721007212\n",
      "-0.5200334743016971\n",
      "-0.5194987473816634\n",
      "-0.5189727531115182\n",
      "-0.5184553554551856\n",
      "-0.5179464205344836\n",
      "-0.5174458165946144\n",
      "-0.5169534139702622\n",
      "-0.5164690850522752\n",
      "-0.5159927042549229\n",
      "-0.5155241479837082\n",
      "-0.5150632946037234\n",
      "-0.5146100244085341\n",
      "-0.5141642195895801\n",
      "-0.5137257642060787\n",
      "-0.5132945441554199\n",
      "-0.5128704471440428\n",
      "-0.5124533626587808\n",
      "-0.5120431819386664\n",
      "-0.5116397979471853\n",
      "-0.5112431053449716\n",
      "-0.5108530004629329\n",
      "-0.5104693812757983\n",
      "-0.5100921473760818\n",
      "-0.50972119994845\n",
      "-0.50935644174449\n",
      "-0.5089977770578682\n",
      "-0.5086451116998726\n",
      "-0.5082983529753341\n",
      "-0.5079574096589164\n",
      "-0.5076221919717735\n",
      "-0.5072926115585614\n",
      "-0.506968581464806\n",
      "-0.5066500161146152\n",
      "-0.5063368312887334\n",
      "-0.5060289441029303\n",
      "-0.5057262729867209\n",
      "-0.5054287376624104\n",
      "-0.5051362591244597\n",
      "-0.5048487596191652\n",
      "-0.50456616262465\n",
      "-0.5042883928311612\n",
      "-0.5040153761216675\n",
      "-0.5037470395527548\n",
      "-0.503483311335815\n",
      "-0.503224120818521\n",
      "-0.5029693984665886\n",
      "-0.5027190758458169\n",
      "-0.5024730856044053\n",
      "-0.5022313614555437\n",
      "-0.5019938381602698\n",
      "-0.5017604515105915\n",
      "-0.5015311383128717\n",
      "-0.5013058363714672\n",
      "-0.5010844844726255\n",
      "-0.500867022368628\n",
      "-0.5006533907621815\n",
      "-0.5004435312910533\n",
      "-0.5002373865129454\n",
      "-0.5000348998906055\n",
      "-0.49983601577717024\n",
      "-0.49964067940174084\n",
      "-0.4994488368551817\n",
      "-0.49926043507614587\n",
      "-0.4990754218373193\n",
      "-0.49889374573188233\n",
      "-0.498715356160186\n",
      "-0.4985402033166389\n",
      "-0.4983682381768032\n",
      "-0.4981994124846945\n",
      "-0.4980336787402853\n",
      "-0.49787099018720754\n",
      "-0.49771130080065124\n",
      "-0.49755456527545766\n",
      "-0.49740073901440285\n",
      "-0.4972497781166697\n",
      "-0.4971016393665059\n",
      "-0.49695628022206384\n",
      "-0.4968136588044216\n",
      "-0.49667373388678\n",
      "-0.49653646488383757\n",
      "-0.49640181184133364\n",
      "-0.49626973542576513\n",
      "-0.49614019691426825\n",
      "-0.4960131581846658\n",
      "-0.4958885817056771\n",
      "-0.4957664305272874\n",
      "-0.49564666827127474\n",
      "-0.4955292591218924\n",
      "-0.49541416781670383\n",
      "-0.49530135963756794\n",
      "-0.49519080040177327\n",
      "-0.4950824564533174\n",
      "-0.49497629465433024\n",
      "-0.49487228237663855\n",
      "-0.49477038749347063\n",
      "-0.4946705783712978\n",
      "-0.4945728238618097\n",
      "-0.49447709329402467\n",
      "-0.49438335646652926\n",
      "-0.49429158363984715\n",
      "-0.49420174552893503\n",
      "-0.49411381329580323\n",
      "-0.49402775854225894\n",
      "-0.49394355330276973\n",
      "-0.4938611700374478\n",
      "-0.493780581625149\n",
      "-0.4937017613566892\n",
      "-0.4936246829281722\n",
      "-0.49354932043443034\n",
      "-0.4934756483625743\n",
      "-0.4934036415856509\n",
      "-0.49333327535640736\n",
      "-0.49326452530115933\n",
      "-0.49319736741376297\n",
      "-0.4931317780496871\n",
      "-0.49306773392018444\n",
      "-0.4930052120865622\n",
      "-0.49294418995454753\n",
      "-0.4928846452687482\n",
      "-0.4928265561072061\n",
      "-0.4927699008760424\n",
      "-0.4927146583041928\n",
      "-0.4926608074382314\n",
      "-0.49260832763728096\n",
      "-0.49255719856800945\n",
      "-0.49250740019971134\n",
      "-0.4924589127994696\n",
      "-0.4924117169274012\n",
      "-0.4923657934319821\n",
      "-0.49232112344544976\n",
      "-0.49227768837928465\n",
      "-0.4922354699197668\n",
      "-0.4921944500236071\n",
      "-0.4921546109136533\n",
      "-0.4921159350746657\n",
      "-0.49207840524916785\n",
      "-0.4920420044333624\n",
      "-0.4920067158731194\n",
      "-0.49197252306003064\n",
      "-0.4919394097275296\n",
      "-0.4919073598470777\n",
      "-0.4918763576244146\n",
      "-0.4918463874958703\n",
      "-0.4918174341247412\n",
      "-0.4917894823977248\n",
      "-0.4917625174214154\n",
      "-0.4917365245188589\n",
      "-0.49171148922616476\n",
      "-0.49168739728917443\n",
      "-0.49166423466018644\n",
      "-0.49164198749473587\n",
      "-0.4916206421484278\n",
      "-0.4916001851738238\n",
      "-0.49158060331738007\n",
      "-0.49156188351643737\n",
      "-0.49154401289626093\n",
      "-0.4915269787671294\n",
      "-0.49151076862147347\n",
      "-0.49149537013106076\n",
      "-0.49148077114422856\n",
      "-0.49146695968316223\n",
      "-0.4914539239412196\n",
      "-0.4914416522802985\n",
      "-0.4914301332282495\n",
      "-0.4914193554763304\n",
      "-0.4914093078767039\n",
      "-0.4913999794399762\n",
      "-0.4913913593327763\n",
      "-0.4913834368753759\n",
      "-0.49137620153934825\n",
      "-0.49136964294526553\n",
      "-0.491363750860435\n",
      "-0.49135851519667145\n",
      "-0.491353926008107\n",
      "-0.4913499734890373\n",
      "-0.4913466479718022\n",
      "-0.49134393992470216\n",
      "-0.491341839949948\n",
      "-0.4913403387816456\n",
      "-0.4913394272838123\n",
      "-0.4913390964484259\n",
      "-0.4913393373935067\n",
      "-0.49134014136123016\n",
      "-0.4913414997160696\n",
      "-0.49134340394297066\n",
      "-0.49134584564555445\n",
      "-0.4913488165443506\n",
      "-0.4913523084750585\n",
      "-0.49135631338683683\n",
      "-0.49136082334062114\n",
      "-0.4913658305074689\n",
      "-0.4913713271669306\n",
      "-0.49137730570544735\n",
      "-0.49138375861477507\n",
      "-0.4913906784904336\n",
      "-0.4913980580301805\n",
      "-0.49140589003250956\n",
      "-0.4914141673951742\n",
      "-0.4914228831137335\n",
      "-0.49143203028012217\n",
      "-0.4914416020812431\n",
      "-0.49145159179758313\n",
      "-0.49146199280184955\n",
      "-0.49147279855763\n",
      "-0.49148400261807235\n",
      "-0.49149559862458686\n",
      "-0.4915075803055674\n",
      "-0.4915199414751344\n",
      "-0.49153267603189726\n",
      "-0.4915457779577361\n",
      "-0.4915592413166029\n",
      "-0.49157306025334174\n",
      "-0.49158722899252766\n",
      "-0.4916017418373237\n",
      "-0.49161659316835543\n",
      "-0.49163177744260445\n",
      "-0.4916472891923177\n",
      "-0.4916631230239355\n",
      "-0.4916792736170344\n",
      "-0.4916957357232883\n",
      "-0.4917125041654453\n",
      "-0.49172957383631966\n",
      "-0.4917469396978004\n",
      "-0.4917645967798755\n",
      "-0.4917825401796697\n",
      "-0.4918007650604992\n",
      "-0.4918192666509394\n",
      "-0.4918380402439082\n",
      "-0.4918570811957625\n",
      "-0.49187638492540925\n",
      "-0.4918959469134303\n",
      "-0.4919157627012195\n",
      "-0.49193582789013485\n",
      "-0.4919561381406623\n",
      "-0.4919766891715929\n",
      "-0.4919974767592119\n",
      "-0.49201849673650144\n",
      "-0.492039744992354\n",
      "-0.49206121747079884\n",
      "-0.4920829101702399\n",
      "-0.4921048191427047\n",
      "-0.49212694049310524\n",
      "-0.4921492703785101\n",
      "-0.4921718050074273\n",
      "-0.49219454063909795\n",
      "-0.49221747358280055\n",
      "-0.49224060019716576\n",
      "-0.49226391688950155\n",
      "-0.4922874201151285\n",
      "-0.49231110637672487\n",
      "-0.4923349722236816\n",
      "-0.4923590142514665\n",
      "-0.4923832291009988\n",
      "-0.49240761345803225\n",
      "-0.4924321640525475\n",
      "-0.4924568776581538\n",
      "-0.49248175109149916\n",
      "-0.49250678121168967\n",
      "-0.49253196491971685\n",
      "-0.49255729915789437\n",
      "-0.4925827809093014\n",
      "-0.4926084071972362\n",
      "-0.492634175084676\n",
      "-0.49266008167374586\n",
      "-0.49268612410519486\n",
      "-0.49271229955788\n",
      "-0.4927386052482578\n",
      "-0.49276503842988245\n",
      "-0.4927915963929129\n",
      "-0.49281827646362564\n",
      "-0.49284507600393523\n",
      "-0.4928719924109213\n",
      "-0.4928990231163632\n",
      "-0.49292616558628016\n",
      "-0.4929534173204793\n",
      "-0.49298077585210953\n",
      "-0.49300823874722177\n",
      "-0.4930358036043356\n",
      "-0.4930634680540125\n",
      "-0.4930912297584343\n",
      "-0.4931190864109886\n",
      "-0.4931470357358595\n",
      "-0.4931750754876246\n",
      "-0.49320320345085694\n",
      "-0.49323141743973353\n",
      "-0.49325971529764917\n",
      "-0.493288094896835\n",
      "-0.4933165541379834\n",
      "-0.4933450909498778\n",
      "-0.4933737032890275\n",
      "-0.493402389139308\n",
      "-0.493431146511606\n"
     ]
    }
   ],
   "source": [
    "losses(y_train, x_train, w, 500, 1.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2040f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossesplot(y_train, x_train, w, 500, 1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71165533, -2.06193404, -2.60828502, -2.1438454 , -0.82646566,\n",
       "        4.01136925,  2.67045982])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train=np.array(last_iter_parameters(y_train,x_train,w,500,1.9))\n",
    "parameters_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy with 500 iterations and step size 1.9: 0.7971830985915493\n",
      "test set accuracy with 500 iterations and step size 1.9: 0.8192090395480226\n"
     ]
    }
   ],
   "source": [
    "print(\"training set accuracy with 500 iterations and step size 1.9:\", accuracy(x_train,parameters_train,y_train))\n",
    "print(\"test set accuracy with 500 iterations and step size 1.9:\", accuracy(x_test,parameters_train,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got similar accuracies for both test and train set, which means that the model has low variance and good generalisation ability (not over fit), and high accuracy scores shows that the model has low bias and good prediction quality (not under fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98, 14],\n",
       "       [18, 47]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix of test set\n",
    "from sklearn.metrics import confusion_matrix \n",
    "C = confusion_matrix(y_test, predictions(x_test,parameters_train))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192090395480226"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test = (C[0,0]+C[1,1])/y_test.shape\n",
    "accuracy_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.88      0.86       112\n",
      "        1.0       0.77      0.72      0.75        65\n",
      "\n",
      "avg / total       0.82      0.82      0.82       177\n",
      "\n",
      "Accuracy: 0.819209039548\n"
     ]
    }
   ],
   "source": [
    "#Classification report of test set\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions(x_test,parameters_train)))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions(x_test,parameters_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More tests to verify the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take stepsize=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "perm=np.random.permutation(887)\n",
    "x_train2,x_test2= Matrix_Combine[perm][177:][:,0:7],Matrix_Combine[perm][:177][:,0:7]\n",
    "y_train2,y_test2=Matrix_Combine[perm][177:][:,-1],Matrix_Combine[perm][:177][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7966101694915254\n",
      "with 1000 iterations and stepsize= 1.5 we get the following test accuracy: 0.7966101694915254\n",
      "with 1500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7853107344632768\n",
      "with 2000 iterations and stepsize= 1.5 we get the following test accuracy: 0.7853107344632768\n",
      "with 2500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7853107344632768\n",
      "with 3000 iterations and stepsize= 1.5 we get the following test accuracy: 0.7853107344632768\n",
      "with 3500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7853107344632768\n",
      "with 4000 iterations and stepsize= 1.5 we get the following test accuracy: 0.7853107344632768\n",
      "with 4500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7853107344632768\n"
     ]
    }
   ],
   "source": [
    "parameters_accuracies(y_train2,x_train2,1.5,x_test2,y_test2) #choose 1500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.42063955, -2.41154329, -3.43315967, -2.83822331, -0.51895413,\n",
       "        1.5022834 ,  2.70669329])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train2=np.array(last_iter_parameters(y_train2,x_train2,w,1500,1.5))\n",
    "parameters_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy: 0.8070422535211268 and test set accuracy: 0.7853107344632768\n"
     ]
    }
   ],
   "source": [
    "print(\"training set accuracy:\", accuracy(x_train2,parameters_train2,y_train2), \"and\",\n",
    "      \"test set accuracy:\", accuracy(x_test2,parameters_train2,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(400)\n",
    "perm=np.random.permutation(887)\n",
    "x_train3,x_test3= Matrix_Combine[perm][177:][:,0:7],Matrix_Combine[perm][:177][:,0:7]\n",
    "y_train3,y_test3=Matrix_Combine[perm][177:][:,-1],Matrix_Combine[perm][:177][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7401129943502824\n",
      "with 1000 iterations and stepsize= 1.5 we get the following test accuracy: 0.7570621468926554\n",
      "with 1500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7627118644067796\n",
      "with 2000 iterations and stepsize= 1.5 we get the following test accuracy: 0.7627118644067796\n",
      "with 2500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7627118644067796\n",
      "with 3000 iterations and stepsize= 1.5 we get the following test accuracy: 0.7627118644067796\n",
      "with 3500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7627118644067796\n",
      "with 4000 iterations and stepsize= 1.5 we get the following test accuracy: 0.7627118644067796\n",
      "with 4500 iterations and stepsize= 1.5 we get the following test accuracy: 0.7627118644067796\n"
     ]
    }
   ],
   "source": [
    "parameters_accuracies(y_train3,x_train3,1.5,x_test3,y_test3) #choose 1000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96738975, -2.15697429, -3.25371905, -3.03421842, -0.15046341,\n",
       "        3.63793018,  2.7935972 ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train3=np.array(last_iter_parameters(y_train3,x_train3,w,1000,1.5))\n",
    "parameters_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy: 0.8042253521126761 and test set accuracy: 0.7570621468926554\n"
     ]
    }
   ],
   "source": [
    "print(\"training set accuracy:\", accuracy(x_train3,parameters_train3,y_train3), \"and\",\n",
    "      \"test set accuracy:\", accuracy(x_test3,parameters_train3,y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(800)\n",
    "perm=np.random.permutation(887)\n",
    "x_train4,x_test4= Matrix_Combine[perm][177:][:,0:7],Matrix_Combine[perm][:177][:,0:7]\n",
    "y_train4,y_test4=Matrix_Combine[perm][177:][:,-1],Matrix_Combine[perm][:177][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.18714666, -2.17026338, -3.34357363, -3.62066547, -0.75258098,\n",
       "        2.33238094,  2.67417318])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train4=np.array(last_iter_parameters(y_train4,x_train4,w,1500,1.5))\n",
    "parameters_train4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy: 0.7985915492957747 and test set accuracy: 0.8192090395480226\n"
     ]
    }
   ],
   "source": [
    "print(\"training set accuracy:\", accuracy(x_train4,parameters_train4,y_train4), \"and\",\n",
    "      \"test set accuracy:\", accuracy(x_test4,parameters_train4,y_test4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing 90-10 split and 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(800) #90-10 split\n",
    "perm=np.random.permutation(887)\n",
    "x_train5,x_test5= Matrix_Combine[perm][89:][:,0:7],Matrix_Combine[perm][:89][:,0:7]\n",
    "y_train5,y_test5=Matrix_Combine[perm][89:][:,-1],Matrix_Combine[perm][:89][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.2342154 , -2.23080976, -3.39074695, -3.03853795, -0.77948802,\n",
       "        2.30558597,  2.6609661 ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train5=np.array(last_iter_parameters(y_train5,x_train5,w,1500,1.5))\n",
    "parameters_train5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy: 0.7944862155388471 and test set accuracy: 0.8426966292134831\n"
     ]
    }
   ],
   "source": [
    "print(\"training set accuracy:\", accuracy(x_train5,parameters_train5,y_train5), \"and\",\n",
    "      \"test set accuracy:\", accuracy(x_test5,parameters_train5,y_test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(800) #80-20 split\n",
    "perm=np.random.permutation(887)\n",
    "x_train6,x_test6= Matrix_Combine[perm][177:][:,0:7],Matrix_Combine[perm][:177][:,0:7]\n",
    "y_train6,y_test6=Matrix_Combine[perm][177:][:,-1],Matrix_Combine[perm][:177][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.18714666, -2.17026338, -3.34357363, -3.62066547, -0.75258098,\n",
       "        2.33238094,  2.67417318])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train6=np.array(last_iter_parameters(y_train6,x_train6,w,1500,1.5))\n",
    "parameters_train6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy: 0.7985915492957747 and test set accuracy: 0.8192090395480226\n"
     ]
    }
   ],
   "source": [
    "print(\"training set accuracy:\", accuracy(x_train6,parameters_train6,y_train6), \"and\",\n",
    "      \"test set accuracy:\", accuracy(x_test6,parameters_train6,y_test6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got higher test accuracy for 90-10 split than for 80-20 split, using the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 fold cross-validation: Use four folds of size 177 and one fold of size 179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5 fold cross-validation\n",
    "\n",
    "x_fold1= Matrix_Combine[:177][:,0:7]\n",
    "y_fold1= Matrix_Combine[:177][:,-1]\n",
    "\n",
    "x_fold2= Matrix_Combine[177:354][:,0:7]\n",
    "y_fold2= Matrix_Combine[177:354][:,-1]\n",
    "\n",
    "x_fold3= Matrix_Combine[354:531][:,0:7]\n",
    "y_fold3= Matrix_Combine[354:531][:,-1]\n",
    "\n",
    "x_fold4= Matrix_Combine[531:708][:,0:7]\n",
    "y_fold4= Matrix_Combine[531:708][:,-1]\n",
    "\n",
    "x_fold5= Matrix_Combine[708:887][:,0:7]\n",
    "y_fold5= Matrix_Combine[708:887][:,-1]\n",
    "\n",
    "#test on fold 1\n",
    "x_train_1, x_test_1= np.concatenate((x_fold2,x_fold3,x_fold4,x_fold5),axis=0), x_fold1\n",
    "y_train_1, y_test_1= np.concatenate((y_fold2,y_fold3,y_fold4,y_fold5),axis=0), y_fold1\n",
    "#test on fold 2\n",
    "x_train_2, x_test_2= np.concatenate((x_fold1,x_fold3,x_fold4,x_fold5),axis=0), x_fold2\n",
    "y_train_2, y_test_2= np.concatenate((y_fold1,y_fold3,y_fold4,y_fold5),axis=0), y_fold2\n",
    "#test on fold 3\n",
    "x_train_3, x_test_3= np.concatenate((x_fold1,x_fold2,x_fold4,x_fold5),axis=0), x_fold3\n",
    "y_train_3, y_test_3= np.concatenate((y_fold1,y_fold2,y_fold4,y_fold5),axis=0), y_fold3\n",
    "#test on fold 4\n",
    "x_train_4, x_test_4= np.concatenate((x_fold1,x_fold2,x_fold3,x_fold5),axis=0), x_fold4\n",
    "y_train_4, y_test_4= np.concatenate((y_fold1,y_fold2,y_fold3,y_fold5),axis=0), y_fold4\n",
    "#test on fold 5\n",
    "x_train_5, x_test_5= np.concatenate((x_fold1,x_fold2,x_fold3,x_fold4),axis=0), x_fold5\n",
    "y_train_5, y_test_5= np.concatenate((y_fold1,y_fold2,y_fold3,y_fold4),axis=0), y_fold5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take stepsize, tau=1.9, max_iters=500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68249687, -2.07204552, -2.4028372 , -1.74407173, -0.99131621,\n",
       "        3.95456535,  2.59695742])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train_1=np.array(last_iter_parameters(y_train_1,x_train_1,w,500,1.9))\n",
    "parameters_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72151618, -2.11547432, -2.59947384, -2.69003883, -0.92275925,\n",
       "        3.28856083,  2.74981976])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train_2=np.array(last_iter_parameters(y_train_2,x_train_2,w,500,1.9))\n",
    "parameters_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61905725, -1.82014976, -2.81299093, -2.49559891, -0.85949393,\n",
       "        4.28101527,  2.67915876])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train_3=np.array(last_iter_parameters(y_train_3,x_train_3,w,500,1.9))\n",
    "parameters_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26024818, -1.595985  , -2.46021285, -2.79848064,  0.21709507,\n",
       "        3.37585938,  2.7464353 ])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train_4=np.array(last_iter_parameters(y_train_4,x_train_4,w,500,1.9))\n",
    "parameters_train_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3947827 , -1.79334178, -2.06155767, -1.87525686, -1.23206349,\n",
       "        3.13395301,  2.67255468])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_train_5=np.array(last_iter_parameters(y_train_5,x_train_5,w,500,1.9))\n",
    "parameters_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of fold 1: 0.8022598870056498\n",
      "test accuracy of fold 2: 0.7966101694915254\n",
      "test accuracy of fold 3: 0.7740112994350282\n",
      "test accuracy of fold 4: 0.751412429378531\n",
      "test accuracy of fold 5: 0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy of fold 1:\", accuracy(x_test_1,parameters_train_1,y_test_1))\n",
    "print(\"test accuracy of fold 2:\", accuracy(x_test_2,parameters_train_2,y_test_2))\n",
    "print(\"test accuracy of fold 3:\", accuracy(x_test_3,parameters_train_3,y_test_3))\n",
    "print(\"test accuracy of fold 4:\", accuracy(x_test_4,parameters_train_4,y_test_4))\n",
    "print(\"test accuracy of fold 5:\", accuracy(x_test_5,parameters_train_5,y_test_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the final parameters from cross validation, as the average of all the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53562024, -1.87939928, -2.4674145 , -2.32068939, -0.75770756,\n",
       "        3.60679077,  2.68898518])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_parameters=(parameters_train_1+ parameters_train_2+ parameters_train_3+ parameters_train_4+ parameters_train_5)/5\n",
    "Final_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of final parameters on fold 1: 0.8022598870056498\n",
      "test accuracy of final parameters on fold 2: 0.8022598870056498\n",
      "test accuracy of final parameters on fold 3: 0.7740112994350282\n",
      "test accuracy of final parameters on fold 4: 0.7853107344632768\n",
      "test accuracy of final parameters on fold 5: 0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy of final parameters on fold 1:\", accuracy(x_test_1,Final_parameters,y_test_1))\n",
    "print(\"test accuracy of final parameters on fold 2:\", accuracy(x_test_2,Final_parameters,y_test_2))\n",
    "print(\"test accuracy of final parameters on fold 3:\", accuracy(x_test_3,Final_parameters,y_test_3))\n",
    "print(\"test accuracy of final parameters on fold 4:\", accuracy(x_test_4,Final_parameters,y_test_4))\n",
    "print(\"test accuracy of final parameters on fold 5:\", accuracy(x_test_5,Final_parameters,y_test_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy of final parameters on fold 1: 0.7985915492957747\n",
      "training accuracy of final parameters on fold 2: 0.7985915492957747\n",
      "training accuracy of final parameters on fold 3: 0.8056338028169014\n",
      "training accuracy of final parameters on fold 4: 0.8028169014084507\n",
      "training accuracy of final parameters on fold 5: 0.7909604519774012\n"
     ]
    }
   ],
   "source": [
    "print(\"training accuracy of final parameters on fold 1:\", accuracy(x_train_1,Final_parameters,y_train_1))\n",
    "print(\"training accuracy of final parameters on fold 2:\", accuracy(x_train_2,Final_parameters,y_train_2))\n",
    "print(\"training accuracy of final parameters on fold 3:\", accuracy(x_train_3,Final_parameters,y_train_3))\n",
    "print(\"training accuracy of final parameters on fold 4:\", accuracy(x_train_4,Final_parameters,y_train_4))\n",
    "print(\"training accuracy of final parameters on fold 5:\", accuracy(x_train_5,Final_parameters,y_train_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7992614335763658"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_parameters_averageaccuracy= (0.807909604519774+0.8022598870056498+0.7740112994350282+0.7853107344632768+0.8268156424581006)/5\n",
    "Final_parameters_averageaccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on x_test and y_test, randomly permuted 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of final parameters: 0.8135593220338984\n",
      "training accuracy of final parameters: 0.795774647887324\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy of final parameters:\", accuracy(x_test,Final_parameters,y_test))\n",
    "print(\"training accuracy of final parameters:\", accuracy(x_train, Final_parameters,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 13],\n",
       "       [20, 45]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "confusion_matrix(y_test, predictions(x_test,Final_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.88      0.86       112\n",
      "        1.0       0.78      0.69      0.73        65\n",
      "\n",
      "avg / total       0.81      0.81      0.81       177\n",
      "\n",
      "Accuracy: 0.813559322034\n"
     ]
    }
   ],
   "source": [
    "#Classification report of test set\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions(x_test,Final_parameters)))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions(x_test,Final_parameters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a good generalisation ability, as the training accuracy is similar to the test accuracy, and a good prediction quality, as the test accuracy is high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost_r(y,m,w,gamma): #scalar\n",
    "    h=sigmoid(m,w)\n",
    "    arg= (y*np.log(h)+(1-y)*np.log(1-h)) \n",
    "    p= gamma/2*(w.T.dot(w))\n",
    "    return (-(arg.T.dot(arg)) -  p)/len(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_r(y,m,w,gamma): #vector\n",
    "    err = sigmoid(m,w)-y\n",
    "    grad = (m.T.dot(err))/len(y) + (gamma*w)/len(y)\n",
    "    return grad, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_r(y, m, initial_w, max_iters, tau, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient_r(y, m, w,gamma)\n",
    "        loss = compute_cost_r(y,m,w,gamma)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}, w2={w2}, w3={w3}, w4={w4}, w5={w5}, w6={w6}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss,  w0=w[0], w1=w[1], w2=w[2], w3=w[3], w4=w[4], w5=w[5], w6=w[6]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_iter_parameters_r(y, m, initial_w, max_iters, tau, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = np.array([])\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient_r(y, m, w,gamma)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "    return [w[0],w[1], w[2], w[3], w[4], w[5], w[6]] #gives a list of parameters for the last iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def losses_r(y, m, initial_w, max_iters, tau, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient_r(y, m, w,gamma)\n",
    "        loss = compute_cost_r(y,m,w,gamma)\n",
    "        # gradient w by descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        losses.append(loss)\n",
    "        print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lossesplot_r(y, m, initial_w, max_iters, tau, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient_r(y, m, w, gamma)\n",
    "        loss = compute_cost_r(y, m, w, gamma)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        losses.append(loss)\n",
    "    cost = list(losses)\n",
    "    n_iterations = [x for x in range(1,max_iters+1)]\n",
    "    plt.plot(n_iterations, cost)\n",
    "    plt.xlabel('No. of iterations')\n",
    "    plt.ylabel('Cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameters_accuracies_r(y,x,tau,xt,yt,gamma):\n",
    "    for i in range (500,5000,500):\n",
    "        a= last_iter_parameters_r(y,x,w,i,tau,gamma)\n",
    "        b=accuracy(xt,a,yt)\n",
    "        print(\"with\", i,\"iterations and stepsize=\", tau, \"we get the following test accuracy:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding the gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for gamma= 1 : accuracy= 0.8248587570621468\n",
      "for gamma= 2 : accuracy= 0.8248587570621468\n",
      "for gamma= 3 : accuracy= 0.8248587570621468\n",
      "for gamma= 4 : accuracy= 0.8248587570621468\n",
      "for gamma= 5 : accuracy= 0.8135593220338984\n",
      "for gamma= 6 : accuracy= 0.8135593220338984\n",
      "for gamma= 7 : accuracy= 0.807909604519774\n",
      "for gamma= 8 : accuracy= 0.807909604519774\n",
      "for gamma= 9 : accuracy= 0.807909604519774\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    t=last_iter_parameters_r(y_train, x_train, w, 500, 1.9, i)\n",
    "    print (\"for gamma=\",i,\":\",\"accuracy=\",accuracy(x_test,t,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.71165532696435918,\n",
       " -2.0619340446478729,\n",
       " -2.6082850169977938,\n",
       " -2.143845401185597,\n",
       " -0.82646566010860212,\n",
       " 4.0113692532653253,\n",
       " 2.6704598213126456]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr= last_iter_parameters(y_train, x_train, w, 500, 1.9)\n",
    "wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15950670652630392,\n",
       " -1.7060305215019655,\n",
       " -1.0128043995213531,\n",
       " -0.58341227966934439,\n",
       " -0.16891995502936419,\n",
       " 0.42372665077876548,\n",
       " 2.1995515841993321]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r= last_iter_parameters_r(y_train, x_train, w, 500, 1.9, 4)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression regularisation has shrunk the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of test set without regularisation: 0.8192090395480226\n",
      "accuracy of test set using ridge regression: 0.8248587570621468\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy of test set without regularisation:\", accuracy(x_test,last_iter_parameters(y_train, x_train, w, 500, 1.9),y_test))\n",
    "print(\"accuracy of test set using ridge regression:\", accuracy(x_test,last_iter_parameters_r(y_train, x_train, w, 500, 1.9, 4),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got higher accuracy with ridge regression regularisation, using the same number of iterations and stepsize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the cost converges with the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a20c91da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossesplot_r(y_train, x_train, w, 500, 1.9, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying cross validation on ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take maximum iterations=500, stepsize=1.9, gamma=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06298842, -1.5992358 , -0.9856386 , -0.63295391, -0.18479148,\n",
       "        0.34226685,  2.22306279])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_parameters_train_1=np.array(last_iter_parameters_r(y_train_1,x_train_1,w,500,1.9,4))\n",
    "r_parameters_train_2=np.array(last_iter_parameters_r(y_train_2,x_train_2,w,500,1.9,4))\n",
    "r_parameters_train_3=np.array(last_iter_parameters_r(y_train_3,x_train_3,w,500,1.9,4))\n",
    "r_parameters_train_4=np.array(last_iter_parameters_r(y_train_4,x_train_4,w,500,1.9,4))\n",
    "r_parameters_train_5=np.array(last_iter_parameters_r(y_train_5,x_train_5,w,500,1.9,4))\n",
    "\n",
    "r_final_parameters_train= (r_parameters_train_1+r_parameters_train_2+r_parameters_train_3+r_parameters_train_4+r_parameters_train_5)/5\n",
    "r_final_parameters_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracies of r_final_parameters_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of final parameters on fold 1: 0.8192090395480226\n",
      "test accuracy of final parameters on fold 2: 0.807909604519774\n",
      "test accuracy of final parameters on fold 3: 0.7853107344632768\n",
      "test accuracy of final parameters on fold 4: 0.751412429378531\n",
      "test accuracy of final parameters on fold 5: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy of final parameters on fold 1:\", accuracy(x_test_1,r_final_parameters_train,y_test_1))\n",
    "print(\"test accuracy of final parameters on fold 2:\", accuracy(x_test_2,r_final_parameters_train,y_test_2))\n",
    "print(\"test accuracy of final parameters on fold 3:\", accuracy(x_test_3,r_final_parameters_train,y_test_3))\n",
    "print(\"test accuracy of final parameters on fold 4:\", accuracy(x_test_4,r_final_parameters_train,y_test_4))\n",
    "print(\"test accuracy of final parameters on fold 5:\", accuracy(x_test_5,r_final_parameters_train,y_test_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracies of r_final_parameters_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy of final parameters on fold 1: 0.7901408450704225\n",
      "training accuracy of final parameters on fold 2: 0.7929577464788733\n",
      "training accuracy of final parameters on fold 3: 0.7985915492957747\n",
      "training accuracy of final parameters on fold 4: 0.8070422535211268\n",
      "training accuracy of final parameters on fold 5: 0.7909604519774012\n"
     ]
    }
   ],
   "source": [
    "print(\"training accuracy of final parameters on fold 1:\", accuracy(x_train_1,r_final_parameters_train,y_train_1))\n",
    "print(\"training accuracy of final parameters on fold 2:\", accuracy(x_train_2,r_final_parameters_train,y_train_2))\n",
    "print(\"training accuracy of final parameters on fold 3:\", accuracy(x_train_3,r_final_parameters_train,y_train_3))\n",
    "print(\"training accuracy of final parameters on fold 4:\", accuracy(x_train_4,r_final_parameters_train,y_train_4))\n",
    "print(\"training accuracy of final parameters on fold 5:\", accuracy(x_train_5,r_final_parameters_train,y_train_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing parameters with and without regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without regularisation: [ 0.68249687 -2.07204552 -2.4028372  -1.74407173 -0.99131621  3.95456535\n",
      "  2.59695742]\n",
      "with regulaisation: [ 0.18395711 -1.75056431 -0.9138937  -0.45661725 -0.21305888  0.45659528\n",
      "  2.15698159]\n",
      "without regularisation: [ 0.72151618 -2.11547432 -2.59947384 -2.69003883 -0.92275925  3.28856083\n",
      "  2.74981976]\n",
      "with regulaisation: [ 0.12251896 -1.7148897  -1.00744585 -0.75101724 -0.23375923  0.28834296\n",
      "  2.21559165]\n",
      "without regularisation: [ 0.61905725 -1.82014976 -2.81299093 -2.49559891 -0.85949393  4.28101527\n",
      "  2.67915876]\n",
      "with regulaisation: [ 0.07744427 -1.55455188 -1.09699325 -0.67437463 -0.23707917  0.48312178\n",
      "  2.21719792]\n",
      "without regularisation: [ 0.26024818 -1.595985   -2.46021285 -2.79848064  0.21709507  3.37585938\n",
      "  2.7464353 ]\n",
      "with regulaisation: [-0.10385909 -1.41844246 -1.02660095 -0.7396667   0.07941254  0.26581126\n",
      "  2.30425419]\n",
      "without regularisation: [ 0.3947827  -1.79334178 -2.06155767 -1.87525686 -1.23206349  3.13395301\n",
      "  2.67255468]\n",
      "with regulaisation: [ 0.03488083 -1.55773067 -0.88325927 -0.54309374 -0.31947268  0.21746299\n",
      "  2.2212886 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"without regularisation:\", parameters_train_1)\n",
    "print(\"with regulaisation:\",r_parameters_train_1)\n",
    "print(\"without regularisation:\",parameters_train_2)\n",
    "print(\"with regulaisation:\",r_parameters_train_2)\n",
    "print(\"without regularisation:\",parameters_train_3)\n",
    "print(\"with regulaisation:\",r_parameters_train_3)\n",
    "print(\"without regularisation:\",parameters_train_4)\n",
    "print(\"with regulaisation:\",r_parameters_train_4)\n",
    "print(\"without regularisation:\",parameters_train_5)\n",
    "print(\"with regulaisation:\",r_parameters_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final parameters without regulaisation: [ 0.53562024 -1.87939928 -2.4674145  -2.32068939 -0.75770756  3.60679077\n",
      "  2.68898518]\n",
      "final parameters with regulaisation: [ 0.06298842 -1.5992358  -0.9856386  -0.63295391 -0.18479148  0.34226685\n",
      "  2.22306279]\n"
     ]
    }
   ],
   "source": [
    "print(\"final parameters without regulaisation:\",Final_parameters)\n",
    "print(\"final parameters with regulaisation:\",r_final_parameters_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation on permuted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5 fold cross-validation on permuted dataset\n",
    "\n",
    "np.random.seed(10) \n",
    "perm=np.random.permutation(887)\n",
    "\n",
    "px_fold1= Matrix_Combine[perm][:177][:,0:7]\n",
    "py_fold1= Matrix_Combine[perm][:177][:,-1]\n",
    "\n",
    "px_fold2= Matrix_Combine[perm][177:354][:,0:7]\n",
    "py_fold2= Matrix_Combine[perm][177:354][:,-1]\n",
    "\n",
    "px_fold3= Matrix_Combine[perm][354:531][:,0:7]\n",
    "py_fold3= Matrix_Combine[perm][354:531][:,-1]\n",
    "\n",
    "px_fold4= Matrix_Combine[perm][531:708][:,0:7]\n",
    "py_fold4= Matrix_Combine[perm][531:708][:,-1]\n",
    "\n",
    "px_fold5= Matrix_Combine[perm][708:887][:,0:7]\n",
    "py_fold5= Matrix_Combine[perm][708:887][:,-1]\n",
    "\n",
    "#test on fold 1\n",
    "px_train_1, px_test_1= np.concatenate((px_fold2,px_fold3,px_fold4,px_fold5),axis=0), px_fold1\n",
    "py_train_1, py_test_1= np.concatenate((py_fold2,py_fold3,py_fold4,py_fold5),axis=0), py_fold1\n",
    "#test on fold 2\n",
    "px_train_2, px_test_2= np.concatenate((px_fold1,px_fold3,px_fold4,px_fold5),axis=0), px_fold2\n",
    "py_train_2, py_test_2= np.concatenate((py_fold1,py_fold3,py_fold4,py_fold5),axis=0), py_fold2\n",
    "#test on fold 3\n",
    "px_train_3, px_test_3= np.concatenate((px_fold1,px_fold2,px_fold4,px_fold5),axis=0), px_fold3\n",
    "py_train_3, py_test_3= np.concatenate((py_fold1,py_fold2,py_fold4,py_fold5),axis=0), py_fold3\n",
    "#test on fold 4\n",
    "px_train_4, px_test_4= np.concatenate((px_fold1,px_fold2,px_fold3,px_fold5),axis=0), px_fold4\n",
    "py_train_4, py_test_4= np.concatenate((py_fold1,py_fold2,py_fold3,py_fold5),axis=0), py_fold4\n",
    "#test on fold 5\n",
    "px_train_5, px_test_5= np.concatenate((px_fold1,px_fold2,px_fold3,px_fold4),axis=0), px_fold5\n",
    "py_train_5, py_test_5= np.concatenate((py_fold1,py_fold2,py_fold3,py_fold4),axis=0), py_fold5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06515621, -1.60184463, -0.9827436 , -0.62455225, -0.19086593,\n",
       "        0.34345629,  2.22434256])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_parameters_train_1=np.array(last_iter_parameters_r(py_train_1,px_train_1,w,500,1.9,4))\n",
    "pr_parameters_train_2=np.array(last_iter_parameters_r(py_train_2,px_train_2,w,500,1.9,4))\n",
    "pr_parameters_train_3=np.array(last_iter_parameters_r(py_train_3,px_train_3,w,500,1.9,4))\n",
    "pr_parameters_train_4=np.array(last_iter_parameters_r(py_train_4,px_train_4,w,500,1.9,4))\n",
    "pr_parameters_train_5=np.array(last_iter_parameters_r(py_train_5,px_train_5,w,500,1.9,4))\n",
    "\n",
    "pr_final_parameters_train= (pr_parameters_train_1+pr_parameters_train_2+pr_parameters_train_3+pr_parameters_train_4+pr_parameters_train_5)/5\n",
    "pr_final_parameters_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracies of pr_final_parameters_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of final parameters on fold 1: 0.8192090395480226\n",
      "test accuracy of final parameters on fold 2: 0.8135593220338984\n",
      "test accuracy of final parameters on fold 3: 0.7796610169491526\n",
      "test accuracy of final parameters on fold 4: 0.768361581920904\n",
      "test accuracy of final parameters on fold 5: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy of final parameters on fold 1:\", accuracy(px_test_1,pr_final_parameters_train,py_test_1))\n",
    "print(\"test accuracy of final parameters on fold 2:\", accuracy(px_test_2,pr_final_parameters_train,py_test_2))\n",
    "print(\"test accuracy of final parameters on fold 3:\", accuracy(px_test_3,pr_final_parameters_train,py_test_3))\n",
    "print(\"test accuracy of final parameters on fold 4:\", accuracy(px_test_4,pr_final_parameters_train,py_test_4))\n",
    "print(\"test accuracy of final parameters on fold 5:\", accuracy(px_test_5,pr_final_parameters_train,py_test_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracies of r_final_parameters_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy of final parameters on fold 1: 0.7901408450704225\n",
      "training accuracy of final parameters on fold 2: 0.7915492957746478\n",
      "training accuracy of final parameters on fold 3: 0.8\n",
      "training accuracy of final parameters on fold 4: 0.8028169014084507\n",
      "training accuracy of final parameters on fold 5: 0.7951977401129944\n"
     ]
    }
   ],
   "source": [
    "print(\"training accuracy of final parameters on fold 1:\", accuracy(px_train_1,pr_final_parameters_train,py_train_1))\n",
    "print(\"training accuracy of final parameters on fold 2:\", accuracy(px_train_2,pr_final_parameters_train,py_train_2))\n",
    "print(\"training accuracy of final parameters on fold 3:\", accuracy(px_train_3,pr_final_parameters_train,py_train_3))\n",
    "print(\"training accuracy of final parameters on fold 4:\", accuracy(px_train_4,pr_final_parameters_train,py_train_4))\n",
    "print(\"training accuracy of final parameters on fold 5:\", accuracy(px_train_5,pr_final_parameters_train,py_train_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on x_test and y_test, defined earlier, in out of sample validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192090395480226"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_test,pr_final_parameters_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100,  12],\n",
       "       [ 20,  45]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "confusion_matrix(y_test, predictions(x_test,pr_final_parameters_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.89      0.86       112\n",
      "        1.0       0.79      0.69      0.74        65\n",
      "\n",
      "avg / total       0.82      0.82      0.82       177\n",
      "\n",
      "Accuracy: 0.819209039548\n"
     ]
    }
   ],
   "source": [
    "#Classification report of test set\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions(x_test,pr_final_parameters_train)))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions(x_test,pr_final_parameters_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced model- just including age and fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_iter_parameters2(y, m, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = np.array([])\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        # gradient descent update\n",
    "        w = w - gamma * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "    return [w[0],w[1],w[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.27117366,  0.01415106],\n",
       "       [ 1.        ,  0.4722292 ,  0.13913574],\n",
       "       [ 1.        ,  0.32143755,  0.01546857],\n",
       "       ..., \n",
       "       [ 1.        ,  0.08268409,  0.04577135],\n",
       "       [ 1.        ,  0.32143755,  0.0585561 ],\n",
       "       [ 1.        ,  0.39683338,  0.01512699]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#age, fare reduced model\n",
    "rm=Matrix[:,[0,2,5]]\n",
    "rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#out of sample validation on reduced sample\n",
    "x_tr,x_te=rm[177:],rm[:177]\n",
    "y_tr,y_te=Output[177:],Output[:177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.4798951256098678, -1.0333451241214351, 7.2337381072714289]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm=last_iter_parameters2(y_tr, x_tr, np.array([1,2,3]), 500, 1.9)\n",
    "prm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6440677966101694"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_te,prm,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced model- just including pclass and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_iter_parameters2(y, m, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = np.array([])\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        # gradient descent update\n",
    "        w = w - gamma * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "    return [w[0],w[1],w[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pclass and gender reduced model\n",
    "rm2=Matrix[:,[0,1,6]]\n",
    "rm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#out of sample validation on reduced sample\n",
    "x_tr2,x_te2=rm2[177:],rm2[:177]\n",
    "y_tr2,y_te2=Output[177:],Output[:177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.10195279396348159, -2.1312159982494516, 2.5719217888881869]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm2=last_iter_parameters2(y_tr2, x_tr2, np.array([1,2,3]), 500, 1.9)\n",
    "prm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135593220338984"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_te2,prm2,y_te2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced model- just including, pclass, fare and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_iter_parameters3(y, m, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = np.array([])\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        # gradient descent update\n",
    "        w = w - gamma * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "    return [w[0],w[1],w[2],w[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  0.01415106,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.13913574,  1.        ],\n",
       "       [ 1.        ,  1.        ,  0.01546857,  1.        ],\n",
       "       ..., \n",
       "       [ 1.        ,  1.        ,  0.04577135,  1.        ],\n",
       "       [ 1.        ,  0.        ,  0.0585561 ,  0.        ],\n",
       "       [ 1.        ,  1.        ,  0.01512699,  0.        ]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pclass, fare and gender reduced model\n",
    "rm3=Matrix[:,[0,1,5,6]]\n",
    "rm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#out of sample validation on reduced sample\n",
    "x_tr3,x_te3=rm3[177:],rm3[:177]\n",
    "y_tr3,y_te3=Output[177:],Output[:177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.36561340958303801,\n",
       " -1.8866118048076956,\n",
       " 2.1331621415259483,\n",
       " 2.5319970206435349]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm3=last_iter_parameters3(y_tr3, x_tr3, np.array([1,2,3,4]), 500, 1.9)\n",
    "prm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8022598870056498"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_te3,prm3,y_te3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192090395480226"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy of full model\n",
    "accuracy(x_test,wr,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248587570621468"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy of full model with ridge regression\n",
    "accuracy(x_test,r,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial weights\n",
    "w=np.array([1,2,3,4,5,6,7])\n",
    "\n",
    "def sigmoid(m,w): \n",
    "    return 1.0/(1 + np.exp(-np.dot(m,w))) \n",
    "\n",
    "def compute_cost(y,m,w): \n",
    "    h=sigmoid(m,w)\n",
    "    arg= (y*np.log(h)+(1-y)*np.log(1-h)) \n",
    "    return -(arg.T.dot(arg))/len(y) \n",
    "\n",
    "def compute_gradient(y,m,w): \n",
    "    err = sigmoid(m,w)-y\n",
    "    grad = (m.T.dot(err))/len(y) \n",
    "    return grad, err\n",
    "\n",
    "def gradient_descent(y, m, initial_w, max_iters, tau):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        loss = compute_cost(y,m,w)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}, w2={w2}, w3={w3}, w4={w4}, w5={w5}, w6={w6}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss,  w0=w[0], w1=w[1], w2=w[2], w3=w[3], w4=w[4], w5=w[5], w6=w[6])) \n",
    "    return losses, ws\n",
    "\n",
    "def last_iter_parameters(y, m, initial_w, max_iters, tau):\n",
    "    ws = [initial_w]\n",
    "    losses = np.array([])\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        # gradient w by descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "    return [w[0],w[1], w[2], w[3], w[4], w[5], w[6]] #gives a list of parameters for the last iterate\n",
    "\n",
    "def losses(y, m, initial_w, max_iters, tau):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        loss = compute_cost(y,m,w)\n",
    "        # gradient w by descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        losses.append(loss)\n",
    "        print (loss)\n",
    "        \n",
    "def lossesplot(y, m, initial_w, max_iters, tau):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient(y, m, w)\n",
    "        loss = compute_cost(y,m,w)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        losses.append(loss)\n",
    "    cost = list(losses)\n",
    "    n_iterations = [x for x in range(1,max_iters+1)]\n",
    "    plt.plot(n_iterations, cost)\n",
    "    plt.xlabel('No. of iterations')\n",
    "    plt.ylabel('Cost')\n",
    "        \n",
    "def predictions(X,w):\n",
    "    preds=[]\n",
    "    for i in sigmoid(X, w):\n",
    "        if i> 0.5:\n",
    "            preds.append(1)\n",
    "        if i < 0.5:\n",
    "            preds.append(0)\n",
    "    return np.array(preds)\n",
    "\n",
    "def accuracy(X,w,y):\n",
    "    return len(np.array((np.where(predictions(X,w)==y))).T)/len(y)\n",
    "\n",
    "def parameters_accuracies(y,x,tau,xt,yt):\n",
    "    for i in range (500,5000,500):\n",
    "        a= last_iter_parameters(y,x,w,i,gamma)\n",
    "        b=accuracy(xt,a,yt)\n",
    "        print(\"with\", i,\"iterations and stepsize=\", tau, \"we get the following test accuracy:\", b)\n",
    "        \n",
    "#Ridge logistric regression   \n",
    "\n",
    "def compute_cost_r(y,m,w,gamma): \n",
    "    h=sigmoid(m,w)\n",
    "    arg= (y*np.log(h)+(1-y)*np.log(1-h)) \n",
    "    p= gamma/2*(w.T.dot(w))\n",
    "    return (-(arg.T.dot(arg)) -  p)/len(y) \n",
    "\n",
    "def compute_gradient_r(y,m,w,gamma):\n",
    "    err = sigmoid(m,w)-y\n",
    "    grad = (m.T.dot(err))/len(y) + (gamma*w)/len(y)\n",
    "    return grad, err\n",
    "\n",
    "def gradient_descent_r(y, m, initial_w, max_iters, tau, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient_r(y, m, w,gamma)\n",
    "        loss = compute_cost_r(y,m,w,gamma)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}, w2={w2}, w3={w3}, w4={w4}, w5={w5}, w6={w6}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss,  w0=w[0], w1=w[1], w2=w[2], w3=w[3], w4=w[4], w5=w[5], w6=w[6]))    \n",
    "    return losses, ws\n",
    "\n",
    "def last_iter_parameters_r(y, m, initial_w, max_iters, tau, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = np.array([])\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient_r(y, m, w,gamma)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "    return [w[0],w[1], w[2], w[3], w[4], w[5], w[6]] #gives a list of parameters for the last iterate\n",
    "\n",
    "def losses_r(y, m, initial_w, max_iters, tau, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient_r(y, m, w,gamma)\n",
    "        loss = compute_cost_r(y,m,w,gamma)\n",
    "        # gradient w by descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        losses.append(loss)\n",
    "        print (loss)\n",
    "\n",
    "def lossesplot_r(y, m, initial_w, max_iters, tau, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute loss, gradient\n",
    "        grad, err = compute_gradient_r(y, m, w, gamma)\n",
    "        loss = compute_cost_r(y, m, w, gamma)\n",
    "        # gradient descent update\n",
    "        w = w - tau * grad\n",
    "        # store w and loss\n",
    "        losses.append(loss)\n",
    "    cost = list(losses)\n",
    "    n_iterations = [x for x in range(1,max_iters+1)]\n",
    "    plt.plot(n_iterations, cost)\n",
    "    plt.xlabel('No. of iterations')\n",
    "    plt.ylabel('Cost')\n",
    "        \n",
    "def parameters_accuracies_r(y,x,tau,xt,yt,gamma):\n",
    "    for i in range (500,5000,500):\n",
    "        a= last_iter_parameters_r(y,x,w,i,tau,gamma)\n",
    "        b=accuracy(xt,a,yt)\n",
    "        print(\"with\", i,\"iterations and stepsize=\", tau, \"we get the following test accuracy:\", b)\n",
    "        \n",
    "#out of sample validation\n",
    "np.random.seed(10) #20-80 split\n",
    "perm=np.random.permutation(887)\n",
    "x_train,x_test= Matrix_Combine[perm][177:][:,0:7],Matrix_Combine[perm][:177][:,0:7]\n",
    "y_train,y_test=Matrix_Combine[perm][177:][:,-1],Matrix_Combine[perm][:177][:,-1]\n",
    "    \n",
    "#5 fold cross-validation\n",
    "x_fold1= Matrix_Combine[:177][:,0:7]\n",
    "y_fold1= Matrix_Combine[:177][:,-1]\n",
    "x_fold2= Matrix_Combine[177:354][:,0:7]\n",
    "y_fold2= Matrix_Combine[177:354][:,-1]\n",
    "x_fold3= Matrix_Combine[354:531][:,0:7]\n",
    "y_fold3= Matrix_Combine[354:531][:,-1]\n",
    "x_fold4= Matrix_Combine[531:708][:,0:7]\n",
    "y_fold4= Matrix_Combine[531:708][:,-1]\n",
    "x_fold5= Matrix_Combine[708:887][:,0:7]\n",
    "y_fold5= Matrix_Combine[708:887][:,-1]\n",
    "#test on fold 1\n",
    "x_train_1, x_test_1= np.concatenate((x_fold2,x_fold3,x_fold4,x_fold5),axis=0), x_fold1\n",
    "y_train_1, y_test_1= np.concatenate((y_fold2,y_fold3,y_fold4,y_fold5),axis=0), y_fold1\n",
    "#test on fold 2\n",
    "x_train_2, x_test_2= np.concatenate((x_fold1,x_fold3,x_fold4,x_fold5),axis=0), x_fold2\n",
    "y_train_2, y_test_2= np.concatenate((y_fold1,y_fold3,y_fold4,y_fold5),axis=0), y_fold2\n",
    "#test on fold 3\n",
    "x_train_3, x_test_3= np.concatenate((x_fold1,x_fold2,x_fold4,x_fold5),axis=0), x_fold3\n",
    "y_train_3, y_test_3= np.concatenate((y_fold1,y_fold2,y_fold4,y_fold5),axis=0), y_fold3\n",
    "#test on fold 4\n",
    "x_train_4, x_test_4= np.concatenate((x_fold1,x_fold2,x_fold3,x_fold5),axis=0), x_fold4\n",
    "y_train_4, y_test_4= np.concatenate((y_fold1,y_fold2,y_fold3,y_fold5),axis=0), y_fold4\n",
    "#test on fold 5\n",
    "x_train_5, x_test_5= np.concatenate((x_fold1,x_fold2,x_fold3,x_fold4),axis=0), x_fold5\n",
    "y_train_5, y_test_5= np.concatenate((y_fold1,y_fold2,y_fold3,y_fold4),axis=0), y_fold5\n",
    "\n",
    "#5 fold cross-validation on permuted dataset\n",
    "np.random.seed(1) \n",
    "perm=np.random.permutation(887)\n",
    "px_fold1= Matrix_Combine[perm][:177][:,0:7]\n",
    "py_fold1= Matrix_Combine[perm][:177][:,-1]\n",
    "px_fold2= Matrix_Combine[perm][177:354][:,0:7]\n",
    "py_fold2= Matrix_Combine[perm][177:354][:,-1]\n",
    "px_fold3= Matrix_Combine[perm][354:531][:,0:7]\n",
    "py_fold3= Matrix_Combine[perm][354:531][:,-1]\n",
    "px_fold4= Matrix_Combine[perm][531:708][:,0:7]\n",
    "py_fold4= Matrix_Combine[perm][531:708][:,-1]\n",
    "px_fold5= Matrix_Combine[perm][708:887][:,0:7]\n",
    "py_fold5= Matrix_Combine[perm][708:887][:,-1]\n",
    "#test on fold 1\n",
    "px_train_1, px_test_1= np.concatenate((px_fold2,px_fold3,px_fold4,px_fold5),axis=0), px_fold1\n",
    "py_train_1, py_test_1= np.concatenate((py_fold2,py_fold3,py_fold4,py_fold5),axis=0), py_fold1\n",
    "#test on fold 2\n",
    "px_train_2, px_test_2= np.concatenate((px_fold1,px_fold3,px_fold4,px_fold5),axis=0), px_fold2\n",
    "py_train_2, py_test_2= np.concatenate((py_fold1,py_fold3,py_fold4,py_fold5),axis=0), py_fold2\n",
    "#test on fold 3\n",
    "px_train_3, px_test_3= np.concatenate((px_fold1,px_fold2,px_fold4,px_fold5),axis=0), px_fold3\n",
    "py_train_3, py_test_3= np.concatenate((py_fold1,py_fold2,py_fold4,py_fold5),axis=0), py_fold3\n",
    "#test on fold 4\n",
    "px_train_4, px_test_4= np.concatenate((px_fold1,px_fold2,px_fold3,px_fold5),axis=0), px_fold4\n",
    "py_train_4, py_test_4= np.concatenate((py_fold1,py_fold2,py_fold3,py_fold5),axis=0), py_fold4\n",
    "#test on fold 5\n",
    "px_train_5, px_test_5= np.concatenate((px_fold1,px_fold2,px_fold3,px_fold4),axis=0), px_fold5\n",
    "py_train_5, py_test_5= np.concatenate((py_fold1,py_fold2,py_fold3,py_fold4),axis=0), py_fold5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
